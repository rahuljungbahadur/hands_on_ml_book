{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahuljungbahadur/hands_on_ml_book/blob/main/chp13_exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rZV38fSduWsx"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yIxe11DtvwP6",
        "outputId": "be6f0f4e-01cf-4e74-e1fd-129585eb8235"
      },
      "outputs": [],
      "source": [
        "base_path='E:\\\\Projects\\\\aclImdb'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "8VtNyl_DwEtG",
        "outputId": "a70a7714-eebf-4f21-f66c-711a792d078d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-22497c20-a411-4875-9cc2-fe9b1d6367e9\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-22497c20-a411-4875-9cc2-fe9b1d6367e9\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving aclImdb_v1.tar.gz to aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-292f82be1b7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m     result = _output.eval_js(\n\u001b[1;32m     70\u001b[0m         'google.colab._files._uploadFilesContinue(\"{output_id}\")'.format(\n\u001b[0;32m---> 71\u001b[0;31m             output_id=output_id))\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'action'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'append'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m       \u001b[0;31m# JS side uses a generator of promises to process all of the files- some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# for fn in uploaded.keys():\n",
        "#   print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "#       name=fn, length=len(uploaded[fn])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUtTidpTwyUo",
        "outputId": "e15ee141-c8d3-4a69-95b5-c2238d293120"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['imdb.vocab', 'imdbEr.txt', 'README', 'test', 'train']"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir(base_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ai2kvsdSwX-a",
        "outputId": "15b0a91d-6dee-4693-9f31-91614c9cd74b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tarfile\n",
        "\n",
        "# open file\n",
        "file = tarfile.open('aclImdb_v1.tar.gz')\n",
        "  \n",
        "# print file names\n",
        "print(file.getnames())\n",
        "  \n",
        "# extract files\n",
        "file.extractall('./imdb_dataset')\n",
        "  \n",
        "# close file\n",
        "file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSeVmC3Txxih",
        "outputId": "d41b22ed-27ef-436d-903c-2fdc03cf3703"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['neg',\n",
              " 'urls_pos.txt',\n",
              " 'urls_neg.txt',\n",
              " 'labeledBow.feat',\n",
              " 'unsupBow.feat',\n",
              " 'urls_unsup.txt',\n",
              " 'unsup',\n",
              " 'pos']"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir('imdb_dataset/aclImdb/train/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "jEcTSMZkx6Mk"
      },
      "outputs": [],
      "source": [
        "trainSet_posFp = f'{base_path}/train/pos'\n",
        "trainSet_negFp = f'{base_path}/train/neg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zuVJPja10Vah"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRXLl-ji1I70",
        "outputId": "6867e713-2ff8-433a-dde9-8f99da08d33e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on function list_files in module tensorflow.python.data.ops.dataset_ops:\n",
            "\n",
            "list_files(file_pattern, shuffle=None, seed=None, name=None)\n",
            "    A dataset of all files matching one or more glob patterns.\n",
            "    \n",
            "    The `file_pattern` argument should be a small number of glob patterns.\n",
            "    If your filenames have already been globbed, use\n",
            "    `Dataset.from_tensor_slices(filenames)` instead, as re-globbing every\n",
            "    filename with `list_files` may result in poor performance with remote\n",
            "    storage systems.\n",
            "    \n",
            "    Note: The default behavior of this method is to return filenames in\n",
            "    a non-deterministic random shuffled order. Pass a `seed` or `shuffle=False`\n",
            "    to get results in a deterministic order.\n",
            "    \n",
            "    Example:\n",
            "      If we had the following files on our filesystem:\n",
            "    \n",
            "        - /path/to/dir/a.txt\n",
            "        - /path/to/dir/b.py\n",
            "        - /path/to/dir/c.py\n",
            "    \n",
            "      If we pass \"/path/to/dir/*.py\" as the directory, the dataset\n",
            "      would produce:\n",
            "    \n",
            "        - /path/to/dir/b.py\n",
            "        - /path/to/dir/c.py\n",
            "    \n",
            "    Args:\n",
            "      file_pattern: A string, a list of strings, or a `tf.Tensor` of string type\n",
            "        (scalar or vector), representing the filename glob (i.e. shell wildcard)\n",
            "        pattern(s) that will be matched.\n",
            "      shuffle: (Optional.) If `True`, the file names will be shuffled randomly.\n",
            "        Defaults to `True`.\n",
            "      seed: (Optional.) A `tf.int64` scalar `tf.Tensor`, representing the random\n",
            "        seed that will be used to create the distribution. See\n",
            "        `tf.random.set_seed` for behavior.\n",
            "      name: Optional. A name for the tf.data operations used by `list_files`.\n",
            "    \n",
            "    Returns:\n",
            "     Dataset: A `Dataset` of strings corresponding to file names.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(tf.data.Dataset.list_files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "pl00_aG70Z8l"
      },
      "outputs": [],
      "source": [
        "trainSet_posFp_random = tf.data.Dataset.list_files(file_pattern=f'{trainSet_posFp}\\\\*.txt')\n",
        "trainSet_negFp_random = tf.data.Dataset.list_files(file_pattern=f'{trainSet_negFp}\\\\*.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JygAmlLm6eNK",
        "outputId": "a353355e-bd2b-4e47-85d1-49c7d04a2242"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['README', 'imdbEr.txt', 'valSet', 'testSet', 'test', 'imdb.vocab', 'train']"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir('imdb_dataset/aclImdb')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "oX72Uaua0eTe"
      },
      "outputs": [],
      "source": [
        "os.mkdir(f'{base_path}\\\\testSet')\n",
        "os.mkdir(f'{base_path}\\\\valSet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.mkdir(f'{base_path}\\\\testSet\\\\pos')\n",
        "os.mkdir(f'{base_path}\\\\testSet\\\\neg')\n",
        "os.mkdir(f'{base_path}\\\\valSet\\\\pos')\n",
        "os.mkdir(f'{base_path}\\\\valSet\\\\neg')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zH3p1qWs8FeI"
      },
      "source": [
        "### Split the test set into a validation set (15,000) and a test set (10,000)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['imdb.vocab', 'imdbEr.txt', 'README', 'test', 'testSet', 'train', 'valSet']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir(base_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "UAgURmZ80m2D"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3250_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3251_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3252_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3253_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3254_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3255_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3256_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3257_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3258_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3259_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\325_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3260_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3261_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3262_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3263_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3264_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3265_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3266_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3267_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3268_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3269_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\326_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3270_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3271_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3272_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3273_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3274_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3275_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3276_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3277_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3278_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3279_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\327_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3280_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3281_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3282_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3283_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3284_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3285_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3286_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3287_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3288_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3289_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\328_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3290_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3291_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3292_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3293_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3294_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3295_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3296_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3297_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3298_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3299_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\329_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\32_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3300_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3301_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3302_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3303_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3304_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3305_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3306_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3307_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3308_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3309_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\330_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3310_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3311_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3312_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3313_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3314_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3315_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3316_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3317_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3318_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3319_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\331_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3320_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3321_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3322_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3323_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3324_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3325_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3326_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3327_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3328_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3329_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\332_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3330_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3331_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3332_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3333_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3334_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3335_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3336_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3337_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3338_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3339_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\333_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3340_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3341_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3342_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3343_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3344_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3345_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3346_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3347_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3348_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3349_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\334_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3350_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3351_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3352_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3353_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3354_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3355_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3356_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3357_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3358_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3359_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\335_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3360_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3361_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3362_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3363_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3364_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3365_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3366_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3367_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3368_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3369_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\336_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3370_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3371_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3372_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3373_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3374_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3375_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3376_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3377_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3378_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3379_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\337_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3380_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3381_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3382_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3383_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3384_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3385_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3386_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3387_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3388_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3389_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\338_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3390_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3391_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3392_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3393_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3394_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3395_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3396_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3397_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3398_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3399_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\339_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\33_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3400_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3401_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3402_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3403_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3404_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3405_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3406_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3407_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3408_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3409_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\340_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3410_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3411_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3412_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3413_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3414_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3415_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3416_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3417_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3418_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3419_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\341_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3420_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3421_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3422_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3423_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3424_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3425_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3426_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3427_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3428_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3429_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\342_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3430_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3431_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3432_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3433_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3434_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3435_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3436_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3437_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3438_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3439_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\343_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3440_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3441_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3442_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3443_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3444_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3445_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3446_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3447_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3448_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3449_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\344_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3450_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3451_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3452_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3453_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3454_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3455_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3456_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3457_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3458_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3459_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\345_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3460_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3461_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3462_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3463_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3464_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3465_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3466_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3467_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3468_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3469_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\346_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3470_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3471_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3472_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3473_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3474_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3475_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3476_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3477_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3478_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3479_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\347_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3480_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3481_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3482_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3483_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3484_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3485_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3486_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3487_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3488_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3489_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\348_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3490_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3491_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3492_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3493_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3494_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3495_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3496_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3497_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3498_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3499_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\349_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\34_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3500_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3501_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3502_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3503_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3504_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3505_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3506_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3507_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3508_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3509_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\350_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3510_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3511_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3512_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3513_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3514_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3515_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3516_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3517_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3518_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3519_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\351_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3520_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3521_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3522_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3523_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3524_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3525_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3526_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3527_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3528_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3529_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\352_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3530_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3531_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3532_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3533_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3534_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3535_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3536_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3537_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3538_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3539_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\353_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3540_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3541_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3542_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3543_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3544_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3545_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3546_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3547_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3548_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3549_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\354_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3550_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3551_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3552_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3553_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3554_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3555_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3556_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3557_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3558_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3559_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\355_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3560_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3561_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3562_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3563_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3564_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3565_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3566_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3567_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3568_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3569_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\356_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3570_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3571_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3572_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3573_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3574_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3575_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3576_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3577_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3578_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3579_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\357_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3580_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3581_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3582_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3583_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3584_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3585_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3586_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3587_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3588_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3589_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\358_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3590_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3591_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3592_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3593_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3594_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3595_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3596_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3597_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3598_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3599_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\359_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\35_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3600_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3601_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3602_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3603_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3604_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3605_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3606_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3607_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3608_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3609_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\360_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3610_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3611_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3612_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3613_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3614_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3615_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3616_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3617_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3618_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3619_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\361_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3620_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3621_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3622_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3623_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3624_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3625_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3626_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3627_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3628_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3629_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\362_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3630_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3631_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3632_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3633_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3634_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3635_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3636_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3637_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3638_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3639_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\363_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3640_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3641_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3642_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3643_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3644_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3645_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3646_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3647_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3648_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3649_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\364_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3650_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3651_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3652_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3653_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3654_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3655_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3656_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3657_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3658_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3659_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\365_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3660_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3661_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3662_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3663_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3664_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3665_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3666_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3667_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3668_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3669_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\366_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3670_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3671_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3672_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3673_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3674_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3675_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3676_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3677_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3678_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3679_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\367_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3680_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3681_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3682_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3683_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3684_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3685_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3686_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3687_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3688_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3689_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\368_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3690_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3691_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3692_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3693_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3694_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3695_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3696_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3697_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3698_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3699_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\369_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\36_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3700_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3701_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3702_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3703_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3704_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3705_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3706_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3707_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3708_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3709_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\370_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3710_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3711_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3712_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3713_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3714_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3715_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3716_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3717_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3718_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3719_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\371_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3720_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3721_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3722_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3723_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3724_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3725_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3726_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3727_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3728_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3729_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\372_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3730_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3731_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3732_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3733_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3734_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3735_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3736_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3737_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3738_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3739_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\373_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3740_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3741_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3742_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3743_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3744_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3745_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3746_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3747_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3748_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3749_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\374_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3750_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3751_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3752_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3753_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3754_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3755_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3756_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3757_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3758_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3759_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\375_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3760_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3761_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3762_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3763_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3764_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3765_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3766_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3767_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3768_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3769_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\376_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3770_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3771_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3772_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3773_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3774_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3775_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3776_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3777_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3778_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3779_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\377_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3780_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3781_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3782_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3783_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3784_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3785_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3786_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3787_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3788_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3789_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\378_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3790_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3791_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3792_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3793_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3794_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3795_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3796_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3797_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3798_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3799_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\379_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\37_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3800_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3801_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3802_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3803_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3804_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3805_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3806_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3807_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3808_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3809_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\380_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3810_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3811_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3812_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3813_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3814_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3815_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3816_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3817_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3818_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3819_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\381_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3820_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3821_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3822_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3823_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3824_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3825_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3826_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3827_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3828_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3829_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\382_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3830_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3831_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3832_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3833_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3834_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3835_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3836_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3837_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3838_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3839_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\383_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3840_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3841_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3842_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3843_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3844_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3845_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3846_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3847_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3848_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3849_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\384_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3850_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3851_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3852_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3853_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3854_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3855_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3856_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3857_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3858_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3859_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\385_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3860_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3861_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3862_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3863_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3864_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3865_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3866_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3867_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3868_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3869_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\386_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3870_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3871_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3872_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3873_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3874_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3875_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3876_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3877_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3878_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3879_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\387_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3880_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3881_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3882_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3883_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3884_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3885_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3886_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3887_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3888_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3889_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\388_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3890_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3891_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3892_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3893_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3894_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3895_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3896_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3897_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3898_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3899_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\389_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\38_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3900_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3901_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3902_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3903_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3904_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3905_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3906_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3907_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3908_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3909_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\390_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3910_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3911_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3912_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3913_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3914_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3915_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3916_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3917_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3918_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3919_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\391_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3920_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3921_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3922_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3923_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3924_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3925_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3926_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3927_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3928_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3929_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\392_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3930_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3931_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3932_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3933_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3934_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3935_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3936_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3937_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3938_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3939_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\393_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3940_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3941_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3942_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3943_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3944_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3945_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3946_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3947_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3948_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3949_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\394_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3950_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3951_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3952_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3953_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3954_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3955_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3956_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3957_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3958_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3959_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\395_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3960_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3961_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3962_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3963_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3964_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3965_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3966_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3967_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3968_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3969_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\396_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3970_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3971_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3972_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3973_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3974_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3975_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3976_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3977_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3978_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3979_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\397_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3980_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3981_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3982_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3983_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3984_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3985_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3986_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3987_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3988_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3989_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\398_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3990_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3991_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3992_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3993_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3994_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3995_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3996_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3997_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3998_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3999_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\399_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\39_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\3_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4000_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4001_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4002_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4003_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4004_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4005_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4006_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4007_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4008_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4009_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\400_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4010_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4011_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4012_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4013_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4014_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4015_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4016_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4017_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4018_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4019_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\401_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4020_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4021_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4022_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4023_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4024_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4025_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4026_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4027_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4028_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4029_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\402_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4030_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4031_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4032_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4033_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4034_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4035_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4036_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4037_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4038_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4039_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\403_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4040_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4041_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4042_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4043_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4044_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4045_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4046_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4047_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4048_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4049_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\404_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4050_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4051_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4052_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4053_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4054_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4055_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4056_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4057_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4058_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4059_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\405_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4060_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4061_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4062_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4063_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4064_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4065_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4066_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4067_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4068_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4069_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\406_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4070_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4071_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4072_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4073_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4074_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4075_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4076_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4077_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4078_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4079_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\407_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4080_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4081_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4082_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4083_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4084_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4085_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4086_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4087_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4088_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4089_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\408_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4090_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4091_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4092_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4093_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4094_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4095_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4096_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4097_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4098_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4099_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\409_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\40_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4100_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4101_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4102_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4103_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4104_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4105_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4106_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4107_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4108_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4109_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\410_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4110_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4111_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4112_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4113_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4114_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4115_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4116_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4117_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4118_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4119_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\411_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4120_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4121_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4122_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4123_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4124_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4125_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4126_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4127_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4128_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4129_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\412_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4130_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4131_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4132_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4133_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4134_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4135_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4136_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4137_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4138_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4139_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\413_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4140_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4141_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4142_10.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4143_9.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4144_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4145_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4146_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4147_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4148_7.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\4149_8.txt',\n",
              " 'E:\\\\Projects\\\\aclImdb\\\\valSet\\\\pos\\\\414_9.txt',\n",
              " ...]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "## test set\n",
        "[shutil.copy2(f'{base_path}\\\\test\\\\neg\\\\{fp}', f'{base_path}\\\\testSet\\\\neg') for fp in os.listdir(f'{base_path}\\\\test\\\\neg')[:5000]]\n",
        "[shutil.copy2(f'{base_path}\\\\test\\\\pos\\\\{fp}', f'{base_path}\\\\testSet\\\\pos') for fp in os.listdir(f'{base_path}\\\\test\\\\pos')[:5000]]\n",
        "\n",
        "## Valid Set\n",
        "[shutil.copy2(f'{base_path}\\\\test\\\\neg\\\\{fp}', f'{base_path}\\\\valSet\\\\neg') for fp in os.listdir(f'{base_path}\\\\test\\\\neg')[5000:]]\n",
        "[shutil.copy2(f'{base_path}\\\\test\\\\pos\\\\{fp}', f'{base_path}\\\\valSet\\\\pos') for fp in os.listdir(f'{base_path}\\\\test\\\\pos')[5000:]]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0jpOW_X2T6S",
        "outputId": "44156723-41a1-4f9d-90b6-1df2a65e5554"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7500, 7500)"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(len(os.listdir(f'{base_path}\\\\valSet\\\\pos\\\\')), len(os.listdir(f'{base_path}\\\\valSet\\\\neg\\\\')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09uJlnG42a_y",
        "outputId": "06bd3547-e41d-4e4b-f08a-0e195872c08c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5000, 5000)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(len(os.listdir(f'{base_path}\\\\testSet\\\\pos\\\\')), len(os.listdir(f'{base_path}\\\\testSet\\\\neg\\\\')))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SLFZOR6-hVU"
      },
      "source": [
        "#### Qns 2 Done"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSXSwQ1_-oM-"
      },
      "source": [
        "## Use tf.data to create an efficient dataset for each set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KARcZ2iArCy"
      },
      "outputs": [],
      "source": [
        "help(tf.data.TextLineDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "0liqxBPNyRrO"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'E:\\\\Projects\\\\aclImdb'"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "base_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0qOI2l9ymf-",
        "outputId": "cb7c4ed3-2b0c-4ffa-da35-9a7a989f9df2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['labeledBow.feat',\n",
              " 'neg',\n",
              " 'pos',\n",
              " 'unsup',\n",
              " 'unsupBow.feat',\n",
              " 'urls_neg.txt',\n",
              " 'urls_pos.txt',\n",
              " 'urls_unsup.txt']"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir('../aclImdb/train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainSet_posFp_random = tf.data.Dataset.list_files(file_pattern=f'{base_path}\\\\train\\\\pos\\\\*.txt')\n",
        "trainSet_negFp_random = tf.data.Dataset.list_files(file_pattern=f'{base_path}\\\\train\\\\neg\\\\*.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9367_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2363_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11856_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8844_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11166_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5347_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2354_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1380_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6168_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10519_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1494_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9980_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\807_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4449_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3159_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3428_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\152_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6489_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2817_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9392_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2403_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7807_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9713_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5741_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11564_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9541_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9866_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11789_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6725_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9670_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7901_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5051_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2235_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4963_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3472_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12354_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8668_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9164_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\761_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9654_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5380_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2921_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3056_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4007_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7702_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9192_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6104_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10344_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4541_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8566_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1196_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\812_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9898_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9122_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2911_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8396_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\45_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11366_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7359_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7373_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1074_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\225_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\56_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9543_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7088_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2822_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4884_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6998_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4168_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5834_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5587_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10579_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1917_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2198_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1088_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2557_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6871_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\124_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10517_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8181_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7248_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10547_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4949_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4747_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8444_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2329_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6461_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4408_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8953_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4043_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7356_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9776_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8575_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6442_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4305_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10613_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10727_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2601_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6180_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9455_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9404_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12410_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12186_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7577_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11618_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4387_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10476_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6522_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7617_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11113_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7489_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8075_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3539_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1043_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9838_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\615_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3962_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2058_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3055_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8828_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\571_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10135_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9109_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4240_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12253_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11739_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\98_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4746_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7123_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4539_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2295_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4312_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4540_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3066_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12198_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9787_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4035_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9012_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\824_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10966_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7508_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11853_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11004_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12299_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2275_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5366_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3823_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10264_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3403_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\549_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2361_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\911_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2978_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11600_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2780_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11469_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6714_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8583_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2025_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8747_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3142_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7694_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3047_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8059_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1863_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8329_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11924_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3287_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10039_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5193_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5547_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4262_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9800_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5417_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\54_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11767_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5325_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9334_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3446_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10136_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5676_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10291_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11520_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5844_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10668_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10570_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3150_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\835_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1579_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12399_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6547_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9184_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8713_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6033_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1255_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12337_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8797_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9735_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8922_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2111_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9256_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7427_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3449_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12105_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6441_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9134_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8246_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1460_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7210_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5666_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11580_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7418_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11537_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2674_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5045_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5450_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3140_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1908_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9914_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\540_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\994_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3405_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4405_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8021_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7407_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7235_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4859_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1126_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2285_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10105_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7514_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\413_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3575_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7030_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3692_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1539_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12335_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3318_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\566_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7779_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6053_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2226_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7074_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1034_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10580_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10034_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1848_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\686_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2456_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8357_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4178_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6431_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11269_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2810_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\183_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5474_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9401_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2768_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6594_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5079_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\373_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11492_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3012_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12245_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8820_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2004_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8122_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5083_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3117_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7865_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3557_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\629_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1312_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8094_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1606_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6763_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12157_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7478_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10453_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9697_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1471_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6888_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9768_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7002_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8424_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4355_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9758_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\720_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6268_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9123_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4898_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11144_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9889_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2713_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5795_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12280_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5784_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12284_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8637_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9803_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11802_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1008_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9465_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9235_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4403_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11872_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\869_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9138_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4470_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4351_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\135_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1003_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10806_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7653_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7410_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4191_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8806_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\828_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8896_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1819_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6562_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8272_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5816_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5727_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4067_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7896_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3121_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2431_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10078_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4137_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11397_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10814_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5080_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12150_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1899_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12403_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2174_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11834_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9246_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\467_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8442_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8049_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3613_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7753_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\473_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12123_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9353_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2931_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\551_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11240_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\793_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5058_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8904_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3452_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9076_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11122_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6075_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3157_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7935_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9982_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1508_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2577_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\728_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11352_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8632_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8733_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3331_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8622_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1687_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5801_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6480_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9580_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11222_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12485_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3478_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4330_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2868_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9194_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5334_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9774_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\799_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3954_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1645_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4129_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9655_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8375_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2719_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8787_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10489_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9983_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5286_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\522_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2530_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12442_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8881_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4781_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5785_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10013_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3411_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12103_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9829_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8824_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1263_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9454_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6317_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2070_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5572_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\336_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5915_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2936_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\506_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7329_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11851_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11028_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1224_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6383_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10141_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6963_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5538_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10575_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6520_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8243_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8792_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\844_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1528_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2037_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11869_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2742_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5693_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5815_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12215_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2286_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11006_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2243_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4564_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4431_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\896_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3450_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9317_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11750_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\992_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1796_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7017_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8055_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\274_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6935_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1674_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11091_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9927_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12259_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5413_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6623_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12221_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9211_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\955_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6266_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11407_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11877_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7890_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12258_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10150_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3279_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4692_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5680_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6473_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1626_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12109_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5429_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\300_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1002_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2845_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9622_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4456_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12127_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1580_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3367_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4797_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4657_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3153_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10555_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5670_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1716_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1691_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2824_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5254_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3703_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8498_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6926_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1488_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6908_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3839_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1957_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4363_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1041_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12396_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4011_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8221_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11828_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\414_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5310_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7467_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11450_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8624_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1288_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\893_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11712_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7673_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\408_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3934_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8408_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\424_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3593_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7900_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3553_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\175_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2455_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7918_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11581_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10363_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5576_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4000_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11337_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8851_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4652_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10221_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8014_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7102_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3339_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\121_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7399_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8609_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9242_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9155_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4154_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11989_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4520_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4170_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10240_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\144_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6179_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10266_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11261_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8619_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1184_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5269_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3433_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12413_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\592_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3878_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\346_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6658_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11648_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1676_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5722_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4893_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11730_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1144_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2869_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10490_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10324_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\789_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5494_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\985_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8635_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4533_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\776_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7309_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6589_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\147_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4650_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1654_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11539_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3800_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7067_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6852_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10582_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11474_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5649_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3907_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8276_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11753_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11843_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4219_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4039_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4328_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6662_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3481_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3025_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9780_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10320_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\780_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9408_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11570_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2076_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8852_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2331_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10745_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5602_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4233_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10746_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6624_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2565_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12041_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10708_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3875_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6360_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9253_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7149_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8469_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5138_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3843_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8468_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9891_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11782_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\276_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4698_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3736_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\229_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9537_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12430_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7800_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8460_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7588_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\554_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2585_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\778_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3939_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8337_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1854_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9923_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8376_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4696_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8539_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2440_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9610_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10488_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4289_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11015_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\909_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9714_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\764_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3599_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6846_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7670_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12429_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10005_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8398_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6970_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11266_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10546_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7701_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7535_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10883_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10827_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2847_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11603_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2143_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1838_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8854_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5683_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2392_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8324_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4285_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12453_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8456_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12497_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8822_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10785_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3040_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9754_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11995_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1316_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6178_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3827_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\590_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3829_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3786_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10209_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5920_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11311_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6162_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1577_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\465_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9683_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5555_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4439_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7734_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2574_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12478_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\648_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5956_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8296_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1274_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2481_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5369_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9214_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1627_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2105_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6790_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6432_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11542_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6730_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11406_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8925_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6983_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9808_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\946_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1356_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6927_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4243_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4073_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8131_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3513_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9556_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12149_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6398_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10764_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10368_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9492_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7776_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5800_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7056_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12119_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\875_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8066_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9538_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5905_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\106_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4112_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4511_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9200_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6226_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7690_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\790_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3443_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2996_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1022_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2692_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9160_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\802_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9479_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10117_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1014_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\963_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7177_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7760_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\631_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10093_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10016_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9180_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8675_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12363_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11403_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\362_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11697_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8993_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3255_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12401_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3609_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5632_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11223_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10404_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1226_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6556_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11306_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11949_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1620_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9124_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7882_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7657_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9910_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10330_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2231_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5120_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7471_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4202_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\882_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5762_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9047_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11226_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3525_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5827_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1836_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11954_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5087_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10445_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3945_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12366_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7182_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7083_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7208_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4798_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6278_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6202_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1891_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2966_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9097_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5140_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7957_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12212_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9799_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9840_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4251_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8860_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2901_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4987_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2133_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12163_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9306_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5032_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8092_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9937_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9295_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10797_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\332_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9432_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4030_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8423_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1495_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6101_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5131_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11675_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12487_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3636_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7441_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12147_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10211_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6426_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9884_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4840_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8633_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6409_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8931_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1472_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1267_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12255_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10581_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3225_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3704_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3399_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10989_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4894_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4013_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11333_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10390_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7998_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2420_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1535_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11513_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2009_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3195_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7780_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3783_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11262_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8069_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5540_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2177_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1684_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6783_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\605_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3858_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5692_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\596_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\735_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2706_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3532_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11163_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7276_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9836_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9522_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11459_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3932_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7867_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10070_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4942_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3242_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\738_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2965_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5607_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9564_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3549_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1275_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\114_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1952_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6972_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3566_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6716_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4827_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1752_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12423_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4542_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\546_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11736_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8047_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\500_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7633_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7274_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11669_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11440_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3970_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7529_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11788_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5833_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4637_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5462_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4999_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\370_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\524_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6722_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2975_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8345_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10007_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9875_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4063_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7165_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\971_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6163_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9018_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2604_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\496_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9245_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7876_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11514_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4089_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10116_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5883_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11388_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6155_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\636_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5708_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7332_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9422_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4042_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\123_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4237_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11708_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9023_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1824_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3061_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9379_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5003_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9578_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11419_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9003_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6813_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\781_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5036_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3299_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10590_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10208_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11328_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4794_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4326_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1293_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1934_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6934_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6083_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11398_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8320_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4114_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\9779_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1690_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8492_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4264_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6144_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12257_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\970_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2080_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6939_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1556_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10128_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2244_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\12062_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3028_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2671_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4779_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\1902_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7740_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\126_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6560_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4697_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7783_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7879_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\11287_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2648_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6738_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\3634_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\2454_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\603_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6514_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10371_8.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\6418_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\5818_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10520_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\4715_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\128_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\86_10.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\8743_7.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10463_10.txt'>,\n",
              " ...]"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[i for i in trainSet_posFp_random]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "keQrBaU2yYFn",
        "outputId": "37510aef-a94e-423d-f4b2-003d49489611"
      },
      "outputs": [
        {
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-aec3e5b950ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainSet_posFp_random\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_pattern\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imdb_dataset/aclImdb/train/pos/*.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrainSet_negFp_random\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_pattern\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imdb_dataset/aclImdb/train/neg/*.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mlist_files\u001b[0;34m(file_pattern, shuffle, seed, name)\u001b[0m\n\u001b[1;32m   1335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       assert_not_empty = control_flow_ops.Assert(\n\u001b[0;32m-> 1337\u001b[0;31m           condition, [message], summarize=1, name=\"assert_not_empty\")\n\u001b[0m\u001b[1;32m   1338\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massert_not_empty\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m         \u001b[0mmatching_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatching_files\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mAssert\u001b[0;34m(condition, data, summarize, name)\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0mop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m           \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Expected '%s' to be true. Summarized data: %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m           (condition, \"\\n\".join(data_str)))\n\u001b[0m\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: b'No files matched pattern: imdb_dataset/aclImdb/train/pos/*.txt'"
          ]
        }
      ],
      "source": [
        "# trainSet_posFp_random = tf.data.Dataset.list_files(file_pattern='imdb_dataset/aclImdb/train/pos/*.txt')\n",
        "# trainSet_negFp_random = tf.data.Dataset.list_files(file_pattern='imdb_dataset/aclImdb/train/neg/*.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\10721_9.txt'>,\n",
              " <tf.Tensor: shape=(), dtype=string, numpy=b'E:\\\\Projects\\\\aclImdb\\\\train\\\\pos\\\\7719_9.txt'>]"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[i for i in trainSet_posFp_random.take(2)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "id": "y8AgPPUA2isX",
        "outputId": "e1ac915d-6af8-4ef9-d822-a05635fed1b5"
      },
      "outputs": [],
      "source": [
        "trainSet_pos = tf.data.TextLineDataset(trainSet_posFp_random, num_parallel_reads=5)\n",
        "trainSet_pos = trainSet_pos.map(lambda content: (content, 1))\n",
        "\n",
        "trainSet_neg = tf.data.TextLineDataset(trainSet_negFp_random, num_parallel_reads=5)\n",
        "trainSet_neg = trainSet_neg.map(lambda content: (content, 0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainSet_complete = tf.data.Dataset.concatenate(trainSet_pos, trainSet_neg).shuffle(25000).batch(32).prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(<tf.Tensor: shape=(32,), dtype=string, numpy=\n",
              "  array([b\"Absolutely one of the worst movies I've seen in a long time! It starts off badly and just deteriorates. Katherine Heigl is woefully miscast in a Lolita role and Leo Grillo manfully struggles with what is essentially a cardboard cutout character. The only cast-member with any enthusiasm is Tom Sizemore, who hams it up as a villain and goes completely overboard with his role. The script is dire, the acting horrible and it has plot holes big enough to drive a double-decker bus through! It is also the most sexist movie I have ever seen! Katherine Heigl's character is completely unsympathetic. She's seen as an evil, wanton seductress who lures the poor, innocent married man to cheat on his wife. It is implied throughout the movie that she's underage, and the message that accompanies that plot-strand just beggars belief! At the end, she isn't even able to redeem herself by shooting the man who's obviously (ha!) become demented with rage and guilt, but the script allows him to kill himself, thereby redeeming himself in the eyes of males everywhere. Horrible. Don't waste your time.\",\n",
              "         b\"The film adaptation of James Joyce's Ulysses is excellent. The actors, the voice overs, the direction, it all captures the feel of the novel without sacrificing its own merits. The Milo O'Shea does an excellent job as Leopold Bloom, the cuckolded man married to the sassy Molly. I absolutely love this picture.\",\n",
              "         b\"All the folks who sit here and say that this movie's weak link is the Ramones would probably say that Amadeus was ok if not for that irritating harpsichordist. Rock and Roll High School was centered around the Ramones. How anyone can watch this and not get a kick out of Joey Ramone eating bean sprouts backstage in an attempt to keep him in performing condition is obviously a wet blanket square daddy-o. Ms Trogar, exploding white mice, the hall patrols...instant classics. Nevermind the Riff Randell character.<br /><br />If you don't like the Ramones then you don't know rock and roll and you don't deserve to watch a movie called ROCK AND ROLL High School.\",\n",
              "         b'Wow. I don\\'t even really remember that much about this movie, except that it stunk.<br /><br />The plot\\'s basically; a girl\\'s parents neglect her, so this sicko PokeMon pretends to be her dad. Am I the only one disturbed by that? Then, this weirdo PokeMon kidnaps Ash\\'s mom to pretend to be the girl\\'s. I don\\'t care if he was trying to make the girl happy, that\\'s just gross.<br /><br />There was no real plot. The girl was just a whiny brat who wanted things her own way. She played with Unowns, was the \"daughter\" of Entei and apparently could grow and shrink in age on a whim with the help of her \"dad\".<br /><br />That\\'s pretty much all I can remember, but I think you can take it as a hint, and not see it. (Or if you do see it, don\\'t expect much.) 1 out of 10.<br /><br />Seriously. If you want a PokeMon movie, rent \"PokeMon; the First Movie\".',\n",
              "         b\"Well.......in contrast to other comments previously written I have to say that the only good thing about this film is the fact that one guy in it looked a bit like Jason Donavon which reminded me of my youth. I have no idea how it won any awards, and although I'm sure a great deal of effort went into making it it was all fruitless as the final outcome is one which screams of early 90's foreign soap operas. The plot was non-existent, the cinematography was hopeless and the acting was on par with an a-level performance. It was unfortunately long and the sub-plots were incredibly unrealistic....for example....if your best friend slept with your ex-boyfriend of 6 years after only 2 weeks of being broken up you would not all remain the best of friends. It was all fantasy. That's all! Oh yeah, and the weird 90's house/soft core indie was mind numbing!\",\n",
              "         b'Why a stupid, boring, crappy overrated film series like \"Star Wars\" gets all the hype, and a truly amazing film like this one goes completely un-noticed.. is beyond me... This movie will really open your eyes to the dark, disturbing, sad, and scary world we live in...<br /><br />Unlike the boring \"Elephant\", this movie isn\\'t one of those \"just a typical day until someome pulls the trigger\" movies.. this movie focuses more on what happens AFTER the event...<br /><br />Deana, played by the very hot and very talented Erika Christensen, is a happy and healthy straight-A student with great friends and a great life... until... she is injured on the day of the shooting, by being shot in the head.. Luckily she is not killed, but is severely injured and has to be in the hospital for a while, causing her to be in a lot of emotional pain, in addition to the physical...<br /><br />Meanwhile, Alicia, played by the also very gorgeous and talented Busy Phillips, is a nasty, cold-hearted, rebellious, anti-social goth girl who doesn\\'t have a single positive trait on her... and she is unharmed when the shooting happens.. because it turns out, she was FRIENDS with the shooter and knew he was going to do what he did... which causes her to be brought into the police station and be asked some questions.. When she refuses to tell the cops if she knew the shooting was going to happen, they constantly come by her house to try to convince her to say something... and she still doesn\\'t, so the principal of the school makes her attend a funeral of one of the dead students, and after she walks out on that... the principal decides enough is enough, and forces her to go visit Deana in the hospital.. Of course she refuses this too, but the principal says that if Alicia doesn\\'t do this, the cops are going to continue to try to get her to say something.. and so she actually goes to see her...<br /><br />The lonely, traumatized, and both physically and emotionally wounded Deana is more than happy to have someone visit her, but of course, Alicia is anything BUT happy to be seeing her.. Deana attempts to give her a friendly welcome, but of course, Alicia responds with nothing but harsh and hurtful comments and a harsh statement on how she is only here because she is being forced, and has no intention of being friendly with her at all. But sooner or later, that intention will change... (and that\\'s all I\\'ll say :) This is truly one of the most moving movies ever, as well as one of the most dark and disturbing.. Actually, I think I would tie this with \"American History X\" as equally disturbing and moving at the same time...<br /><br />WARNING: Watch this movie at your own risk!! It contains VERY graphic scenes and images! EXCELLENT and criminally under-appreciated movie! I feel so ashamed that I\\'m pretty much the only one that knows about it!',\n",
              "         b\"I cannot stay indifferent to Lars van Trier's films. I consider 'Breaking the Waves' nothing less than a masterpiece. I loved 'Dancer in the Night'. I admired the idea in 'Dogville' but the overall exercise looked to me too dry and too theatrical, less cinema. 'Europa' which I see only now was a famous film at its time, succeeded in the US the relative success of an European film and got the Oscar for the best foreign language movie, but did not survive well the time in my opinion. It is also a too much explicit and extrovert exercise in cinema art to my taste.<br /><br />The story has a level of ambiguity that cannot escape the viewer. Treating the period that immediately followed the second world war not in the black and white colors of victors and vanquished, of executioners and victims but as rather ambiguous times when people of both sides were fighting for survival in the aftermath of a catastrophic event that change the lives of nations and individuals forever is still a source of disputes even today, more such was novel and courageous two decades ago. Yet it is the means of expression that really do not appear fit to the task.<br /><br />The film seems to include a lot of quotes descending directly from the films of Hitchcock, especially his early films set in the pre-war Europe, with brave British spies fighting evil German spies on trains crossing at high speed the continent at dark. The trains were a symbol of the world and its conflicts with all their intensity and dramatism. Here the train also becomes the symbol of the first sparkles of the re-birth of Germany after war, of its might, of its obsession with order and regulation, of punctuality and civility. The characters that populate the train are far from being the classical spy stories good or bad guys. The principal character a young American of German origin coming to post-war Europe willing to be part of a process of help and reconciliation finds himself in an ambiguous world of destruction and corruption, with liberators looking more like oppressive occupiers, with the vanquished not resigned to their fate but rather willing to continue on the path of self-destruction, with love doubtfully mixed with treason.<br /><br />It is yet this classical film treatment that betrays the director in this case. The actions of the characters, especially of Leopold Kessler played by Jean-Marc Barr seem confused, and lack credibility. The overall cinematography seems to be not Hitchcock-like but rather from a bad imitation of Hitchcock in the late 30s. The usage of color over the black-and-white film used in the majority of the time in moments of emotional intensity is also too demonstrative. It is not that Van Trier does not master his artistic means, but he is too demonstrative, he seems to try too hard to show what a great filmmaker he is. He really is great, as he will show in some of his later films, but it will be left to the viewers to decide this alone.\",\n",
              "         b\"This is one of the worst action films I have ever seen. This is particularly due to much of the factual implausibility (like an obvious agent posing as a bank loan officer while making obvious that he is speaking to someone through a wire or the scene where the scientists assume it is safe to enter a room in which a virus has been released even though 'it has not found a viable host' does not mean that it will never find one), the cheap sets (the bank looks like it was poorly constructed to resemble a dungeon), and the bad acting. It is the story of an organized crime group that has successfully stolen a capsule of the lethal virus. However, the head honcho who decides to remove it from a bank security deposit box, does so at the same time a bank heist is going down, at the same FBI agents have been informed of this, and at the same time a terrible earthquake erupts. Needless to say, the aftermath of the quake is messy in more ways than one. However, the results do not make for an enticing action film, but instead, one that has been obviously z-grade junk from the beginning of the film. (Perhaps this is why some of the screen captures on the packaging look to be created with computer graphics rather than being actual screen captures from various sequences of the film). What the hell Ron Perlman was doing in this, I have no idea. I wonder if he was as embarrassed to be in it as I was to have watched it.\",\n",
              "         b\"Home Room deals with a Columbine-like high-school shooting but rather than hashing over the occurrence itself the film portrays the aftermath and what happened to the survivors, their trauma, guilt and denial.<br /><br />*Spoilers* The shooting itself is treated as a foregone conclusion, with no action footage other than the reaction of an almost teenage SWAT commando after shooting the high school killer. The film has three protagonists; the detective investigating the crime of which no guilty parties are left to convict and two teenage girls surviving the incident, played by a very young Erika Christensen and Busy Philipps.<br /><br />The two girls having nothing in common besides the shooting are put together because of it and the drama ensues.<br /><br />Erika Christensen, though only 24 has been around the block so much that film viewers are pretty much acquainted with her solid and reliable style of acting. Busy Philipps, three years older than Christensen and altogether unknown to me, blew me away with her overwhelming dramatic strength and screen presence. This girl was the part.<br /><br />It's a great movie and it connects to you with its intimate focus on the fragile yet growing relationship between the two traumatized girls. Gus van Sant's Elephant (2003) though good, seems almost superficial and paltry compared to Home Room when it comes to dramatic flair and acting. What I can see this film got very little screen time and exposure - so much more a loss for an equally traumatized America.<br /><br />Ten out of Ten\",\n",
              "         b'This anime seriously rocked my socks. When the anime first opened itself, I felt it was too slow; the story wasn\\'t quite moving forward, and Shirou was quite an unimpressive male lead. Once he learns more about tracing, and you learn more about Saber and the Holy Grail War itself, the story pans out and you can see multiple facets of it moving together. It was fantastic.<br /><br />Additionally, I felt that the way the characters developed was very true to form with the way real people develop, in the real world. There wasn\\'t any stupid completely obvious things going on; the development of Ilya and Rin was interesting to watch, but I think the way Shirou and Saber grew in their certain personalities was just interesting to watch all on its on. A few of the \"surprise\" people that show up (Gilgamesh?) seemed to also be unique from the rest of the cast in one way or another, meaning we didn\\'t have \"Generic Bad-ass A\" being replaced by \"Generic Bad-ass B\" as soon as A died.<br /><br />Anddd, I loved the music. The opening music rocked, and the finishing theme from the final episode just...Seriously pushed forward the theme of the last episode even more. Good job, Type-MOON!',\n",
              "         b'PRC which was the lowest of the low actually struck gold with this moody little thriller. They did the same thing a year earlier with \"Detour\" which is probably one of the finest low-budget films ever made.<br /><br />\"Strangler\" is basically a one set film, filled with mist and shadows, a technique used by most poverty row studios to hide the sets, or lack thereof. But here, it works well. The ghost of Charles Middleton (better known as Ming the Merciless) lurches around the swamp killing those involved in his wrongful execution for murder and generates some sympathy from the viewer. His final victim is to be the daughter of the ferryman.....he concentrates his wrath not only on those directly involved in his fate but their relatives as well.<br /><br />Rosemary LaPlanche does her usual imitation of someone in a coma that passes for her acting style. She offers herself up to the strangler in order to put a stop to the killing but as a sop to the audience, the strangler sees the goodness of her gesture as a sign that his mission is complete and he returns to the hereafter, somewhat chastened. If Ulmer(who directed \"Detour\") has directed \"Strangler\" she would be hanging from the nearest tree and the strangler\\'s job would be done. But who\\'s complaining? It\\'s not the story that is the major attraction but the shrouded sets, lighting and the general moodiness of the piece. It stands, right behind \"Detour\", as PRC\\'s finest hour',\n",
              "         b'This is a top finnish film this year,although Tango Kabaree comes close.The Director Lampela made couple of years back another nice little film called Rakastin ep\\xc3\\xa4toivoista naista (I was in love with a desperate woman).Joki is truly true-to-life beautiful film of one saturday afternoon in a little village/town.The actors are maybe not so handsome or beautiful but they do act beautifully.I certainly do hope that many of them get JUSSI statue (finnish OSCAR) next spring.I think this film could make it abroad as well.',\n",
              "         b\"I thought the movie (especially the plot) needs a lot of work. The elements of the movie remains westernized and untrue to the attempt of trying to produce an eastern feel in the movie. I'll give three out of many of the flaws of the movie:<br /><br />First, when Shen told Wendy that he would help her study the history of China, I was really happy that the audience would receive some information about Chinese history; but it turns out that the movie did not exactly show Wendy actually studying Chinese history; yet instead, the movie only shows Wendy practicing the method of remembering what she had studied, which frustrated and put me in dismay.<br /><br />Second, which really bothered me, is how the characters kept mentioning about moon cakes -- moon cakes this and moon cakes that and how good it tastes. Yet they didn't really mention the real significance of it. The only they they talked about that had any relevance to the moon cake was the Autumn Festival, which they did not explain or go in depth. They could have mentioned the myth that correlates with the moon cake -- the Moon Lady. The myth starts of with how there once exists ten suns and each would rotate rising, but one day all ten suns rose up, drying up the land with the rising intense heat; so the Divine Archer, Hou Yi, shot nine of the ten suns, leaving only one sun (there are different versions where the Hou Yi shot the eight out of nine suns). Because of his heroic contribution, he was given the pill of immortality so he could live on forever in case the ten suns do rise up again, but his wife, Chang-O stole it. After stealing it, she fled to the moon, where she met a hare. She then came upon an idea and told the hare to pound the pill into many piece so she could spread the pill all over earth, giving everyone immortality. (There are a few variations of this story but throughout my childhood, I, most of the time, heard about this version). I thought details such as this would make the plot more culturally Chinese oriented.<br /><br />The last thing I would point out is the last battle scene of the movie. The teachers that were possessed by the monks were fighting the Terra-cotta Warriors (the life-like statues of the soldiers) went against the idea of how important Chinese history is to the Chinese. The Terra-cotta Warrors serves as a connection of China's past and it was very westernized (where evil must be killed in anyway possible) that the monks in the movies were willing to destroy that connection. It would be understandable if Wendy, considering she is Chinese-American and doesn't have full Chinese knowledge, had no problem destroying these priceless artifacts.<br /><br />The whole movie was westernized because it seemed that all the monks and Shen want to do is fight... I mean, it's rated TVPG due to violence, which goes against the Confucius thinking of cooperation and harmony. It would seem more accurate that the monks try to avoid violence and try to work things out peacefully before having to resort to violence.<br /><br />All in all, all of or either of the producer, writer, or director did not do their research thoroughly and did a messy and effortless job instead. I would suggest that they either stop airing this movie or that they re-shoot the movie so it contains more accurate information; however, I would give it credit (2 stars) for removing one stereotype of Asians and Asian-Americans of being smart and quiet.\",\n",
              "         b'A collection of Deleted scenes and alternative takes, edited together and with added voice-over to make it appear to take place after the events of the first. Pretty cool idea, but deleted scenes are left on the cutting room floor for a reason and this is further proof. As it\\'s just not as funny as \"Anchorman\", and really let\\'s face it THAT film wasn\\'t exactly comedy gold either, so you get a \\'movie\\' worse than one that was moderately funny. In my eyes that STILL puts it one or two notches above \"Kicking and Screaming\", or \"Bewitched\". Chross your fingers that \"The Wedding Crashers\" is a return to old school form (no pun intended) <br /><br />My Grade: D',\n",
              "         b\"When I first saw the trailer for Prom Night, I have to admit, the trailer looked good and like this would be a fun horror movie. So my friend and I saw Prom Night last night and I have to say I must be growing up because this was such a ridicules film, not to mention I am so sick and tired of the typical horror slasher movies with the loud noises as an excuse to scare people. There was no tension, the characters, how was I supposed to care about them? They had no development what-so-ever, the killer?! Oh, my God, this was very possibly the most stupid serial killer that has ever existed, I know it's a film, but why would a man who never(or at least we know of) killed any one before, kill a girl's family and friends that he's just obsessed over? I mean, was he going to kidnap her or was he going to kill her? I have no idea, because this film made no sense and is too predictable and insulting to true fans of horror.<br /><br />Donna's family was just brutally murdered by her teacher, who has become very obsessed over her, he was captured and put in jail. It's been 3 years and she's just now getting some peace in her life, she's even going to her senior prom. But the killer has escaped and still has Donna on his mind, he follows her to her prom which means bad news for her friends, and the hotel maid, and the bell boy, because it is such a good idea to kill the maid and bell boy so no one become suspicious enough to check to see where these employee's are. Donna is in big trouble because also this killer who is clearly human can apparently get into houses un-noticed and can kill people so silently, just, wow.<br /><br />I'm sorry, I really did want to love this movie, we haven't had a good slasher flick in a long time, but this was just a stupid movie that I was not impressed with. Just the situations were unbelievable and the actors were obnoxious. I know that this was a PG-13 movie, but I just love how someone was brutally stabbed to death and they only have just a little blood on their clothes? Not to mention no stab holes? I wouldn't recommend this movie for anyone unless you're a teen, this movie was made for the teenagers, not adults, and not for those who know a real horror movie, no offense to those who did enjoy this film, but I don't understand how anyone could.<br /><br />2/10\",\n",
              "         b\"I grew up watching the original Disney Cinderella, and have always loved it so much that the tape is a little worn.<br /><br />Accordingly, I was excited to see that Cinderella 2 was coming on TV and I would be able to see it.<br /><br />I should have known better.<br /><br />This movie joins the club of movie sequels that should have just been left alone. It holds absolutely NONE of the originals super charm! It seems, to me, quite rough, and almost brutal, right from the (don't)Sing-a-longs to the characterization.<br /><br />While I remember the character's telling a story through a song, this film's soundtrack was laid over the top, and didn't seem to fit. Jaq's transformation into a human is a prime example: Where he was walking around eating an apple and adding a few little quips in here and there, he should have been dancing around and singing about how great it was to be tall! And in the ballroom, there's old barn dance type country music. It's as though the writers forgot where and when this story was set. The upbeat fiddles certainly didn't fit.<br /><br />Even the artwork and animation in Cinderella 2 isn't up to scratch with the original. The artwork in this film seems quite raw and less detailed. And we see part of Cinderella's hoop skirt, which doesn't feel right.<br /><br />The movie itself could have been it's own story, I think that it should have been just that. I wouldn't say that I hate it, but I believe that it had many shortcomings. It seems to downgrade in a significant way from the beloved Cinderella original.\",\n",
              "         b'Carla is a secretary who is essentially deaf without her hearing aids. When she finds herself overloaded at work, she is able to hire Paul to help her out. Paul is just out of jail, and his past is not entirely behind him. To say too much more about the story, which has many twists, would be a mistake.<br /><br />The most interesting thing about this film for me is how sound is used to indicate when Carla can hear and when she can\\'t -- a sort of \"point of hear\" (like point of view). The early scenes that set this up, as well as the early character development of Carla and Paul, was more interesting to me than the twists and turns later on, some of which were hard to follow and/or stretched credibility a bit. There is also some unpleasant violence. Back to the positive side, the cinematography was very good.<br /><br />The film is worth seeing, but perhaps not seeking out. Seen at the San Francisco International Film Festival on 4/28/2002.',\n",
              "         b'This movie really woke me up, like it wakes up the main male character of this bravely different movie from his life slumber.<br /><br />This guy John (Ben Chaplin) leads his mediocre safe life of a bank teller in a small provincial English town, until the stunningly gorgeous, wild, girl-to-die-for Nadia (Nicole Kidman), ordered by email from Russia, enters his life to become his beloved wife, by Johns plan. However a glitch turns up - Nadia does not speak a word of Johns language. Although calm and emotionless on the outside, John becomes so interested in beautiful Nadia that instead of using the full refund policy of the matching service, he buys her a dictionary to start the communication process.<br /><br />What happens henceforth in the plot really shakes poor John from his slumber of a decently-paid safe-feeling clerk into a decision-making decently thinking action figure, giving the viewer a subliminal message \"you would have probably acted likewise\".<br /><br />Kidman, Cassel & Kassovitz make a great team acting Russians and they are almost indistinguishable from the real thing, \"almost\" only due to the slight accent present in their Russian dialogues, however slight enough to amaze a native Russian by the hard work done to get the words sound right. Nicole Kidman proves her talent once again by playing a character quite different from the previous roles, at least from the cultural background.<br /><br />The pace of the film is fast and captivating, and you certainly are not ready to quit watching when the end titles appear, you rather feel that you\\'re in the middle of the plot, and are left with a desire to see the sequel as soon as it comes out.<br /><br />My advice is to go out and get this film immediately and watch it and enjoy. To sum it up, it has an unusual plot, great acting, and ideas below the surface. Like the idea of the \"rude awakening\" from the artificial safe routine life of a wheel in a Society\\'s machine, the life which members of the Fight Club were so keen to quit and the machine of which Pink Floyd sings (\"Welcome to the machine!\"). I bet that in the end, John was rather off with Sophia on their way to the unknown than not having met her at all.<br /><br />Thank you, writers, for the great story, and everyone else for this great movie! Please make a sequel! And you can stage it whereever and name the location whatever, because the authenticity of the place is irrelevant to the 99.9999 percent of the potential viewers, I am sure of it.',\n",
              "         b'This is an anti-Serb propaganda film made for TV.<br /><br />\"The Muslims are good; the Orthodox Christian Serbs are BAD.\" <br /><br />That\\'s the message.<br /><br />Using \"entertainment\" to get across a propaganda message is nothing new.<br /><br />This movie lays it on thick.<br /><br />And apparently many viewers and reviewer lap it up.<br /><br />I know better.<br /><br />The Serbs, under General Draza Milhalovitch and his Chetniks, saved over 500 shot-down US fliers from the Germans in World War II.<br /><br />Churchill decided to betray Milhalovitch and put British backing behind communist Tito. Roosevelt followed suit and as a result, after the war ended Yugoslavia was delivered over to communist Tito.<br /><br />And US ally Milhalovitch has been smeared by the media ever since.<br /><br />This movie is part of the anti-Serb propaganda campaign engineered by George Soros and his International Crisis Group (ICG) which culminated in the Kosovo \"War,\" in which Serbia was bombed by NATO because of totally false claims by the ICG of \"mass graves\" in Kosovo filled with \"victims\" of the nasty Serbs. The fact that there were no such mass graves and the Albanians (Muslims) had no business being in Serbia\\'s Kosovo are facts that most of the media won\\'t print.<br /><br />I chose this movie to watch because the one-sentence description on the video cover looked interesting.<br /><br />Imagine my disgust when I discovered I had been fooled into renting another branch of the propaganda machine aimed at Serbia.<br /><br />Instead of this propaganda someone should make a movie about the unwillingness of the Clinton Administration to come clean with the Congress and with the American people about its complicity in the delivery of weapons from Iran to the Muslim government in Sarajevo.<br /><br />I won\\'t hold my breath waiting for such a movie.',\n",
              "         b\"But the fun is in the journey.<br /><br />I found this movie to be extremely enjoyable, not only are both leads extremely easy on the eyes, the humor from the supporting cast and the jokes actually made me laugh out loud several times.<br /><br />Yes, it's predictable, and yes, it's a clich\\xc3\\xa9 romantic comedy. But the point is that it's a sweet story, the message about finding your one true love also rings true in many ways.<br /><br />The dialog is dead-on and the acting is well done on all parts, and over the top for comic effect. The Bulgari scene is worth it's weight in gold, the actress there deserves honorable mention! For those that panned it for being predictable - If you want a film with twists and turns that keep you guessing... then you want a thriller. This is a romantic comedy... it touched my heart and made me realize that I was lucky enough to find my true love in life, and it has been worth every effort along the way.<br /><br />Great date movie, great movie for a happy cry...\",\n",
              "         b'Riding Giants is a brilliant documentary that dives deep into the world of one of the most under-appreciated sports and brings to the surface a very human and raw emotion that only director Stacy Peralta could capture. Everything from the structure, to the players, to the amazing stock footage, to even the style in which this was filmed only reinforced the beauty and power behind the sport of surfing. Of all the surfing films that I have seen (Endless Summer, Billabong Odyssey, and Step Into Liquid) this was the most consistent and relevant. Beginning with the early ages of surfing (a brief history lesson) lasting all the way till Laird\\'s infamous ride, Riding Giants goes further into the mind, heart, and soul of the sport than any of these other documentaries. How does it do this? By giving us the whole story, from start to finish, without fictionalizing or jig jagging from wave to wave.<br /><br />To begin this film was structurally sound. In the other films that I have seen about surfing, you sometimes find yourself jumping from new person to new person, wave to wave, event to event, without any knowledge of why or who? In Riding Giants, we have a very small cast of veterans and newbies. This allows you to really go deeper into the mind of each one. Also, instead of just riding waves, we are handed more history and more personal insight to the world than before. This is what really attracted me to this film. I was impressed that instead of showing all these big waves (because it is a big wave movie), we listen to stories and see first hand what these surfers had to overcome to get to those waves. I loved the information about the \"beach bums\" or father\\'s of surfing. I am still floored by the amazing tales of Greg Noll and his early adventures into the harsh deep blue. Then, to see him in person, talking about what was going on in his mind, only added more fuel to the fire. The straightforward structure that Peralta followed allowed me to follow and walk away with more knowledge of the sport than with any of the earlier films. Peralta shows so much emotion and passion that you cannot help but be amazed by what these brave people have done, and where the sport is going.<br /><br />Add to a immaculate structure some intense and creative cinematography, and you have darn near perfect film. Using techniques that I last saw in The Kid Stays in the Picture, Riding Giants creates some scenes that almost feel as if they are jumping out of the screen. While it isn\\'t 3D, it is that flat dimensional feeling that you get when you put two pictures on top of each other. In this film, it worked. It created more depth to the scenes, and really added to not just the shock value (man these waves were huge), but also the danger that these guys constantly faced. If it broke differently or they maneuvered wrong, these waves would kill them. Some did die, but it didn\\'t stop the sport. It only created more excitement and more passion to do better. It is this love of the ocean and sport that leads me to my final point.<br /><br />The human element. So many of my earlier adventures in the world of surfing documentaries left me with beautiful waves, but very little about the people. The films knew that people were watching for the waves, so it would basically go from wave to wave to wave and the maybe a short second about the person. This film was the direct opposite. Peralta created this masterpiece by still giving us the waves, but devoting so much more attention onto the surfers and the immortal question of why they do this everyday. What rushes through their minds, what pushes them to go further, and the bonds that are formed while out there on the wild blue yonder. I felt like after watching this film that I not only knew more about big wave surfing, but also about the emotional side to the sport. This was an element not as developed in the other films and pushed Riding Giants to a whole new personal level.<br /><br />Overall, this film was brilliant. Never have I witnessed so much passion, devotion, and love wrapped in a structurally sound film. From beginning to end, I was impressed. I would be very happy if this film won the Oscar this year for Best Documentary, and to see a new rebirth in the surfing world and open more doors for films of this nature.<br /><br />Grade: ***** out of *****',\n",
              "         b\"I saw this film at the 2005 Toronto International Film Festival. Based on a novella by science- fiction author Brian Aldiss, this film attempts to tell the story of Tom and Barry Howe, conjoined twins who are plucked from their family by an impresario in order to form a rock band.<br /><br />Almost deliberately gimmicky, the film is also too clever by half (if you'll pardon the pun). By mixing genres, styles and moods, the directors (whose previous film was the excellent documentary Lost In La Mancha) lose their way pretty quickly. I was never sure whether I was meant to take it all seriously or not. Flashbacks, dream sequences, it was all just a bit much. Plus, the promised rock and roll just didn't move me. I was reminded a bit too much at times of Hedwig and the Angry Inch, a film I found original and moving. But in this case, the songs just weren't as good, nor were the main characters sympathetic. A more unfavourable comparison would be the similarly disappointing Velvet Goldmine.\",\n",
              "         b'I don\\'t watch a lot of TV, except for The Office, Weeds, Entourage and E!\\'s Soup. I think I hold this show in good company.<br /><br />I love the scathing review of pop culture that this show gives. Soup also helps me stay on top of what people in the office are referring to when talking about a Sanjaya or Heidi Montag (sp?).<br /><br />The best part is that Soup shows clips of the highlights of these shows, which are usually the funniest or most controversial moments (c\\'mon, most people get hooked into watching American Idol because of the freak show that are the auditions), which is why most people claim to watch. And that means, I don\\'t have to suffer through the other 98% of these mind numbing talk shows or \"reality\" shows, for one nugget of \"funny\" or \"shock.\" The only reason why Soup doesn\\'t get a 10 in my opinion are sometime the sketches are not that funny, and on an even rarer occasion, the commentary isn\\'t always up to par. But they can\\'t all be home runs either, if so, Soup wouldn\\'t be on E!.<br /><br />Joel\\'s quick wit and Soup\\'s writing team (which includes McHale) make for a great show. I happen to enjoy the laughing and comments from the crew who are off-camera. Even when they\\'re being blatantly obvious by giving occasional courtesy laughs, it\\'s hilarious because it IS forced. They\\'re obviously being ironic. And that\\'s part of what makes this show funny.',\n",
              "         b'I notice the DVD version seems to have missing scenes or lines between the posting of the FRF and the launch. <br /><br />They are to prove they can win the right to sit in the FRF other than the green team.<br /><br />Another scene is like during their failure at the simulation, Kevin gets Joaquin to clam down.<br /><br />I think the VHS edition other than the ABC one might have all the missing stuff.<br /><br />Otherwise I like to know which DVD release has the missing stuff.<br /><br />The DVD I have watched feels edited for television.',\n",
              "         b\"Goodnight, Mister Tom begins in an impossibly exquisite village in the south of England where the sun always seems to shine. Before we have much idea of the period we hear a radio announcement of the declaration of World War II. Soon a train blowing clouds of steam brings refugee children from London and when shy little William is billeted with reluctant, gruff old Tom (who you just know will turn out to have a heart of gold) our tale begins.<br /><br />And what a load of sentimental claptrap it is. In fact it's just the old odd-couple buddy formula. Aren't any new stories being written?<br /><br />As I suggested there's hardly any period feel in the village and not much more in London apart from the odd old ambulance rattling around. And certainly no hint of the horror of the Blitz as London's citizens file politely into air-raid shelters. Even when the local schoolteacher's husband is declared missing presumed killed, he is later restored to life.<br /><br />I found `Goodnight, Mister Tom' cliched and obvious and John Thaw's accent conjured up a picture of Ronnie Barker of the Two Ronnies with a straw in his mouth doing his `country bumpkin' accent.<br /><br />Incidentally my wife enjoyed this movie for all the reasons that I disliked it and looking at fellow-imdb reviewers I seem to be in a minority of one.<br /><br />\",\n",
              "         b'Once big action star who fell off the face of the earth ends up in a small town with a problem with drug dealers and a dead body of a federal agent. Reuniting with some former co-stars to clean up the town.<br /><br />Low key, often to the point of blandness, \"action\" comedy mostly just doesn\\'t work. Part of the problem is the casting Chris Klien as a former action hero. he\\'s not bad, but he\\'s really not believable as some one who was taken to be a tough guy. As I said he\\'s not bad, he\\'s just just miscast for what his back story is. The real problem here is the combination of the script, which really isn\\'t funny and seems artificial at times, and the direction which is pedestrian to the port of dullness. There is no life in the way things are set up. Its as if the director had a list of shots and went by that list. It makes for an un-engaging film. And yet the film occasionally springs to life, such as the in the final show down that ends the film. That sequence works, but because the earlier parts of the film floundered its drained of much of its power.<br /><br />I can\\'t really recommend the film. Its worth a shot if you\\'re a fan of the actors or are a huge fan of independent cinema in all its forms, but otherwise this is just a disappointment.',\n",
              "         b'I really enjoyed the reunion a lot! I would have rated it a 10 if they had had \"Hassie\" and \"Little Luke\". There wasn\\'t even a mention of where they are today or why they didn\\'t participate in the reunion. They were very popular characters and I think it was a mistake not to give an explanation about their lack of appearance.<br /><br />Anyway, I was glad that TNN ran the series again! I had been looking for episodes for years and what a joy to be able to tape the whole series (I may have missed a few episodes). Jenny Hanahan',\n",
              "         b'This is a movie that relies solely on the somewhat controversial image of incest and lesbianism to get noticed.That is it.The dialogs are pathetic and the sensuality of the \"sex scenes\" is absolutely absent.The acting and the dialog are more suited for high-school children,yet the subject is intended for adult audiences. It is a gutless and shallow movie.It could have been way better if it had a story and more drama. Ah and on top of that, one more thing: why are inner monologues so excessively used? Makes it seem so cheap.All in all an embarrassing movie for Romanian cinema as well as for mature audiences attempting to view it.I know the means are scarce but, that is not always an excuse for a movie flopping as this one does.And please start using some good actors in your movies and stop recycling them from musicians (Tudor Chirila) - they can\\'t act!',\n",
              "         b\"I enjoy quality crapness, and this ranks up there with some of the finest. the cg is out of this world, or at least pre-dates our world, and the insanity of a 6 foot bloke in a rat outfit chasing after people is laughably bad. I quite enjoyed some of this, but the acting is so goddamn awful, and even the obligatory nude scene doesn't really have any baps out in it. just a complete waste of time if ever i saw one. I don't know who wasted more time, me watching this, or the poor saps who got dragged into making it in the faint hope that this will launch their acting careers. I can assure you, it wont. However, on a brighter note, I have managed to successfully do the 6 degrees of Kevin Bacon from this movie, so I think it was almost worthwhile watching the 91 minutes of it.\",\n",
              "         b\"I don't understand why the other comments focus on McConaughey. He has never been a very interesting film actor. <br /><br />The best part of this movie is the writing and the wit. Alfred Molina and Patrick McGaw make an unusual comic duo, definitely not stock types. Although one can't say their characters are well developed that doesn't make them any less funny.<br /><br />The version I saw was on HDNET and had subtitles for the Spanish dialog, so that was certainly not a problem. The use of Spanish gives it more authenticity. <br /><br />A very underrated movie, judging by the unusually low score IMDb members have given it. I thought it was fun and interesting and worth a 7 at least. A lot of slick movies with higher scores and making big money at the box office are much less interesting.\",\n",
              "         b'I do not watch much television and came across this show. Reality show? I sure hope this is not for real. If I was a man and had such a nag and was married to someone so snotty, It would be grounds for divorce. I think she sets a bad example of how a person should treat a person they love. That is one thing that is wrong with our world now, so many people in bad relationships, selfish and do not know the meaning of what it is to truly love another. It is self sacrificing and not something that should be on merritt. That does not give one a very good feeling, to watch what should be in private counseling. If his personality on the show is for real, then he deserves someone much better that would show real true love and care for him and appreciate him for who he is. Is this show a reality or made up for ratings???? I really would like to know. Sincerely, GB',\n",
              "         b'This film has to be viewed in the right frame of mind. First, the central father-son relationship makes it pretty clear that the film was intended as a prequel to his Wong Fei Hung film \"Drunken Master\" (ideas from this film recur in \"Drunken Master II), and not \"Young Master\"; that Chan backed away from this plan and renamed the characters indicates that he himself was not convinced the material was coming together properly; and, indeed, the film conveys a sense of being incomplete; for instance, the romantic relationship around which half the plot turns is left utterly hanging at the end of the film. \"Young Master\", from the same period, also feels underdone, but at least all its central threads are tied together at the end. This film feels as though Chan wrestled with the plot and characters trying to find his central theme, only to abandon the effort, possibly due to time and budget.<br /><br />Or perhaps the film is simply over-ambitious. This is an important turning point film in Chan\\'s career, because he commits himself to development of the central character above all other concerns - which is why there\\'s such a lack of kung fu throughout the film. Chan wants to make an historical romantic comedy that just happens to have kung fu in it. But both the historical element and the romantic element come across as little more than plot-twists.<br /><br />That leaves us with the comedy. Since Chan\\'s concern is character-development, the comedy is largely character driven - as in the conflict between Chan\\'s character and his best friend, an argument over a girl. But there\\'s plenty of slapstick as well. Frankly, I find the comedy amusing enough to forgive the incompleteness of the plot.<br /><br />This film represents an effort on Chan\\'s part to find a viable formula that he can use and develop over time. It doesn\\'t quite work, and Chan would only find that formula after abandoning the historical elements of his earlier films, with the making of the contemporary action comedy \"Police Story\". But going back to view this film is still very informative as to how Chan worked his way through the historical genre, and perhaps why he abandoned it.'],\n",
              "        dtype=object)>,\n",
              "  <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              "  array([0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n",
              "         1, 1, 0, 0, 1, 0, 0, 1, 0, 1])>),\n",
              " (<tf.Tensor: shape=(32,), dtype=string, numpy=\n",
              "  array([b'I was so disappointed by this show. After hearing and reading all the hoopla about it, how it was a \"ground breaking show\" and all sorts of wild promises if quality, I tried to watch it.<br /><br />What a letdown!! The acting was way forced and exaggerated. The story made very little sense. As for any hint of the vaunted \"look into teenagers\\' lives\", I could only see a paltry attempt that had as much reality to it as a reality show.<br /><br />Some are wondering why there are so many negative comments about this show. The reason is that it\\'s really not all that good and beating the drums over quality on this show only serves to attract attention to how poorly made it is.',\n",
              "         b'John Van Druten\\'s \"Bell, Book and Candle\" is a delightful and unexpected fantasy about a coven of modern-day witches living in New York City; it was obviously an attractive movie property. It had a stellar part for Gillian Holroyd, for her erstwhile book publisher enforced-sweetheart, Shepherd Henderson and her madcap family and circle, including Shep\\'s bewildered fianc\\xc3\\xa9e, the hateful Merle Kittredge, against whose chances with Shep Gillian begins her magical spell-casting. It even had Pyewacket, a Siamese cat-familiar with well-timed miaows, Sidney Redlitch, a fake witch expert with atrocious pretensions and bad manners. In short, it seemed to its producer, perhaps, box-office magic. And so it proved to be. So many things were right about its production, it only had one element not perfect; but I found the rest to be amusing, charming and very consistently-entertaining. To begin with, the screenplay by Daniel Taradash kept the best qualities of the fine theatrical play but opened out its scenes to include Greenwich Village and other areas of New York\\'s scene. The technical production was beautiful, with cinematography by the legendary James Wong Howe, a fine score by George Duning, more-than-clever sets by Louis Diage and gowns by Jean Louis. In the attractive cast were Wolfe Barzell, Howard McNear, Janice Rule as Merle, Ernie Kovacs as Redlitch, Jack Lemmon as Gillia\\'s mischievous brother, wonderful comediennes Elsa Lanchester and Hermione Gingold as fellow witches and lovely Kim Novak in one of her most touching parts as Gillian. Jimmy Stewart was the imperfect element in my judgment; he did well with the comedic portions of his part, but he was never convincing as a New York book publisher, and a bit too-old for the part of Henderson anyhow. But director Richard Quine used subtle lighting, pace changes, and unusually-composed shots to indicate the oddness of the witch portions of the film, keeping the other portions very luminous but straightforward in their presentation. The plot\\'s main crisis in the film comes to pass when in reality Gillian falls for Henderson, who does not believe in witches at all. She started out merely to alienate him from his fianc\\xc3\\xa9e, her stuck-up college rival. Later, when Henderson tries to walk out, he keeps coming back to her--and realizes he is under a spell, as she has apologetically tried to explain to him. ..Meanwhile, Sidney Redlich has been summoned by witching spell to come to New York to sell his book to Henderson. Of course he knows nothing at all of magic, but is quite puzzled and interested to find out why he had come anywhere at all; but Gillian\\'s brother enlightens him. All comes out right in the end in this romantic satire as Gillian proves her love to Henderson by losing her powers--which is what happens to witches when they truly love a mortal. Of course, he never really wanted to resist her anyhow. The film has sprightly dialogue, charm, and a little \"magic\" of its own in the fey charm of the witches and the torments Gillian must undergo in her battle with herself, and to win the man she loves. A lovely ending to this beautifully-photographed and unusual romance makes its amazing realism, though a fantasy, just about complete in my view. Memorably delightful.',\n",
              "         b'I am usually disappointed by network movies. Even flix that attract big name actors are usually ruined by the TV people. However, this one is the worst of the worst. The screenplay is weak and the acting, especially that of Tracey Pollan is abominable. I\\'ve trudged off to see my kids\\'high school plays and been treated to better acting. Pollan acts as if she is reading the script as she speaks. When she tries to express fear, anger or grief, it\\'s extremely hollow. Because of the overall quality of the production I found it difficult to take it seriously. If you decide to brave this one just be prepared for a big disappointment. Scary things won\\'t scare you, sad things won\\'t make you sad, romance won\\'t make you feel warm and fuzzy and you will likely be as anxious as I was to see the end arrive. \"First to die\" says a lot about this movie.',\n",
              "         b'The script was VERY weak w/o enough character arcs to make you care one bit about the characters or what happens to them. The script is way too talky and not enough gore or action to even call it slow paced. The story gets to the point that you just want everyone to shut up and die as quickly as possible so you don\\'t have to listen to them talk this very muted, stiff dialogue. On a technical note, the music mix is way to high and makes it hard to understand what is being said most times. Then again, this could be called a blessing. Overall, this same story could have better been told in a short film w/ a running time under 30 minutes. The obvious \"in your face\" homages to Sam Raimi and \"Evil Dead\" would have been good had they been more subtle, but here they seem more like a bald faced rip off. C\\'mon, this kind of 35mm budget and THIS is the best that could be done? Still, the cinematography, lighting design and shots were very well done indeed.',\n",
              "         b'There are some movies you just know they are going to be bad from frame one. Even if you were totally oblivious of Ed Wood\\'s work, one look at that commentator from \"Plan 9 from outer space\" and you just KNOW you are not gonna see the next cinematic masterpiece. Just like that, when I saw the first shot of Uwe Bolls masterpiece \"House of Dead\", with that guy sitting at the front of the house starting his introduction while trying desperately to sound like he just arrived from Sin City, I knew I\\'m in for a helluva ride.<br /><br />So, the movie starts like this - first the lead character says that everybody else is going to die. You know, to keep you wandering. Then he starts introducing the rest of the characters with lines like \"Karma..thinks she\\'s Foxy Brown\" or \"Alicia..my ex.. we broke up recently.. I had to study and she had to fence\". No, I\\'m not kidding.<br /><br />Anyway, this bunch of 20-somethings who couldn\\'t act their way out of a wet paper-bag are going to the \"Rave of the century\", rave in question being a few tents, a port-a-potty and a shoddy stage located on small island in the middle of the Pacific. Our gang missed the ferry, but thankfully will find a way to get there, the way being a fisher-boat ran by Kirk (Cpt Kirk? Get it? Man, whoever wrote this script is a genius) and his sidekick who is a bastard child of Simpsons\\' Cpt McAllister and that hook killer who knows what you did last summer.<br /><br />To make the long story short, the gang gets to the island, finds nobody there except some bloody T-shirts and then decide to run the hell away from there. No wait, they do not, they actually get all happy and like cos there\\'s free booze.<br /><br />With that scene the movie hits rock bottom and then against all odds proceeds to go further downhill. Some guys in rubber suits start running around, there is some screaming and shooting, our gang goes to some house to meet some other gang, they go out of the house, meet Cpt Kirk and some police woman (who between them have about 500 pounds of weapons) and then decide to go back to the house. Somewhere along the line they transform into a S.W.A.T. team, enter the Matrix, the rubber-suit guys start multiplying like bacteria and I start to cry because I actually paid to see this. To add insult to the injury, every few minutes there are shots from the video game this crap is based on and there is a cute game-over cut-scene for a few characters when they die.<br /><br />I seriously hate this movie. It doesn\\'t even fit in that famed \"So bad it\\'s good\" category. It\\'s just plain bad. The script is bad, the zombies are awful, there is no tension, lines are bad, actors are bad.. the list just goes on.<br /><br />You will probably want to see this movie just because of its reputation of being awful. Don\\'t. There are bad movies that deserve to be watched. This is not one of them.',\n",
              "         b'Probably the finest fantasy film ever made. Sumptuous colour, spectacular sets, incredible, spot-on Miklos Rosza musical score that is perfect for each scene and mood. Acting is superb as well in what could have been stiff and pretentious in lesser hands, but here the poetic dialog is deftly, sensitively spoken (the humour is subtle and delightful as well).<br /><br />Doubtless Spielberg and Lucas were enthralled by this one. Along with \"The Four Feathers\" (1939), one of the two finest motion pictures released by Alexander Korda and London Films---and one of the finest motion pictures ever made.<br /><br />A true, compelling classic!',\n",
              "         b'I thought the movie was actually pretty good. I enjoyed the acting and it moved along well. The director seemed to really grasp the story he was trying to tell. I have to see the big budget one coming out today, obviously they had a lot more money to throw at it but was very watchable. When you see a movie like this for a small budget you have to take that in to account when you are viewing it. There were some things that could of been better but most are budget related. The acting was pretty good the F/X and stunts were well done. A couple of standouts were the guy who played the camera asst. and the boy who played the child. These kind of films have kept LA working and this is one that turned out OK.',\n",
              "         b'Alicianne (Laurel Barnett) becomes a live in babysitter for young Rosalie Nordon (Rosalione Cole) who has recently lost her mother. But Rosalie misses her dead mother a lot and continuously visits her grave (conveniently located in a cemetery right behind the house) late at night...where she also meets her \"friends\"...<br /><br />This starts off good with a truly eerie sequence in the cemetery...then falls apart. The story is thin and there is TONS of padding to make the film 85 minutes long. The acting is terrible across the board (with Cole easily being the worst). Badly directed with some of the WORST editing I\\'ve ever seen in a motion picture. Scenes (and sound) are just cut off with no rhyme or reason. Also the film has terrible (and obvious) post-production sound.<br /><br />As for blood and violence--forget it! There\\'s very little and what there is looks incredibly fake. I\\'ve NEVER seen such fake-looking blood--looks like ketchup! Boring, pointless--a rightfully forgotten drive-in movie. You can skip this one.',\n",
              "         b\"This movie had a good story, but was brought down because it didn't have enough horror film elements and violence. It was like watching a live action cartoon. It would of been better if this story is what they planned from the start of the first movie so they could of played seeds for where the series was going.\",\n",
              "         b\"With a Bo Derek movie, the audience get just what they expect. A paper thin plot and a few shots of Mrs. Derek in no clothes. 'Ghosts can't do it' is just that. The first fifteen minutes is ordinary TV drama, as long as Scott [Anthony Quinn] is still alive. He is a very good actor with long experience in a lot of different roles, but it seems as even a famous actor need to work just for money sometimes. Bo Derek is the opposite, always playing a strikingly handsome young woman with or without clothes. The movie is a complete waste of time. If you want to see Quinn, rent Lawrence of Arabia or La Strada. If you want to see nude women or bad acting, rent any porno movie.\",\n",
              "         b'\"Land of Plenty\" is not a film. It is a tombstone for the directorial career of German Director Wim Wenders.<br /><br />Many felt it in \"The Million Dollar Hotel\" and now \"Land of Plenty\" makes it perfectly clear; not only has Wenders lost it, he\\'s actually turned into a BAD director, creating horribly weak and superficial stories and scenes.<br /><br />One might argue that the \"time you lose it\" comes for every director, but Wenders\\' case is extreme. It\\'s as if he completely forget everything he knew about cinema and started all over again - only to get sloppish results.<br /><br />In a few words, this film does not deserve your time.',\n",
              "         b\"THE BROKEN is part of the After Dark Horrorfest III. Not a slasher or filled with gore. Plenty of broken glass and mirrors in this edgy thriller from France and writer/director Sean Ellis. A successful radiologist Gina McVay(Lena Headly)inters a strange world as her life seems to spiral out of control. While attending her father's(Richard Jenkins)birthday party, the guests are stunned when a mirror crashes to the floor for no obvious reason. Things get really strange when she witnesses a woman that is the spitting image of herself driving down a London street in a car identical to her own. Gina sneaks to her doppelganger's apartment and finds a photo of herself with her father. She drives away and is involved in a head on collision. Then mysteriously her boyfriend is not the same; to be exact family and friends are not easy for her to trust. Is Gina beside herself? Is she in a parallel world? Her nightmares become more horrific...is she broken?<br /><br />Kudos if you can figure this one out...it won't be easy. Editing couldn't be any tighter. Lighting is questionable. Other players: Melvil Poupard, William Armstrong, Michelle Duncan and Ulrich Thomsen.\",\n",
              "         b\"This movie was so terrible it was almost good... almost. We love musicals, but not this one. Even with the terrible sound quality, poor cinematography, and many actors who can't sing or dance, Anthony Rapp actually managed to give a good performance (especially toward the end). The character Marjorie, a drunk lady, was enjoyable to watch, too. <br /><br />The plot is very unexpected and could have been funny without terrible singing and cheezy piano music. Admittadly, some of the songs (fantabulous) are pretty catchy (but not in a good way).<br /><br />Open House is a funny movie to watch simply because it is awful! We think it might be a good stage musical (with excellent actors).\",\n",
              "         b\"The film is side spliting from the outset, Eddie just seems to bring that uniqueness to the stage and makes the most basic thing funny from having an ice cream as a child to the long old tradition of the family get together. The film is very rare in this country but unsure of availability in other countries i have searched through a lot of web sites and still no luck, phoned companies that search for rare videos and there are year waiting lists for it. SO HINTS ARE VERY WELCOME. If any one likes Eddie Murphy as a comedian and see's the video get it,it is worth the money and can't go far wrong.\",\n",
              "         b'\"Horrible People\" ought to be the subtitle of this horrible film. If you want to see ordinary people doing ordinary things, then look out of your window at real life. But if you want to see unpleasant people doing dull things, you\\'ll have to watch this horrible film by Mike Leigh. The characters talk at length, but never actually manage to communicate with each other. Why not? Presumably because Leigh things that all of us are as ineffective and pathetic as his actors, and he wants to film real life. But we\\'re not, and he failed.',\n",
              "         b'I guess that this movie is based on some kind of a true story.... It\\'s about two young girls who molest a grown man for 48hrs.; I don\\'t see where the terror comes into play here.... There are some \"weird\\' and \"surreal\" sequences in the movie. And the two girls (Sandra Locke and...ah...oh well) play the roll of two psycho-man haters to the hilt...they do a pretty good job (although some of it is just a tad over the top). The movie\\'s not good, and it\\'s not horrible; it\\'s just really really dated! I mean this thing is dripping with the 70\\'s.... It\\'s not really bad if you like that sort of thing...you know...that thang?',\n",
              "         b'In celebration of Earth Day Disney has released the film \"Earth\". Stopping far short of any strident message of gloom and doom, we are treated to some excellent footage of animals in their habitats without feeling too bad about ourselves.<br /><br />The stars of the show are a herd of elephants, a family of polar bears and a whale and its calf. The narrative begins at the North Pole and proceeds south until we reach the tropics, all the while being introduced to denizens of the various climatic zones traversed.<br /><br />Global warming is mentioned in while we view the wanderings of polar bear; note is made of the shrinking sea ice islands in more recent years. We never see the bears catch any seals, but the father\\'s desperate search for food leads him to a dangerous solution.<br /><br />The aerial shots of caribou migrating across the tundra is one of the most spectacular wildlife shots I ever saw; it and another of migrating wildfowl are enough to reward the price of admission to see them on the big screen.<br /><br />One of the disappointments I felt was that otherwise terrific shots of great white sharks taking seals were filmed in slow motion. Never do you get the sense of one characteristic of wild animals; their incredible speed. The idea of slowing down the film to convey great quickness I think began with (or at least it\\'s the first I recall seeing) the television show \"Kung Fu\" during the early Seventies.<br /><br />An interesting sidelight is that as the credits roll during the end some demonstrations of the cinematographic techniques employed are revealed. There are enough dramatic, humorous and instructive moments in this movie to make it a solid choice for nature buffs. Perhaps because of some selective editing (sparing us, as it were, from the grisly end of a prey-predator moment) and the fact that this footage had been released in 2007 and is available on DVD it is a solid film in its own right. And you can take your kids!<br /><br />Three stars.',\n",
              "         b\"This movie is by far the worst movie ever made. If you have to create a film costarring the guy who plays Lars in heavyweights than don't make the damn film. I have to say that I could watch Leprechaun in Space 6 times before I could watch the trailer for this POS of a movie. Adam sandler should be restricted from any movie after this disgrace. Watching this movie is like a mix of listening to Cher and willingly putting your dick in a blender. Anyone with half of a brain cell will realize that this movie is not worth a dime. If I had an extra dollar and had to spend it, I'd give it to the support Lorraina Bobbitt foundation before buying this movie.\",\n",
              "         b'Robin Williams does his best to combine comedy and pathos, but comes off a bit shrill. Donald Moffat is too one-note as his father-in-law. Jeff Bridges is excellent though as the quarterback, and Holly Palance and Pamela Reed are marvelous, carrying the film through most of its rough spots. It fills time nicely, but is little more than that.',\n",
              "         b\"It's a really cheesy parody of Tomb Raider and some Indiana Jones, the humor's cheesy, and so is the acting. But after all it is a soft core movie, which is expected and doesn't matter because what you really want is the sex. Which gets me to the biggest problem of all, there barely is any of it. Which makes you feel like you're watching TV at 3 am and the independent movies are playing and the one that is on was made by some college kid that's going nowhere in that industry. You're left a very long time waiting for an actual sex scene, a lot of times you are thinking something is going to happen, then just left hanging. The one(maybe two, or one with two parts)that actually goes somewhere is very pleasing though. I personally can't recommend this unless you found it in a clear out bin for a dollar or two. If you lucking for a good movie with a plot and good acting, you don't want this. If you looking for a good soft core lesbian film, you don't want this either.\",\n",
              "         b'This is hands down the worst movie I can ever remember watching. Everything was unbelievably clich\\xc3\\xa9 and retarded. The acting was horrible too. The camera work wasn\\'t bad but that still couldn\\'t redeem it. The writer/director of this film must suffer from down\\'s syndrome if he believed this movie would help his career. I want the hour and a half of my life back that I wasted watching this crap. I would rather watch a video of the grass growing than this. I cant believe IMDb is making me write 10 lines in order to post this but I feel that this movie is so bad that I must continue to warn others about it. The reason I came about this movie is that my girlfriend requested it from the local library thinking that it was the Kris Kristoferson movie which ended up being entitled \"Disappearances\". I don\\'t know whose fault it was for this garbage ending up in my DVD player but I feel that someone owes me at least $20 for my time, pain and suffering. In conclusion, the director/writer of this movie better hope i ever recognize him on the street.',\n",
              "         b\"I watched this movie purely for the setting. It was filmed in an old hotel that a friend owns shares of. The plot was predictable, the acting was mediorcre at best, the scares were all gross-outs, not true scares.<br /><br />I don't remember much of the plot, and I think that's because there wasn't much of one to remember. They didn't even use the hotel to it's fullest potential...The beaches are fantastic and the hotel is situated on a peninsula. At low tide, you can walk almost 1/4 mile into the bay, which is actually an eerie sight first thing in the morning or late at night when the wind is howling through the cracks.<br /><br />The best way to see this movie is with the remote in your hand so you can fast forward through the action (and I'm using that term loosly)scenes and pause at the beauty of the surroundings!\",\n",
              "         b\"I felt brain dead, I'll tell you. This is the worst film I have ever bought. (in my ignorance I thought this was the Peter Jackson film of the same name). The performances are so terrible they are laughable. The special effects have not stood the test of time and look dire. The script promotes that kind of TV movie, stare into the middle distance kind of acting. The cast look as if they have been taking lessons from Joey Tribbiani, they have one look each, and stick to it. Plus I have never been confused by a movie until I sat down to watch this. The is it a dream or no plot is so terrible that frustration sets in within a few minutes. Avoid like a plague.\",\n",
              "         b'I read reviews on this movie and decided to give it a shot. I\\'m an open minded guy after all and I\\xe2\\x80\\x99ve given good reviews to some pretty bad flicks. As the end credits rolled on this one I searched for meaning and something nice to say. Here goes: \"This film was mercifully short.\" That\\'s all I got.<br /><br />Okay, Okay. The sets and visuals were well done and the music helped lend to the mood of asylum life but the film was painful to watch and the endless dialogue took away from the good bits. I did find myself laughing at this film but the way you laugh at your best friend who just embarrassed himself in front of a large crowd.<br /><br />By the time of the \"chicken dance\" at the finale I had just decided to tuck and roll with the film and let the bodies fall where they fall. I don\\'t know what could have salvaged this film. The acting was not bad and it looked like it had a budget but there just wasn\\'t any way to make it watchable; not even the presence of beautiful bare breasts. Maybe I should have sparked a doobie or drank a LOT of beer to get the full experience of the film. Either way, I\\'m not watching this film again unless I\\'m really depressed. Then I can tell myself \\xe2\\x80\\x9cAt least I wasn\\xe2\\x80\\x99t in \\xe2\\x80\\x98Dr. Tarr\\'s Torture Dungeon.\\xe2\\x80\\x99 I\\xe2\\x80\\x99m better than those guys.\"',\n",
              "         b\"I ordered this extremely rare and highly overrated movie on ebay with very high expectations. I think I paid about 50$ for this movie. As an eternal fan of horror, from cheesy 80s American slashers to European zombie films, I told myself this was going to be great! I can't tell you how wrong I was. First of all, I thought it was gonna be pretty much gorier than it actually is. After all I've had heard about this film, I was almost scared to watch it. The murders are boring. The acting... forget it, there's no acting! The story, even if we don't care, is incredibly bad. It seems they tried to get your attention with some weird sexual scenes and naked girls, but unfortunately in this case it doesn't help the movie. Why? There's no atmosphere, and this is the worst thing about this flick. It's just bad film-making from point A to B. Though it's extremely funny and amusing to watch with your friends and a lot of beers, don't make any effort to get your hands on it. There are so many movies in this world, don't waste your time watching Necro Files!\",\n",
              "         b'COME ON!!! They did that on purpose!! Two of my current faves on TV (Meloni from \"Oz\" and \"L and O-SVU\" and Janel from \"West Wing\") hook up for a nice little sleeper/character study. Plot\\'s nothing fancy, but the acting is right on the mark. Tim Busfield shows up for some neat bits. Worth a look.',\n",
              "         b'Most people (36) gave this movie a 10 and those who don\\'t are being too critical or maybe expected something else. This is one of my favorite movies from the 80\\'s, it grows on you, and has it all. I just got it on DVD and 20 years later it still does not disappoint, having plenty of action, drama, romance, and even comedy. Add to that the great car chases, automatic weapon shootouts and lots of stuff blowing up and you have a fun, edge of your seat experience! You will even be humming or whistling the main theme song for days after seeing this. <br /><br />You can watch this movie with your wife/gf and you will both enjoy it lots. The premise is that of a paperback book hero, like Doc. Savage, really existing and helping people fight evil so he can write the story is almost true to life here. The actor Jake Speed is also a director, producer and writer of many films. In THIS film Jake Speed (the character) is an Indiana Jones adventurer type, he usually uses his head to get out of sticky situations but will sometimes resorts to brute firepower (yay!,and sheer dumb luck too!). Keep an eye out for his one \"James Bond\" hi-tech equipment, the ultimate road warrior SUV dropping out of the sky.<br /><br />The heroine is the very beautiful young love interest from the early Jim Carey vampire movie \"Once Bitten\" and here she is a little older and still a knockout even compared to her teenage blonde little sister.<br /><br />The bad guys are \"real bad\" men and are the worst lowlife villainous scum you love to hate. The ending is just perfect and can stand alone or invite a sequel, sadly never made - but you can just imagine what would happen next!<br /><br />You have to see this movie just because it will entertain and amuse you and that\\'s worth the price of a ticket.',\n",
              "         b'I like films that don\\'t provide the typical \"happy ending,\" and that\\'s my main reason for my liking of this movie. Alice Marano (Danes) and her best friend Darlene (Beckinsale) are arrested in Thailand for narcotics smuggling after a tip anonymously phoned in to the Thai authorities. The film does a solid job of keeping viewers guessing as to whether (or which) of the girls was involved, and Bill Pullman is perfect as their sleazy lawyer. Jacqueline Kim turns in a terrific performance as his more kind, magnanimous wife, Yon, who is also an attorney. I wish the girls had been abused more in the prison, as another commenter has suggested, as I\\'ve heard that Thai prisons can be quite brutal. Where this film grabs me, however, is its ending. Alice subjects herself to a sentence of 96 years in total so that Darlene can be pardoned, and we (the viewers) realize that they are both innocent. Any film that defies my expectation of the ending wins extra points with me, and this well-acted drama is certainly deserving.',\n",
              "         b'This Kiyoshi Kurosawa ghost movie is pretty wild, and it did have at least one jump scare that caught me off guard. But all in all, the movie is incredibly stupid, with a detective trying to track down a suspected serial killer, only to find out he may have committed one of the crimes. Then he finds himself haunted by a gorgeous Asian lady ghost, and has no idea why (and neither does the viewer). As other murders are committed, he becomes even more confused as the killers are easily found, and this ghost still haunts him for some reason. Not only is the plot completely stupid, the lady ghost is more funny than anything, especially when she suddenly flies across the city, like Wonder Woman. And the ending makes little sense, in fact, the whole movie makes little sense, and I can\\'t recommend it at all. If it didn\\'t take itself so serious, I would think it was supposed to be a black comedy. Outside of \"Bright Future\" this is the worst movie directed by Kiyoshi Kurosawa I have seen yet.',\n",
              "         b\"Run away from this movie. Even by B-movie standards this movie is dreadful. It is also insidious in it's theme. The main theme is that people who reject society and have no respect for anything are cool and worth admiring. People who treat others with respect are losers. Guncrazy is a movie that speaks for the disenfranchised a lot better than this movie, see it instead.<br /><br />No normal kid would do what Trent does. State Troopers do not work as they do in this film etc. Seeing this movie makes you realize why writers use the hooker-with-a-heart-of-gold cliche. Mija is a completely unsympathetic hooker,who yes, has had a terrible life. However, she is such a terrible person the audience cannot identify with her.<br /><br />Usually there is one thing a movie can be recommended for, in this case there is none. It is such a ridiculous movie it insults the person who tries to identify with the main characters. The acting is adequate by B-movie standards and the direction presents nothing new or interesting.\",\n",
              "         b\"An unforgettable masterpiece from the creator of The Secret of Nimh and The Land Before Time, this was a very touching bittersweet cartoon. I remember this very well from my childhood, it was funny and sad and very beautiful. Well it starts out a bit dark, a dog who escaped the pound, and gets killed by an old friend, ends up in Heaven, and comes back. But it becomes sweet when he befriends an orphaned girl who can talk to animals. Some scenes were a bit scary contrary to other cartoons, like the dream sequence of Charlie, but everything else was okay,and the songs were fair. A memorable role of Burt Reynolds and Dom DeLuise, I just love that guy, ahehehe. And Judith Barsi of Jaws The Revenge, may God rest her soul, poor girl, she didn't deserve to die, but she is in Heaven now, all good people go to Heaven. Overall this is a very good animated movie, a Don Bluth classic enough to put anime and Disney to shame. Recommended for the whole family. And know this, if you have the original video of this, you'll find after the movie, Dom DeLuise has a very important and special message, gotta love that guy, ahehehe.\",\n",
              "         b'American icon Henry Fonda portrays \"Elegant\" John Howard, an aging trucker who has had his beloved big rig \"Eleanor\" repossessed after a lengthy hospital stay has forced him to miss his payments. Deciding that he would like to make just one more perfect run, he breaks out of the hospital, steals back Eleanor, and hooks up with old friend Penelope Pearson (Eileen Brennan), who is in need of relocating her troupe of prostitutes.<br /><br />Fondas\\' wonderful performance is a natural anchor for a film that tugs at the heartstrings as effectively as it tickles the funny bone in the more comedic scenes. A superb cast including Robert Englund, as a reluctant young sidekick, Susan Sarandon (who also gets co-producer credit), and Dub Taylor (a delightful ham, as always, in the most blatantly comedic portion of the picture) helps immeasurably.<br /><br />The ultimately life-affirming nature of the picture and the poignancy of the journey carry incredible weight; this is a picture, that provided you get into it, you can remember long after it\\'s over.<br /><br />The promise of the open road is vividly displayed here; the countryside just looks beautiful. Set to Craig Safans\\' wonderful music score, it\\'s a remarkable picture in terms of aesthetics.<br /><br />It loses a little something in its final act (the characters played by John Byner and Austin Pendleton are little more than intrusions), but it still maintains its good vibes thanks to the appeal of its central characters.<br /><br />Not at all the exploitation / drive-in schlock picture one might expect from the title (especially its alternate title, \"The Great Smokey Roadblock\"), it\\'s a rewarding movie experience that I can recommend without qualms.<br /><br />9/10'],\n",
              "        dtype=object)>,\n",
              "  <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              "  array([0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
              "         0, 0, 0, 1, 1, 1, 0, 0, 1, 1])>),\n",
              " (<tf.Tensor: shape=(32,), dtype=string, numpy=\n",
              "  array([b\"This movie is so bad it hurts. The car doing 30 mph when it's supposed to go 100... the shift lever that's stuck (in Park!), the nurse that drives for almost 2 hours with the cell phone on the shoulder...can't any of the 2 morons take this damn phone? There's nothing credible in this crap. I would be ashamed to be seen in a movie like this!\",\n",
              "         b\"The comic banter between William Powell and Jean Arthur is the highlight of this murder mystery, which has one of the most bizarre and unlikely plots ever. Powell is probably the most suave detective of the 30's, and Arthur has a unique voice which often sounds like a succession of tiny tinkly bells. They are extremely fun to watch, so take the brashness of the plot with a grain of salt and just enjoy seeing it unfold. Eric Blore also has some comic turns as Powell's butler.<br /><br />Powell's contract with MGM included a clause which allowed him to reject being loaned out to another studio, but he wanted to work again with Arthur and he liked the script, so he eagerly accepted the assignment. They had worked together in two 1929 Paramount films, The Canary Murder Case and The Greene Murder Case, both in the Philo Vance series.\",\n",
              "         b\"Cat Soup at first seems to be a very random animated film. The best way I've been able to explain it is that it's quite acidic. Though it's not totally random. The story is about Nyatta, a young cat boy and his sister Nyaako. Nyaako is very ill and dies, however, Nyatta sees her soul being taken away by death and is able to retrieve half of it. The story is about their quest to bring Nyaako fully back to life.<br /><br />Though a lot of the content in this movie seems completely random, it is not. Most of it is symbolism for life, death and rebirth. You can also see references from other tales, such as Hansel and Gretal. This strangely cute short film has an interesting story, packed with a deeper meaning than what you see on the surface of the screen.\",\n",
              "         b'Possibly the best movie ever created in the history of Jeffrey Combs career, and one that should be looked upon by all talent in Hollywood for his versatility, charisma, and uniqueness he brings through his characters and his knowledge of acting.',\n",
              "         b'...said a couple exiting the movie theater just as I was entering to watch this. Hmm, not a good sign, but who knows? Different strokes for different folks, after all. Well, nope. They were being kind. Godard has released work that is passionate (Contempt), entertaining (Band of Outsiders), sometimes both (My Life to Live). This is just dull intellectualism, that grates on the nerves pretty quickly. During my showing, literally half of the audience had walked out by the end of the film. If only I had been so wise.',\n",
              "         b'I hate this movie. I hate the show. i hate just about everything about it. it\\'s so annoying and stupid. everyone\\'s saying that nat and alex wolff are heroes in the music world and that they\\'re going to make it big. WHAT KIND OF DRUGS ARE YOU TAKING???!!!?!?!?!?! nat and alex are going to end up as either hobos or end up like Jane Hudson from \"Whatever Happened to Baby Jane?\". i could only get through not even 20 minutes of this one, barely 30 seconds of the show, and i managed to survive about half an hour of \\'Battle of the Bands\\'. How anyone could cheer for these guys in the audience at the Kid\\'s Choice Awards, i have no clue. days before the movie premiere on Nick, most of the teen girl actresses on Nick (Jamie Spears, Emma Roberts, Lindsey Shaw, etc.) showed up in a commercial influencing brain-dead kids about how awesome nat and alex wolff are. first off, they didn;t trick me, and second of all, nat and alex probably either drugged them or payed them loads of money in order to say that and sound convincing, because i don\\'t see how anyone could find this show/movie entertaining. the music is just awful. nat\\'s singing sounds like a sick, dying moose on crack. alex is the most annoying movie/TV show character EVER. he\\'s not funny, he\\'s annoying, he\\'s really weird, and he thinks he\\'s hot and knows everything about girls. this guy\\'s lucky if he ever manages to get laid. you know this show is fake when you find out that some of the characters (in real life) don\\'t even exist!! the character Jesse is actually played by Nat and Alex\\'s cousin jesse Draper (they mustve had some budget problem). Their father is not single, he\\'s married to Polly Draper, but she doesn\\'t appear on the show, making it seem the Wolff\\'s are mom-less. Rosalina doesn\\'t exist either. Her name is Allie DiMeco. I\\'ll tell ya, the Naked Brothers are gonna be in some deep sh** when their \"fans\" find out the whole thing is staged. 0/10',\n",
              "         b'First of all, Riget is wonderful. Good comedy and mystery thriller at the same time. Nice combination of strange \\'dogma\\' style of telling the story together with good music and great actors. But unfortunately there\\'s no \\'the end\\'. As for me it\\'s unacceptable. I was thinking... how it will be possible to continue the story without Helmer and Drusse? ...and I have some idea. I think Lars should make RIGET III a little bit different. I\\'m sure that 3rd part without Helmer wouldn\\'t be the same. So here\\'s my suggestion. Mayble little bit stupid, maybe not. I know that Lars likes to experiment. So why not to make small experiment with Riget3? I think the only solution here is to create puppet-driven animation (like for example \"team America\" by Trey Parker) or even computer 3d animation. I know it\\'s not the same as real actors, but in principle I believe it could work... only this way it\\'s possible to make actors alive again. For Riget fans this shouldn\\'t be so big difference - if the animation will be done in good way average \\'watcher\\' will consider it normal just after first few shots of the movie. The most important thing now is the story. It\\'s completely understandable that it\\'s not possible to create Riget 3 with the actors nowadays. So why not to play with animation? And... look for the possibilities that it gives to you! Even marketing one! Great director finishes his trilogy after 10 years using puppet animation. Just dreams?<br /><br />I hope to see Riget 3 someday... or even to see just the script. I\\'m curious how the story ends... and as I expect- everybody here do.<br /><br />greets, slaj<br /><br />ps: I\\'m not talking about the \"kingdom hospital\" by Stephen King ;-)',\n",
              "         b\"The Waiting Womans Ward of a large lying-in hospital, with all its joys and sorrows, is the place where LIFE BEGINS.<br /><br />This nearly forgotten drama is a fine little soap opera, replete with comedy and tragedy, all tied into the lives of the maternity staff and their patients. The frankness with which the subject matter is handled points up the movie's pre-Code status.<br /><br />Marvelous Aline MacMahon, as the sympathetic head nurse, is the calm center of the film, the rock around which all the currents flow. Able to handle any crisis or emergency, she is the mothers' best, sometimes last, friend. Surrounding MacMahon is a bevy of excellent costars: Loretta Young as a convicted murderess released from prison long enough to give birth; Eric Linden as her frightened young husband; brassy Glenda Farrell as a dame who hates children; sweet Clara Blandick as a very mature mother in for her sixth birthing; Preston Foster & Hale Hamilton as thoughtful, compassionate doctors and Frank McHugh as a comically frantic father-to-be.<br /><br />Movie mavens will recognize Bobs Watson as a wee tyke who wants to see the Stork; Paul Fix as a nervous husband who promises to behave like a `little soldier;' Gilbert Roland as a distraught Italian husband and Elizabeth Patterson as a snooty doctor's wife interested in adopting Farrell's son - all uncredited.<br /><br />There are a few absurdities in the plot - some of the mothers are obviously much too old; Farrell becomes blatantly drunk in the Ward but none of the staff seem to notice; an obviously psychotic patient is able to wander around at will - but this really only enhances the quirky entertainment value of the film and keeps things from becoming too serious.\",\n",
              "         b'I view probably 200 movies a year both at theaters and at home and I can say with confidence that this movie is by far the worst I have seen this year (If not ever, however I have not actually seen \"Quest of the Delta Knights\" yet). This movie is just bad joke after bad joke geared to the 13 year old and because I had he displeasure of viewing it on a bus trip I couldn\\'t walk out.<br /><br />Do yourself a favor and skip this one in the rental aisle. The four dollars could be better spent on any movie by numbers produced by Jerry Bruckheimer.',\n",
              "         b'With the rising popularity of the now iconic Godzilla series, like with any hit cinema event, there was inevitably going to be a crowd of imitators trying to cash in on the success on the big lizard. With Godzilla came the dawn of a rising popularity of the kaiju (giant monster) genre. Many sought after success; a few gained it. One of the few that not only profited, but garnered popularity was Gamera, a giant turtle that could breathe fire in and out and fly by spewing flames from the sockets in his carapace as a means of jet propulsion. But unlike Godzilla, Gamera was marketed as a friend to all children, later fighting other monsters to save kids in peril, and thus Gamera became very popular amongst the kiddies. Unfortunately, that\\'s about the only audience mainstream that the original Gamera series will have any appeal to. While the new Gamera movies directed by Shusuke Kaneko are marvelous, revolutionary monster movies, the original series, including the original, is nothing special.<br /><br />The first Gamera movie, titled in Japan as \"The Giant Monster Gamera\" was clearly a Godzilla want-to-be. Even though the movie was produced in the era of color films, it was shot in black-and-white. Why? To imitate the first Godzilla movie from the 1950s. Gamera also attacks Tokyo. Because Godzilla attacked Tokyo in the first movie. I don\\'t know much about the Japanese version, for the version I am familiar with the Americanized version, where scenes were cut and new footage with American actors were inserted (is it coincidence that the same thing happened with the first Godzilla film?) Now whether this adds or takes away from the film, I cannot say. But \"Gammera the Invincible\" is really nothing more than a ponderous bore that just plods along like the big turtle himself.<br /><br />\"Gammera the Invincible\" is a very routine-orientated movie. The characters are from a stock of science-fiction standards, the story is inane, the monster has no real motive for attacking civilization, the acting is laughable, and so on and so forth. The only thing that differentiates it from the Godzilla series is the ending of the movie, but that\\'s also a detractor since the plan that eventually halts Gamera\\'s rampage is completely phony and ridiculous. Now the rest of the movie and many other entries in this genre also fit that description, but this is a direfully stodgy monster movie.<br /><br />And although Shusuke Kaneko would later transform Gamera into an interesting monster with his trilogy in the 1990s, in the original series, Gamera was not an attractive screen presence. He was neither scary nor sympathetic. He just waddles around like a toddler, swaying with each step, and knocks miniature sets over. As usual, everybody wants to destroy Gamera except for a little kid (Yoshio Uchida who was lazily left out of the credits though he plays a \\'central\\' role) who thinks Gamera is a nice turtle.<br /><br />Most movies in the genre that \"Gammera the Invincible\" is a part of are easy targets for criticism and this one is subject to extra pressure. Even in the company of many other Godzilla-imitators, this Gamera film is not a particularly good entry. And as far as my cinema experience goes, the rest of the movies in the series are either just as boring or worse. Like Godzilla, Gamera would be filmed in color and go on to fight monsters. And like Godzilla, he\\'d get cheaper and cheaper with every film until it was time to revive the series and make him serious again.<br /><br />It\\'s peculiar. Usually I recommend people to stick with the originals and pass on the remakes. But in the case of Gamera, my verdict is just the opposite. I strongly encourage people to watch the 1990s Gamera trilogy directed by Shusuke Kaneko and to skip over the original series unless interested. The new films are inventive, well-made, exciting, and above all, fun. The original series is a long stream of boredom.',\n",
              "         b\"If you have plenty of time to waste ... it's OK. It moves at a good pace but to pull this movie off it would need to be a little longer with a little more background on the sitter. <br /><br />The acting is OK. Mariana Klaveno as the sitter does the best job and is the most believable.<br /><br />William R. Moses played a pretty good part as the husband.<br /><br />Gail O'Grady, as the wife, had a weak part and the reasons for her going back to work were not developed.<br /><br />The ending is sort of silly. Like most of these sitter movies ... there are parts that are interesting ... but overall it leaves you wondering why you spent the time.\",\n",
              "         b'Simon\\'s carefully written dialogues are truly electrified by Matthau and Burns. You can literally hear the script crackle. There are few movies out there that can develop such a relationship between the actors and the script. For example, the famed reunion scene could have been a lot duller with less-quality actors involved. Matthau seems to had been born to play Willie Clark (of course, Oscar moreso in the Odd Couple), and with all of the little idiosyncracies and mannerisms that Matthau crams into the character (the line where he is arguing that he is with it since he lives in the city whereas Lewis lives in the country that Lewis is \"out of touch\" is the quintessential example of this) make this one of the best performances I\\'ve ever seen of any actor in any role, be it comedic or drama or whatever else. Period. Matthau and Burns work excellently together; the contrast they portray accentuates Simon\\'s superb knack at creating comedic conflict. This movie is simply one of the ultimate \"must-sees\" and does demand a rightful prestigious place in the pages of film history.',\n",
              "         b\"Who wrote this? Some guy named John Cohen. I guess this was the first screenplay he's ever worked on. Someone should've told him you're supposed to write dialog that sounds like something someone actually might say.<br /><br />And who directed this? Scott Marshal? Son of Gerry Marshall. My the nut has fallen far from the tree. Someone might have wanted to let him know that you can, in fact, shoot a scene in a cab in New York, and it will look real, and you won't have to fake it with a blue screen for no reason. Might have also wanted to let him know he should stay away from Jessica Simpson, but hopefully he's learned that lesson now.<br /><br />And Jessica Simpson... naturally she can't act. Hell, she makes Jessica Alba look like Audry Hepburn, and yet she's starring in this movie. OH wait, it was produced by her father. Okay, that's why she got the part. That's really the only reason I can think of.<br /><br />So should I be surprised it's bad? No. Should I be amazed at how bad it is? I think a lot of people would if they saw as much of it as I did. I mean you expect a movie starring Jessica Simpson to be bad, but this... it's not just bad, it's the complete opposite of a classic film. Think of a great Woody Allen movie, this film is as bad as that film is good. It's the Anti-Annie Hall.<br /><br />I am so glad I didn't pay to see it, I stopped watching ten minutes in cus I couldn't go on. No doubt I would've walked out of the theater sooner. In fact I wonder how many of the 6 people who saw it per theater actually stayed and watched the whole thing. The film starts out laughably bad, and then goes to the point of being so bad it becomes a kind of Chinese water torture. And then, around when the first act is ending, you realize it'll only get worse, and that's when you either need to leave, or kill yourself.<br /><br />In conclusion, this film goes under the category of being so bad it should be used in place of water boarding at Guantanamo Bay. Although some prefer the water boarding.\",\n",
              "         b\"Everybody who wants to be an editor should watch this movie! It shows you about every mistake not to do in editing a movie! My grandma could have done better than that! But that's not the only reason why this movie is really bad! (It's actually so bad that I'm not able to write a sentence without exclamation mark!) If the first episode of \\xc2\\x91Les Visiteurs' was a quite good familial comedy with funny jokes and cult dialogues, this sequel is copying badly the receipe of the first one. The funny parts could be counted on one hand and maybe half of it. Clavier is over-acting his role even more than in the first part, Robin is trying to act like Lemercier (because she's replacing her) but that's \\xc2\\x91grotesque'. Lemercier is Lemercier, Robin is Robin! Even if Muriel Robin can be funny by herself on stage, she is not in this movie because she's not acting as she used to act. I know that it should be hard to replace somebody who was good in a role (Lemercier obtained a C\\xc3\\xa9sar award for her role in the first movie) but she made a big mistake: instead of playing her role, she played \\xc2\\x91Lemercier playing her role'! As for the story, it's just too much! Of course we knew at he end of the first movie that there would be a sequel but Poir\\xc3\\xa9 and Clavier should hae tried to write a more simple story like the first episode. The gags are repetitive, childish and d\\xc3\\xa9j\\xc3\\xa0-vu. No, really, there's no more than 3 funny parts in this. The only good things might be the costumes and some special effects. So you have only 2 reasons to watch it: 1) if you want to learn how to edit awfully a movie, 2) if you want to waste your time or if you really need a \\xc2\\x91brainless moment'! 2/10\",\n",
              "         b\"That hilarious line is typical of what these naughty sisters say. (It's funny on its own terms and pretty funny unintentionally , too.) Only two of the sisters are really bad. Boy, are they bad, too! One is given to pinup poses and salacious comments where e'er she goes. The other is got up to look like Marilyn Monroe. She has those sensual, slightly parted lips. And, not to give anything away, she is even more bad than the other.<br /><br />All three sisters are played by starlets. The man who stumbles into their lives is played by John Bromfield. He had something of a career.<br /><br />This looks today like possibly the first mainstream soft-core porn ever marketed. Well, of course not the first but the raciest at that time.<br /><br />The girls wear as little as possible and let's not forget about the female audience members: Bromfield is shown shaving with an electric razor -- whose fetish was this? -- bare-chested. He also is shown sopping wet in a swimsuit.<br /><br />There's a real plot here, too: The girls' family, see, is cursed. They are prone to suicide -- or dramatic deaths that can be made to seem like suicide.<br /><br />The movie is not bad. I truly don't know where it was shown. Maybe it was made for drive-ins. Somehow, and I could be wrong, I felt that the typical male audience was not the primary target here. The women are scantily dressed. They often resemble lurid covers of mags like Police Detective or jackets of dime novels.<br /><br />But the guy seems to be the central focus. Not everyone in the movie likes him, but all the girls love him. And I think the audience is meant to also.<br /><br />It's lots of fun -- and on its own terms, too.\",\n",
              "         b\"Much as we all love Al Pacino, it was painful to see him in this movie. A publicity hack at the grubby ending of what seems to have once been a distinguished and idealistic career Pacino plays his part looking like an unmade bed and assaulting everyone with a totally bogus and inconsistent southern accent.<br /><br />The plot spools out this way and that with so many loose ends and improbabilities that the mind reels (and then retreats).<br /><br />Kim Basinger is there, not doing much. Her scenes with Pacino are flat and unconvincing. Hard to believe they meant a lot to each other. There's no energy there.<br /><br />Tea Leone, on the other hand, lit up the screen. She was electric and her scenes with Pacino were by far the most interesting in the movie, but not enough to save Al from embarrassment.\",\n",
              "         b\"This movie is just so good! Despite Carmen Electra, this has to be one of the better films I have seen in awhile. Jamie Kennedy is just amazing, and Loren Dean plays an insane spoiled movie star very well. The plot is great as well. It's all very real which is scary. It says here that it's a drama, but this is one of the damn funniest dramas I have ever seen. Go check it out.\",\n",
              "         b\"I saw this movie on the Hallmark Channel and thought it was wonderful, especially since it was based on a true man. Pierce Brosnan was very good as the loner English man who took on the persona of the half breed Grey Owl. The photography was beautiful.<br /><br />This movie made me do more research into this character Archie Belaney known simple as Grey Owl. I want to read as much as I can about him. At the time I did not know Richard Attenborough had directed it. But I am not surprised. I like all his movies whether he is acting or directing. I gave it the highest rating. However, I would have liked to have seen more in the movie about WHY he took on this persona as it only showed the two aunts who raised him and his room in their house.<br /><br />You can't go wrong with this movie if you are like me and enjoy a beautiful story without hearing foul language and contrived special effects every few minutes.\",\n",
              "         b\"A thematic staple of cinema since its inception is that genre involving seductive women whose wiles and means entice susceptible men not only into their arms but also into dire circumstances that typically will only result in jeopardy for the male victims, along with incertitude as to whether or not temptresses will be forced to take their medicine, and here Susan Lucci performs as a siren, although her acting chops from a primarily soap opera pedigree are inadequate to make her performance a credible one. Isabelle (Lucci), inconstant wife of venture capitalist Stewart Collins (John O'Hurley), begins a love affair merely for fun with yacht salesman Richard Davis (Philip Casnoff), simply a bagatelle for her but an earnest matter of the heart for Richard, apparently mesmerized by his lover while she takes advantage of his ardour by engaging him in a risky plot that will graduate into a scheme of murderous intent. When Davis becomes convinced that guileful Isabelle is a victim of physical abuse administered by her husband, he desperately attempts to free her from what he feels is a marital trap in order that he may wed her himself, coming to believe that the only clear solution to his plight will be found in a rudimentary essay at hiring a professional assassin who will dispose of the allegedly violent Stewart. In the wake of the hit-man's assault upon Collins, a pair of police detectives, performed by Joe Grifasi and Dean McDermott, become increasingly curious concerning Isabelle's possible involvement in the crime, while at the same time reality dawns upon enraptured Richard who might have to pay a dear price in return for his inamorata's maneuvering. Lucci and Kasnoff are properly cast as a viable pair of conspirators, each giving a reading that makes for a boring rather than charming set of lovebirds, but O'Hurley and McDermott offer strong turns in a film that suffers from a hackneyed scenario as well as uninventive direction and design elements. Released upon a Fremantle DVD, this largely lustreless affair depicting a man 'neath the spell of a seductress does benefit from top-flight visual and sound quality, and although no extra features are provided, the above-average production quality enhances able efforts from cinematographer Robert Primes and composer Stephen Edwards.\",\n",
              "         b\"This movie is a journey through the mind of a screenwriter caught in his own paradoxical philosophy. He examines the ever illusive question of 'who am I' and 'what is I?' It's a courageous and thought provoking enterprise. There is a shipload of beautiful images, dream-inspired, Escher-like paradoxes reminiscent of the hand drawing itself, or rather, erasing itself. More and more we follow the writer in his agony over what to say and what to film, we see him phoning with his wife who left for Peru, leaving him to take care of their baby, a task he performs with less and less attention until he's so absorbed in his dilemma's that he hardly looks at the child anymore. His wife comes back and makes a scene, destroys his notes and helping him go over the last treshold until he erases him-self. Interspersed with eye-pleasing and I-destructing images, the story is mainly philosophical. It's about the veils of Maya, the world of illusion. The paradox of the movie however, is that it needs a lot of talking and thinking to prove that thinking should stop. During the more than two hours of provocative beauty and rapid philosophising the movie made me long for silence or a shorter movie. If that was the purpose of the maker, he succeeded quite well.\",\n",
              "         b\"This movie is spoofed in an episode of Mystery Science Theater 3000. I think MST3K was at its best when they ripped this movie.<br /><br />Terrible acting, bad makeup, poor effects, chick in skimpy (1960's)underwear. I give it a 2.<br /><br />The villain is hard to understand due to the makeup. The assistant says things like 'not you' that sound like NACHOO!! (think sneezing). It's just poor oration. The long eyebrows are hilarious on one of the characters. <br /><br />I still don't know what 'The Projected Man' means in terms of the plot. I missed some of the beginning though. <br /><br />What is up with this 10 line minimum on posting??\",\n",
              "         b'\"Hollywood Hotel\" is a fast-moving, exuberant, wonderfully entertaining musical comedy from Warners which is sadly overlooked. It should be remembered if only for providing the official theme song of Tinseltown -- \"Hooray for Hollywood.\" The score by Richard Whiting and Johnny Mercer has a number of other gems, however, including the charming \"I\\'m Like a Fish Out of Water,\" and \"Silhouetted in the Moonlight.\" The best musical number is \"Let That Be a Lesson to You,\" in which Dick Powell and company detail the misadventures of people who found themselves \"behind the eight-ball,\" a fate which literally befalls slow-burning Edgar Kennedy at the number\\'s end. The picture celebrates Hollywood glamour and punctures it all at once, as it gets a lot of comic mileage out of pompous and ego-maniacal actors and duplicitous studio executives. The cast includes a gaggle of great character comedians--Allyn Joslyn as a crafty press agent, Ted Healy as Dick Powell\\'s would-be manager, Fritz Feld as an excitable restaurant patron, Glenda Farrell as Mona Marshall\\'s sarcastic Gal Friday, Edgar Kennedy as a put-upon drive-in manager, Mabel Todd as Mona\\'s goofy sister, and Hugh Herbert as her even goofier dad. The \"racist\" element mentioned in another review here is a ten-second bit where Herbert appears in black-face during a pseudo-\"Gone With the Wind\" sequence. It\\'s in questionable taste, but it shouldn\\'t prevent you from seeing the other delights in this film, notably the Benny Goodman Quartet (including Teddy Wilson and Lionel Hampton!) in what I believe is the only footage available on this incredible jazz combo. The \"Dark Eyes\" sequence goes on a bit too long and comes in too late, but otherwise \"Hollywood Hotel\" is a gem, well worth your time and certainly a film which should be considered for DVD release.',\n",
              "         b\"What network was , Diagnosis Murder on? I thought it was CBS. Am I right or?? Also, Back in those days, the actual production H.Q. was near about the Van Nuys Airport. I surely remember, because I practically made nearly two episodes in those daze. More. I remember the early days. I had found an article in Reader's Digest giving this actor/writer a clue to a terrific episode. So just for suggesting it I was awarded. Awarded or not, I sadly didn't develop it, and was cut out of it all due to poor publicity of mine. So as a justification I learned as I always have, the hard way... Roll the dice..Craps!!! Just a side bar on Mr. Van Dyke. He had a house in the Brentwood area on Chalon Road and it was an incredible party house. Dick had a terrific sense of modernism when he built that house.\",\n",
              "         b\"I went to see this movie with my 17 y.o. daughter. I insisted we go the matin\\xc3\\xa9e showing, not because I'm a tightwad, but just feeling I had. In the NASCAR spirit, this is a sponser's dream. SO much blatant advertising, it almost qualifies as an info-mercial, if it weren't for the so-called acting. Keeping with tradition, the Herbie franchise continues with its cheesy story lines, the car is only a 'vehicle' (no pun intended)for this cornball of a motion picture. Earlier Herbie installments (although cheesy as well) were produced during more serious times, making them a little easier to digest. Ms. Lohan, Disney's reigning drama queen, has little acting ability. I was surprised that Mr. Keaton and Mr. Dillon would get involved in such a project. Only the snack bar, was a bigger ripoff!\",\n",
              "         b\"The Slackers as titled in this movie are three college friends Dave, Jeff and Sam(Devon Sawa, Michael Maronna and Jason Segel respectively), who are about to graduate from university without sitting through an honest exam but making it end successfully. This continues until the very end when unlikeable but the most likable character of the movie Nathan(Schwartzman) figures out what they are up to. Nathan starts blackmailing in order to make up with his dream girl as he cant pursue that in normal conditions. The only problem is when the trio starts to work on it, Dave falls in love with the gorgeous and good hearted Angela(James King) Unfortunately, not a brilliant genre movie. Schwartzman makes to watch the movie easy as his performance is brilliant. King's performance is average, I think she was hired just to be around with her gorgeous look. The Slackers is reminiscent of American Pie with a different direction. Jokes are as shallow as in American Pie. But aren't they all used? I think this movie is a warning to the filmmakers of the genre that they are running out of originality. Overall, a few smiley moments but a horrible movie in terms of acting(except for Schwartzman) and subject. * out of *****\",\n",
              "         b\"This excellent drama had me in suspense the whole time. I could not take my eyes off the screen for one second because every word kept connecting the pieces to this puzzling murder. This movie really touched me because it showed how sad and hard life can be. I really did cry in the end (which I don't want to give away!) It also let me realize how cruel and sickening people can be when it comes to murder. <br /><br />The cast was also very good. The only bad cast member was the actress who played Anne Marie. The actress did a great job, but the director didn't. I say this because he found someone who didn't look a single bit like Anne Marie Fahey herself.\",\n",
              "         b'it is of course very nice to see improvements on Turkish movie industry, however, i would have expected something more creative from Togan Gokbakar. starting from the script, which i believe it was not a wise written one as some may think. especially the cheesiness of the dialogs, which were putting the audience in a position that, as if they were not smart enough to understand the situations, which, most of the times makes the movie unbearable. it also has an obvious ending; you can easily guess the murderer from the beginning. the weakest part of the scenario is that the impossibility of seriously mentally ill patients to act like normal people, like professionals right away!!!did they ever search for the possibility of patients who are on heavy medicals, to act like professionals and use all the medical terms that even normal people cannot use?????!!!!!!also in the scene where staff was searching for the most dangerous patient, with out any weapon to protect themselves was another weird point of the film. and that scene was so suitable for \"Dikkat Sahan Cikabilir\" title!! those are not the only weak parts of the movie. there were also a lot of preciosities in the film. the depiction of the most dangerous patient was an exact copy from Hannibal, also appearance of Togan in the very end is obviously the worst mistake that he could have done in his first movie! the fuss about the greatness of the movie and the interviews that actor\\'s gave just made people to be curious and force them to see it. Gen is a total disappointment. i would have wonder, if Sahan was not this famous, would Togan be able to shoot this movie, with this much of budget amount?? i hope Togan would realize that it is not fashionable to play in a role as a director as he said in an interview. it was Hitchcock who did it wisely and Night Shyamalan continued it successfully! he should be aware of the fact that he is not Hitchcock nor Shyamalan yet!!!!hoping him to be more careful and creative next time in this big industry!',\n",
              "         b\"Kirstie Alley, looking a bit slimmer, but only a bit, is in this mess along with a man who is a MacGuyver lookalike, bleached blond hair and all. The premise of the movie is about an older woman (50!!!) who cannot get her screenplay produced due to age discrimination so she sends in her younger nephew to pose as the writer. Not an original idea and not a very good movie with lousy acting, inane dialogue and a ridiculous plot. There is another plot concerning a writer with a crush or admiration for Kirstie's character and why this is included is a mystery. The actor who portrays Kirstie's brother is so wooden and miscast, it was torture to watch their scenes. What is there to say about this film. Avoid it.\",\n",
              "         b'I haven\\'t read a biography of Lincoln, so maybe this was an accurate portrayal......<br /><br />And maybe it\\'s because I\\'m used to the equally alienating and unrealistic worshiping portrayals that unnaturally deify Lincoln as brilliant, honorable, and the savior of our country......<br /><br />But why would they make a movie representing Lincoln as a buffoon? While Henry Fonda made an excellent Lincoln, his portrayal of him as an \"aw shucks, I\\'m just a simple guy\" seemed a little insulting.<br /><br />[Granted, that was Bushie Jr.\\'s whole campaign, to make us think he was \"just a regular guy\" so we wouldn\\'t care that he\\'s a rich & privileged moron -- but that\\'s a whole other story.]<br /><br />Not only did the film show Lincoln as sort of a simple (almost simple-minded) kind of guy , the film states that Lincoln just sort of got into law by accident, and that he wasn\\'t even that interested in the law - only with the falsely simplistic idea of the law being about rights & wrongs. In the film he\\'s not a very good defense attorney (he lounges around with his feet on the table and makes fun of the witnesses), and the outcome is mostly determined by chance/luck.<br /><br />Furthermore, partly because this was financed by Republicans (in reaction to some play sponsored by Democrats that had come out) and partly because it was just the sentiment of the times, the film is unfortunately religious, racist and conservative.<br /><br />Don\\'t waste your time on this film!',\n",
              "         b\"This is the true story of how three British soldiers escaped from the German Prisoner Of War (POW) camp, Stalag Luft III, during the Second World War. This is the same POW camp that was the scene for the Great Escape which resulted in the murder of 50 re-captured officers by the Gestapo (and later was made into a very successful movie of the same name). <br /><br />While the other POWs in Stalag Luft III are busy working on their three massive tunnels (known as Tom, Dick & Harry), two enterprising British prisoners came up with the idea to build a wooden vaulting horse which could be placed near the compound wire fence, shortening the distance they would have to tunnel from this starting point to freedom. The idea to build their version of the Trojan Horse came to them while they were discussing 'classic' attempts for escape and observing some POWs playing leap-frog in the compound.<br /><br />Initially containing one, and later with two POWs hidden inside, the wooden horse could be carried out into the compound and placed in almost the same position, near the fence, on a daily basis. While volunteer POWS vaulted over the horse, the escapees were busy inside the horse digging a tunnel from under the vaulting horse while positioned near the wire, under the wire, and into the woods. <br /><br />The story also details the dangers that two of the three escaping POWs faced while traveling through Germany and occupied Europe after they emerged from the tunnel. All three POWs who tried to escape actually hit home runs (escaped successfully to their home base.). The Wooden Horse gives a very accurate and true feeling of the tension and events of a POW breakout. The movie was shot on the actual locations along the route the two POWs traveled in their escape. Made with far less a budget than The Great Escape, The Wooden Horse is more realistic if not more exciting than The Great Escape and never fails to keep you from the edge of your seat rooting for the POWs to make good their escape. <br /><br />The story line is crisp and the acting rings true and is taut enough to keep the tension up all the way through the movie. The Wooden Horse is based on the book of the same name by one of the escapees, Eric Williams, and is, by far, the best POW escape story ever made into a movie. Some of the actual POWs were used in the movie to reprise their existence as prisoners in Stalag Luft III. I give this movie a well deserved ten.\",\n",
              "         b\"My, how the mighty have fallen. Kim Basinger is a great actress but she was definitely slumming when she took this role. This movie is bad for one reason in particular: lapses in logic. Its looks like one of those movies that would have been passable with all its plot holes if it had came out in the 80s and 90s but in 2008 it just looks real stupid. This is the worst thriller I've ever seen and I've seen The Bone Collector and Twisted.<br /><br />The story details Della(Kim Basinger)is just getting from buying gifts in a mall an is harassed by a gang of thugs that end up killing a cop that came to her aid. From then on she is chased by these idiotic goons through an abandoned street and she gets rid of them one by one with a toolbox full of tools.<br /><br />So many things are wrong with this movie. As I said this movie leaps over logic at every turn and with the exception of Kim Basinger, the acting is made-for-TV bad. Hell, this pseudo thriller is made-for-TV bad. The way she kills each of these politically correct thugs(1 Caucasian, 1 Hispanic, 1 Asian and 1 African American all coming together to stalk a Caucasian woman. Don't you just love America?)is laughable to a fault. The way she killed the Hispanic guy made me laugh hysterically. The sex scene with the main hoodlum was so out in left field that it make you shake your head in shame. I only recommend this to lovers of bad films and no one else. Anybody else especially Kim Basinger fans would do well not to own this flick. You don't want see an actress you respect in a film this bad now do you? Of course not. You were warned.\",\n",
              "         b\"Bridges of madison county is a better made version of this story. I felt the ending of this movie was not handled sensitively as they did in the original English movie. This movie is very indianised, if you are a very sensitive person who cries in a movie when hero dies in the end you'll love this movie, On the other hand if you are a fighter in life and think crying is for wimps you may not like the ending.But on the whole it's pretty good subject is well handled for indian conditions. Tabu was good as a caring wife and mother. Everybody acted well.\"],\n",
              "        dtype=object)>,\n",
              "  <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              "  array([0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
              "         1, 0, 0, 1, 0, 0, 0, 1, 0, 0])>)]"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "[i for i in trainSet_complete.take(3)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "NzuHaa-a_Chn"
      },
      "outputs": [],
      "source": [
        "testSet_pos = tf.data.TextLineDataset(tf.data.Dataset.list_files(f'{base_path}\\\\testSet\\\\pos\\\\'), num_parallel_reads=5).batch(1)\n",
        "testSet_pos = testSet_pos.map(lambda content: (content, 1))\n",
        "\n",
        "testSet_neg = tf.data.TextLineDataset(tf.data.Dataset.list_files(f'{base_path}\\\\testSet\\\\neg\\\\'), num_parallel_reads=5).batch(1)\n",
        "testSet_neg = testSet_neg.map(lambda content: (content,0))\n",
        "\n",
        "testSet_complete = tf.data.Dataset.concatenate(testSet_pos, testSet_neg).shuffle(10000).batch(32).prefetch(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<TakeDataset shapes: ((None, None), (None,)), types: (tf.string, tf.int32)>"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testSet_complete.take(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "Ak2OnOBe_s7P"
      },
      "outputs": [],
      "source": [
        "valSet_pos = tf.data.TextLineDataset(tf.data.Dataset.list_files(f'{base_path}\\\\valSet\\\\pos\\\\'), num_parallel_reads=5).batch(1)\n",
        "valSet_pos = valSet_pos.map(lambda content: (content,1))\n",
        "\n",
        "\n",
        "valSet_neg = tf.data.TextLineDataset(tf.data.Dataset.list_files(f'{base_path}\\\\valSet\\\\neg\\\\'), num_parallel_reads=5).batch(1)\n",
        "valSet_neg = valSet_neg.map(lambda content: (content, 0))\n",
        "\n",
        "valSet_complete = tf.data.Dataset.concatenate(valSet_pos, valSet_neg).shuffle(15000).batch(32).prefetch(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUPKwvq5DkPT"
      },
      "source": [
        "## Qns 4 Create a binary classification model, using a TextVectorization layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "ix4azVJRDT_2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import TextVectorization, Dense, Input, Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "j50-L1lGEiy7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on class TextVectorization in module keras.layers.preprocessing.text_vectorization:\n",
            "\n",
            "class TextVectorization(keras.engine.base_preprocessing_layer.PreprocessingLayer)\n",
            " |  TextVectorization(max_tokens=None, standardize='lower_and_strip_punctuation', split='whitespace', ngrams=None, output_mode='int', output_sequence_length=None, pad_to_max_tokens=False, vocabulary=None, idf_weights=None, sparse=False, ragged=False, **kwargs)\n",
            " |  \n",
            " |  A preprocessing layer which maps text features to integer sequences.\n",
            " |  \n",
            " |  This layer has basic options for managing text in a Keras model. It transforms\n",
            " |  a batch of strings (one example = one string) into either a list of token\n",
            " |  indices (one example = 1D tensor of integer token indices) or a dense\n",
            " |  representation (one example = 1D tensor of float values representing data\n",
            " |  about the example's tokens).\n",
            " |  \n",
            " |  The vocabulary for the layer must be either supplied on construction or\n",
            " |  learned via `adapt()`. When this layer is adapted, it will analyze the\n",
            " |  dataset, determine the frequency of individual string values, and create a\n",
            " |  vocabulary from them. This vocabulary can have unlimited size or be capped,\n",
            " |  depending on the configuration options for this layer; if there are more\n",
            " |  unique values in the input than the maximum vocabulary size, the most frequent\n",
            " |  terms will be used to create the vocabulary.\n",
            " |  \n",
            " |  The processing of each example contains the following steps:\n",
            " |  \n",
            " |  1. Standardize each example (usually lowercasing + punctuation stripping)\n",
            " |  2. Split each example into substrings (usually words)\n",
            " |  3. Recombine substrings into tokens (usually ngrams)\n",
            " |  4. Index tokens (associate a unique int value with each token)\n",
            " |  5. Transform each example using this index, either into a vector of ints or\n",
            " |     a dense float vector.\n",
            " |  \n",
            " |  Some notes on passing callables to customize splitting and normalization for\n",
            " |  this layer:\n",
            " |  \n",
            " |  1. Any callable can be passed to this Layer, but if you want to serialize\n",
            " |     this object you should only pass functions that are registered Keras\n",
            " |     serializables (see `tf.keras.utils.register_keras_serializable` for more\n",
            " |     details).\n",
            " |  2. When using a custom callable for `standardize`, the data received\n",
            " |     by the callable will be exactly as passed to this layer. The callable\n",
            " |     should return a tensor of the same shape as the input.\n",
            " |  3. When using a custom callable for `split`, the data received by the\n",
            " |     callable will have the 1st dimension squeezed out - instead of\n",
            " |     `[[\"string to split\"], [\"another string to split\"]]`, the Callable will\n",
            " |     see `[\"string to split\", \"another string to split\"]`. The callable should\n",
            " |     return a Tensor with the first dimension containing the split tokens -\n",
            " |     in this example, we should see something like `[[\"string\", \"to\",\n",
            " |     \"split\"], [\"another\", \"string\", \"to\", \"split\"]]`. This makes the callable\n",
            " |     site natively compatible with `tf.strings.split()`.\n",
            " |  \n",
            " |  For an overview and full list of preprocessing layers, see the preprocessing\n",
            " |  [guide](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n",
            " |  \n",
            " |  Args:\n",
            " |    max_tokens: Maximum size of the vocabulary for this layer. This should only\n",
            " |      be specified when adapting a vocabulary or when setting\n",
            " |      `pad_to_max_tokens=True`. Note that this vocabulary\n",
            " |      contains 1 OOV token, so the effective number of tokens is `(max_tokens -\n",
            " |      1 - (1 if output_mode == \"int\" else 0))`.\n",
            " |    standardize: Optional specification for standardization to apply to the\n",
            " |      input text. Values can be None (no standardization),\n",
            " |      `\"lower_and_strip_punctuation\"` (lowercase and remove punctuation) or a\n",
            " |      Callable. Default is `\"lower_and_strip_punctuation\"`.\n",
            " |    split: Optional specification for splitting the input text. Values can be\n",
            " |      None (no splitting), `\"whitespace\"` (split on ASCII whitespace), or a\n",
            " |      Callable. The default is `\"whitespace\"`.\n",
            " |    ngrams: Optional specification for ngrams to create from the possibly-split\n",
            " |      input text. Values can be None, an integer or tuple of integers; passing\n",
            " |      an integer will create ngrams up to that integer, and passing a tuple of\n",
            " |      integers will create ngrams for the specified values in the tuple. Passing\n",
            " |      None means that no ngrams will be created.\n",
            " |    output_mode: Optional specification for the output of the layer. Values can\n",
            " |      be `\"int\"`, `\"multi_hot\"`, `\"count\"` or `\"tf_idf\"`, configuring the layer\n",
            " |      as follows:\n",
            " |        - `\"int\"`: Outputs integer indices, one integer index per split string\n",
            " |          token. When `output_mode == \"int\"`, 0 is reserved for masked\n",
            " |          locations; this reduces the vocab size to\n",
            " |          `max_tokens - 2` instead of `max_tokens - 1`.\n",
            " |        - `\"multi_hot\"`: Outputs a single int array per batch, of either\n",
            " |          vocab_size or max_tokens size, containing 1s in all elements where the\n",
            " |          token mapped to that index exists at least once in the batch item.\n",
            " |        - `\"count\"`: Like `\"multi_hot\"`, but the int array contains a count of\n",
            " |          the number of times the token at that index appeared in the\n",
            " |          batch item.\n",
            " |        - `\"tf_idf\"`: Like `\"multi_hot\"`, but the TF-IDF algorithm is applied to\n",
            " |          find the value in each token slot.\n",
            " |      For `\"int\"` output, any shape of input and output is supported. For all\n",
            " |      other output modes, currently only rank 1 inputs (and rank 2 outputs after\n",
            " |      splitting) are supported.\n",
            " |    output_sequence_length: Only valid in INT mode. If set, the output will have\n",
            " |      its time dimension padded or truncated to exactly `output_sequence_length`\n",
            " |      values, resulting in a tensor of shape\n",
            " |      `(batch_size, output_sequence_length)` regardless of how many tokens\n",
            " |      resulted from the splitting step. Defaults to None.\n",
            " |    pad_to_max_tokens: Only valid in  `\"multi_hot\"`, `\"count\"`, and `\"tf_idf\"`\n",
            " |      modes. If True, the output will have its feature axis padded to\n",
            " |      `max_tokens` even if the number of unique tokens in the vocabulary is less\n",
            " |      than max_tokens, resulting in a tensor of shape `(batch_size, max_tokens)`\n",
            " |      regardless of vocabulary size. Defaults to False.\n",
            " |    vocabulary: Optional. Either an array of strings or a string path to a text\n",
            " |      file. If passing an array, can pass a tuple, list, 1D numpy array, or 1D\n",
            " |      tensor containing the string vocbulary terms. If passing a file path, the\n",
            " |      file should contain one line per term in the vocabulary. If this argument\n",
            " |      is set, there is no need to `adapt` the layer.\n",
            " |    idf_weights: Only valid when `output_mode` is `\"tf_idf\"`. A tuple, list, 1D\n",
            " |      numpy array, or 1D tensor or the same length as the vocabulary, containing\n",
            " |      the floating point inverse document frequency weights, which will be\n",
            " |      multiplied by per sample term counts for the final `tf_idf` weight. If the\n",
            " |      `vocabulary` argument is set, and `output_mode` is `\"tf_idf\"`, this\n",
            " |      argument must be supplied.\n",
            " |    ragged: Boolean. Only applicable to `\"int\"` output mode. If True, returns a\n",
            " |      `RaggedTensor` instead of a dense `Tensor`, where each sequence may have a\n",
            " |      different length after string splitting. Defaults to False.\n",
            " |    sparse: Boolean. Only applicable to `\"multi_hot\"`, `\"count\"`, and\n",
            " |      `\"tf_idf\"` output modes. If True, returns a `SparseTensor` instead of a\n",
            " |      dense `Tensor`. Defaults to False.\n",
            " |  \n",
            " |  Example:\n",
            " |  \n",
            " |  This example instantiates a `TextVectorization` layer that lowercases text,\n",
            " |  splits on whitespace, strips punctuation, and outputs integer vocab indices.\n",
            " |  \n",
            " |  >>> text_dataset = tf.data.Dataset.from_tensor_slices([\"foo\", \"bar\", \"baz\"])\n",
            " |  >>> max_features = 5000  # Maximum vocab size.\n",
            " |  >>> max_len = 4  # Sequence length to pad the outputs to.\n",
            " |  >>>\n",
            " |  >>> # Create the layer.\n",
            " |  >>> vectorize_layer = tf.keras.layers.TextVectorization(\n",
            " |  ...  max_tokens=max_features,\n",
            " |  ...  output_mode='int',\n",
            " |  ...  output_sequence_length=max_len)\n",
            " |  >>>\n",
            " |  >>> # Now that the vocab layer has been created, call `adapt` on the text-only\n",
            " |  >>> # dataset to create the vocabulary. You don't have to batch, but for large\n",
            " |  >>> # datasets this means we're not keeping spare copies of the dataset.\n",
            " |  >>> vectorize_layer.adapt(text_dataset.batch(64))\n",
            " |  >>>\n",
            " |  >>> # Create the model that uses the vectorize text layer\n",
            " |  >>> model = tf.keras.models.Sequential()\n",
            " |  >>>\n",
            " |  >>> # Start by creating an explicit input layer. It needs to have a shape of\n",
            " |  >>> # (1,) (because we need to guarantee that there is exactly one string\n",
            " |  >>> # input per batch), and the dtype needs to be 'string'.\n",
            " |  >>> model.add(tf.keras.Input(shape=(1,), dtype=tf.string))\n",
            " |  >>>\n",
            " |  >>> # The first layer in our model is the vectorization layer. After this\n",
            " |  >>> # layer, we have a tensor of shape (batch_size, max_len) containing vocab\n",
            " |  >>> # indices.\n",
            " |  >>> model.add(vectorize_layer)\n",
            " |  >>>\n",
            " |  >>> # Now, the model can map strings to integers, and you can add an embedding\n",
            " |  >>> # layer to map these integers to learned embeddings.\n",
            " |  >>> input_data = [[\"foo qux bar\"], [\"qux baz\"]]\n",
            " |  >>> model.predict(input_data)\n",
            " |  array([[2, 1, 4, 0],\n",
            " |         [1, 3, 0, 0]])\n",
            " |  \n",
            " |  Example:\n",
            " |  \n",
            " |  This example instantiates a `TextVectorization` layer by passing a list\n",
            " |  of vocabulary terms to the layer's `__init__()` method.\n",
            " |  \n",
            " |  >>> vocab_data = [\"earth\", \"wind\", \"and\", \"fire\"]\n",
            " |  >>> max_len = 4  # Sequence length to pad the outputs to.\n",
            " |  >>>\n",
            " |  >>> # Create the layer, passing the vocab directly. You can also pass the\n",
            " |  >>> # vocabulary arg a path to a file containing one vocabulary word per\n",
            " |  >>> # line.\n",
            " |  >>> vectorize_layer = tf.keras.layers.TextVectorization(\n",
            " |  ...  max_tokens=max_features,\n",
            " |  ...  output_mode='int',\n",
            " |  ...  output_sequence_length=max_len,\n",
            " |  ...  vocabulary=vocab_data)\n",
            " |  >>>\n",
            " |  >>> # Because we've passed the vocabulary directly, we don't need to adapt\n",
            " |  >>> # the layer - the vocabulary is already set. The vocabulary contains the\n",
            " |  >>> # padding token ('') and OOV token ('[UNK]') as well as the passed tokens.\n",
            " |  >>> vectorize_layer.get_vocabulary()\n",
            " |  ['', '[UNK]', 'earth', 'wind', 'and', 'fire']\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      TextVectorization\n",
            " |      keras.engine.base_preprocessing_layer.PreprocessingLayer\n",
            " |      keras.engine.base_layer.Layer\n",
            " |      tensorflow.python.module.module.Module\n",
            " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
            " |      tensorflow.python.training.tracking.base.Trackable\n",
            " |      keras.utils.version_utils.LayerVersionSelector\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, max_tokens=None, standardize='lower_and_strip_punctuation', split='whitespace', ngrams=None, output_mode='int', output_sequence_length=None, pad_to_max_tokens=False, vocabulary=None, idf_weights=None, sparse=False, ragged=False, **kwargs)\n",
            " |  \n",
            " |  build(self, input_shape)\n",
            " |      Creates the variables of the layer (optional, for subclass implementers).\n",
            " |      \n",
            " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
            " |      can override if they need a state-creation step in-between\n",
            " |      layer instantiation and layer call.\n",
            " |      \n",
            " |      This is typically used to create the weights of `Layer` subclasses.\n",
            " |      \n",
            " |      Args:\n",
            " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
            " |          `TensorShape` if the layer expects a list of inputs\n",
            " |          (one instance per input).\n",
            " |  \n",
            " |  call(self, inputs)\n",
            " |      This is where the layer's logic lives.\n",
            " |      \n",
            " |      Note here that `call()` method in `tf.keras` is little bit different\n",
            " |      from `keras` API. In `keras` API, you can pass support masking for\n",
            " |      layers as additional arguments. Whereas `tf.keras` has `compute_mask()`\n",
            " |      method to support masking.\n",
            " |      \n",
            " |      Args:\n",
            " |        inputs: Input tensor, or dict/list/tuple of input tensors.\n",
            " |          The first positional `inputs` argument is subject to special rules:\n",
            " |          - `inputs` must be explicitly passed. A layer cannot have zero\n",
            " |            arguments, and `inputs` cannot be provided via the default value\n",
            " |            of a keyword argument.\n",
            " |          - NumPy array or Python scalar values in `inputs` get cast as tensors.\n",
            " |          - Keras mask metadata is only collected from `inputs`.\n",
            " |          - Layers are built (`build(input_shape)` method)\n",
            " |            using shape info from `inputs` only.\n",
            " |          - `input_spec` compatibility is only checked against `inputs`.\n",
            " |          - Mixed precision input casting is only applied to `inputs`.\n",
            " |            If a layer has tensor arguments in `*args` or `**kwargs`, their\n",
            " |            casting behavior in mixed precision should be handled manually.\n",
            " |          - The SavedModel input specification is generated using `inputs` only.\n",
            " |          - Integration with various ecosystem packages like TFMOT, TFLite,\n",
            " |            TF.js, etc is only supported for `inputs` and not for tensors in\n",
            " |            positional and keyword arguments.\n",
            " |        *args: Additional positional arguments. May contain tensors, although\n",
            " |          this is not recommended, for the reasons above.\n",
            " |        **kwargs: Additional keyword arguments. May contain tensors, although\n",
            " |          this is not recommended, for the reasons above.\n",
            " |          The following optional keyword arguments are reserved:\n",
            " |          - `training`: Boolean scalar tensor of Python boolean indicating\n",
            " |            whether the `call` is meant for training or inference.\n",
            " |          - `mask`: Boolean input mask. If the layer's `call()` method takes a\n",
            " |            `mask` argument, its default value will be set to the mask generated\n",
            " |            for `inputs` by the previous layer (if `input` did come from a layer\n",
            " |            that generated a corresponding mask, i.e. if it came from a Keras\n",
            " |            layer with masking support).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A tensor or list/tuple of tensors.\n",
            " |  \n",
            " |  compute_output_shape(self, input_shape)\n",
            " |      Computes the output shape of the layer.\n",
            " |      \n",
            " |      If the layer has not been built, this method will call `build` on the\n",
            " |      layer. This assumes that the layer will later be used with inputs that\n",
            " |      match the input shape provided here.\n",
            " |      \n",
            " |      Args:\n",
            " |          input_shape: Shape tuple (tuple of integers)\n",
            " |              or list of shape tuples (one per output tensor of the layer).\n",
            " |              Shape tuples can include None for free dimensions,\n",
            " |              instead of an integer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          An input shape tuple.\n",
            " |  \n",
            " |  compute_output_signature(self, input_spec)\n",
            " |      Compute the output tensor signature of the layer based on the inputs.\n",
            " |      \n",
            " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
            " |      and dtype information for a tensor. This method allows layers to provide\n",
            " |      output dtype information if it is different from the input dtype.\n",
            " |      For any layer that doesn't implement this function,\n",
            " |      the framework will fall back to use `compute_output_shape`, and will\n",
            " |      assume that the output dtype matches the input dtype.\n",
            " |      \n",
            " |      Args:\n",
            " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
            " |          objects, describing a candidate input for the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
            " |          how the layer would transform the provided input.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
            " |  \n",
            " |  finalize_state(self)\n",
            " |      Finalize the statistics for the preprocessing layer.\n",
            " |      \n",
            " |      This method is called at the end of `adapt` or after restoring a serialized\n",
            " |      preprocessing layer's state. This method handles any one-time operations\n",
            " |      that should occur on the layer's state before `Layer.__call__`.\n",
            " |  \n",
            " |  get_config(self)\n",
            " |      Returns the config of the layer.\n",
            " |      \n",
            " |      A layer config is a Python dictionary (serializable)\n",
            " |      containing the configuration of a layer.\n",
            " |      The same layer can be reinstantiated later\n",
            " |      (without its trained weights) from this configuration.\n",
            " |      \n",
            " |      The config of a layer does not include connectivity\n",
            " |      information, nor the layer class name. These are handled\n",
            " |      by `Network` (one layer of abstraction above).\n",
            " |      \n",
            " |      Note that `get_config()` does not guarantee to return a fresh copy of dict\n",
            " |      every time it is called. The callers should make a copy of the returned dict\n",
            " |      if they want to modify it.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Python dictionary.\n",
            " |  \n",
            " |  get_vocabulary(self, include_special_tokens=True)\n",
            " |      Returns the current vocabulary of the layer.\n",
            " |      \n",
            " |      Args:\n",
            " |        include_special_tokens: If True, the returned vocabulary will include\n",
            " |          the padding and OOV tokens, and a term's index in the vocabulary will\n",
            " |          equal the term's index when calling the layer. If False, the returned\n",
            " |          vocabulary will not include any padding or OOV tokens.\n",
            " |  \n",
            " |  reset_state(self)\n",
            " |      Resets the statistics of the preprocessing layer.\n",
            " |  \n",
            " |  set_vocabulary(self, vocabulary, idf_weights=None)\n",
            " |      Sets vocabulary (and optionally document frequency) data for this layer.\n",
            " |      \n",
            " |      This method sets the vocabulary and idf weights for this layer directly,\n",
            " |      instead of analyzing a dataset through 'adapt'. It should be used whenever\n",
            " |      the vocab (and optionally document frequency) information is already known.\n",
            " |      If vocabulary data is already present in the layer, this method will replace\n",
            " |      it.\n",
            " |      \n",
            " |      Args:\n",
            " |        vocabulary: Either an array or a string path to a text file. If passing an\n",
            " |          array, can pass a tuple, list, 1D numpy array, or 1D tensor containing\n",
            " |          the vocbulary terms. If passing a file path, the file should contain one\n",
            " |          line per term in the vocabulary.\n",
            " |        idf_weights: A tuple, list, 1D numpy array, or 1D tensor of inverse\n",
            " |          document frequency weights with equal length to vocabulary. Must be set\n",
            " |          if `output_mode` is `\"tf_idf\"`. Should not be set otherwise.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: If there are too many inputs, the inputs do not match, or\n",
            " |          input data is missing.\n",
            " |        RuntimeError: If the vocabulary cannot be set when this function is\n",
            " |          called. This happens when `\"multi_hot\"`, `\"count\"`, and \"tf_idf\" modes,\n",
            " |          if `pad_to_max_tokens` is False and the layer itself has already been\n",
            " |          called.\n",
            " |  \n",
            " |  update_state(self, data)\n",
            " |      Accumulates statistics for the preprocessing layer.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        data: A mini-batch of inputs to the layer.\n",
            " |  \n",
            " |  vocabulary_size(self)\n",
            " |      Gets the current size of the layer's vocabulary.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The integer size of the voculary, including optional mask and oov indices.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __abstractmethods__ = frozenset()\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from keras.engine.base_preprocessing_layer.PreprocessingLayer:\n",
            " |  \n",
            " |  adapt(self, data, batch_size=None, steps=None)\n",
            " |      Fits the state of the preprocessing layer to the data being passed.\n",
            " |      \n",
            " |      After calling `adapt` on a layer, a preprocessing layer's state will not\n",
            " |      update during training. In order to make preprocessing layers efficient in\n",
            " |      any distribution context, they are kept constant with respect to any\n",
            " |      compiled `tf.Graph`s that call the layer. This does not affect the layer use\n",
            " |      when adapting each layer only once, but if you adapt a layer multiple times\n",
            " |      you will need to take care to re-compile any compiled functions as follows:\n",
            " |      \n",
            " |       * If you are adding a preprocessing layer to a `keras.Model`, you need to\n",
            " |         call `model.compile` after each subsequent call to `adapt`.\n",
            " |       * If you are calling a preprocessing layer inside `tf.data.Dataset.map`,\n",
            " |         you should call `map` again on the input `tf.data.Dataset` after each\n",
            " |         `adapt`.\n",
            " |       * If you are using a `tf.function` directly which calls a preprocessing\n",
            " |         layer, you need to call `tf.function` again on your callable after\n",
            " |         each subsequent call to `adapt`.\n",
            " |      \n",
            " |      `tf.keras.Model` example with multiple adapts:\n",
            " |      \n",
            " |      >>> layer = tf.keras.layers.experimental.preprocessing.Normalization(\n",
            " |      ...     axis=None)\n",
            " |      >>> layer.adapt([0, 2])\n",
            " |      >>> model = tf.keras.Sequential(layer)\n",
            " |      >>> model.predict([0, 1, 2])\n",
            " |      array([-1.,  0.,  1.], dtype=float32)\n",
            " |      >>> layer.adapt([-1, 1])\n",
            " |      >>> model.compile() # This is needed to re-compile model.predict!\n",
            " |      >>> model.predict([0, 1, 2])\n",
            " |      array([0., 1., 2.], dtype=float32)\n",
            " |      \n",
            " |      `tf.data.Dataset` example with multiple adapts:\n",
            " |      \n",
            " |      >>> layer = tf.keras.layers.experimental.preprocessing.Normalization(\n",
            " |      ...     axis=None)\n",
            " |      >>> layer.adapt([0, 2])\n",
            " |      >>> input_ds = tf.data.Dataset.range(3)\n",
            " |      >>> normalized_ds = input_ds.map(layer)\n",
            " |      >>> list(normalized_ds.as_numpy_iterator())\n",
            " |      [array([-1.], dtype=float32),\n",
            " |       array([0.], dtype=float32),\n",
            " |       array([1.], dtype=float32)]\n",
            " |      >>> layer.adapt([-1, 1])\n",
            " |      >>> normalized_ds = input_ds.map(layer) # Re-map over the input dataset.\n",
            " |      >>> list(normalized_ds.as_numpy_iterator())\n",
            " |      [array([0.], dtype=float32),\n",
            " |       array([1.], dtype=float32),\n",
            " |       array([2.], dtype=float32)]\n",
            " |      \n",
            " |      Arguments:\n",
            " |          data: The data to train on. It can be passed either as a tf.data\n",
            " |            Dataset, or as a numpy array.\n",
            " |          batch_size: Integer or `None`.\n",
            " |              Number of samples per state update.\n",
            " |              If unspecified, `batch_size` will default to 32.\n",
            " |              Do not specify the `batch_size` if your data is in the\n",
            " |              form of datasets, generators, or `keras.utils.Sequence` instances\n",
            " |              (since they generate batches).\n",
            " |          steps: Integer or `None`.\n",
            " |              Total number of steps (batches of samples)\n",
            " |              When training with input tensors such as\n",
            " |              TensorFlow data tensors, the default `None` is equal to\n",
            " |              the number of samples in your dataset divided by\n",
            " |              the batch size, or 1 if that cannot be determined. If x is a\n",
            " |              `tf.data` dataset, and 'steps' is None, the epoch will run until\n",
            " |              the input dataset is exhausted. When passing an infinitely\n",
            " |              repeating dataset, you must specify the `steps` argument. This\n",
            " |              argument is not supported with array inputs.\n",
            " |  \n",
            " |  compile(self, run_eagerly=None, steps_per_execution=None)\n",
            " |      Configures the layer for `adapt`.\n",
            " |      \n",
            " |      Arguments:\n",
            " |        run_eagerly: Bool. Defaults to `False`. If `True`, this `Model`'s logic\n",
            " |          will not be wrapped in a `tf.function`. Recommended to leave this as\n",
            " |          `None` unless your `Model` cannot be run inside a `tf.function`.\n",
            " |          steps_per_execution: Int. Defaults to 1. The number of batches to run\n",
            " |            during each `tf.function` call. Running multiple batches inside a\n",
            " |            single `tf.function` call can greatly improve performance on TPUs or\n",
            " |            small models with a large Python overhead.\n",
            " |  \n",
            " |  make_adapt_function(self)\n",
            " |      Creates a function to execute one step of `adapt`.\n",
            " |      \n",
            " |      This method can be overridden to support custom adapt logic.\n",
            " |      This method is called by `PreprocessingLayer.adapt`.\n",
            " |      \n",
            " |      Typically, this method directly controls `tf.function` settings,\n",
            " |      and delegates the actual state update logic to\n",
            " |      `PreprocessingLayer.update_state`.\n",
            " |      \n",
            " |      This function is cached the first time `PreprocessingLayer.adapt`\n",
            " |      is called. The cache is cleared whenever `PreprocessingLayer.compile`\n",
            " |      is called.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Function. The function created by this method should accept a\n",
            " |        `tf.data.Iterator`, retrieve a batch, and update the state of the\n",
            " |        layer.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from keras.engine.base_preprocessing_layer.PreprocessingLayer:\n",
            " |  \n",
            " |  is_adapted\n",
            " |      Whether the layer has been fit to data already.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  __call__(self, *args, **kwargs)\n",
            " |      Wraps `call`, applying pre- and post-processing steps.\n",
            " |      \n",
            " |      Args:\n",
            " |        *args: Positional arguments to be passed to `self.call`.\n",
            " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor(s).\n",
            " |      \n",
            " |      Note:\n",
            " |        - The following optional keyword arguments are reserved for specific uses:\n",
            " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
            " |            whether the `call` is meant for training or inference.\n",
            " |          * `mask`: Boolean input mask.\n",
            " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
            " |          layers do), its default value will be set to the mask generated\n",
            " |          for `inputs` by the previous layer (if `input` did come from\n",
            " |          a layer that generated a corresponding mask, i.e. if it came from\n",
            " |          a Keras layer with masking support.\n",
            " |        - If the layer is not built, the method will call `build`.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
            " |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
            " |  \n",
            " |  __delattr__(self, name)\n",
            " |      Implement delattr(self, name).\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __setattr__(self, name, value)\n",
            " |      Support self.foo = trackable syntax.\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  add_loss(self, losses, **kwargs)\n",
            " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
            " |      \n",
            " |      Some losses (for instance, activity regularization losses) may be dependent\n",
            " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
            " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
            " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
            " |      of dependencies.\n",
            " |      \n",
            " |      This method can be used inside a subclassed layer or model's `call`\n",
            " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      class MyLayer(tf.keras.layers.Layer):\n",
            " |        def call(self, inputs):\n",
            " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
            " |          return inputs\n",
            " |      ```\n",
            " |      \n",
            " |      This method can also be called directly on a Functional Model during\n",
            " |      construction. In this case, any loss Tensors passed to this Model must\n",
            " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
            " |      losses become part of the model's topology and are tracked in `get_config`.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      # Activity regularization.\n",
            " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
            " |      ```\n",
            " |      \n",
            " |      If this is not the case for your loss (if, for example, your loss references\n",
            " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
            " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
            " |      topology since they can't be serialized.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      d = tf.keras.layers.Dense(10)\n",
            " |      x = d(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      # Weight regularization.\n",
            " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
            " |          may also be zero-argument callables which create a loss tensor.\n",
            " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
            " |          Accepted values:\n",
            " |            inputs - Deprecated, will be automatically inferred.\n",
            " |  \n",
            " |  add_metric(self, value, name=None, **kwargs)\n",
            " |      Adds metric tensor to the layer.\n",
            " |      \n",
            " |      This method can be used inside the `call()` method of a subclassed layer\n",
            " |      or model.\n",
            " |      \n",
            " |      ```python\n",
            " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
            " |        def __init__(self):\n",
            " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
            " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
            " |      \n",
            " |        def call(self, inputs):\n",
            " |          self.add_metric(self.mean(inputs))\n",
            " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
            " |          return inputs\n",
            " |      ```\n",
            " |      \n",
            " |      This method can also be called directly on a Functional Model during\n",
            " |      construction. In this case, any tensor passed to this Model must\n",
            " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
            " |      metrics become part of the model's topology and are tracked when you\n",
            " |      save the model via `save()`.\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
            " |      ```\n",
            " |      \n",
            " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
            " |      Functional Model, as shown in the example below, is not supported. This is\n",
            " |      because we cannot trace the metric result tensor back to the model's inputs.\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        value: Metric tensor.\n",
            " |        name: String metric name.\n",
            " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
            " |          Accepted values:\n",
            " |          `aggregation` - When the `value` tensor provided is not the result of\n",
            " |          calling a `keras.Metric` instance, it will be aggregated by default\n",
            " |          using a `keras.Metric.Mean`.\n",
            " |  \n",
            " |  add_update(self, updates, inputs=None)\n",
            " |      Add update op(s), potentially dependent on layer inputs.\n",
            " |      \n",
            " |      Weight updates (for instance, the updates of the moving mean and variance\n",
            " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
            " |      when calling a layer. Hence, when reusing the same layer on\n",
            " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
            " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
            " |      of dependencies.\n",
            " |      \n",
            " |      This call is ignored when eager execution is enabled (in that case, variable\n",
            " |      updates are run on the fly and thus do not need to be tracked for later\n",
            " |      execution).\n",
            " |      \n",
            " |      Args:\n",
            " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
            " |          that returns an update op. A zero-arg callable should be passed in\n",
            " |          order to disable running the updates by setting `trainable=False`\n",
            " |          on this Layer, when executing in Eager mode.\n",
            " |        inputs: Deprecated, will be automatically inferred.\n",
            " |  \n",
            " |  add_variable(self, *args, **kwargs)\n",
            " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
            " |  \n",
            " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregationV2.NONE: 0>, **kwargs)\n",
            " |      Adds a new variable to the layer.\n",
            " |      \n",
            " |      Args:\n",
            " |        name: Variable name.\n",
            " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
            " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
            " |        initializer: Initializer instance (callable).\n",
            " |        regularizer: Regularizer instance (callable).\n",
            " |        trainable: Boolean, whether the variable should be part of the layer's\n",
            " |          \"trainable_variables\" (e.g. variables, biases)\n",
            " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
            " |          Note that `trainable` cannot be `True` if `synchronization`\n",
            " |          is set to `ON_READ`.\n",
            " |        constraint: Constraint instance (callable).\n",
            " |        use_resource: Whether to use `ResourceVariable`.\n",
            " |        synchronization: Indicates when a distributed a variable will be\n",
            " |          aggregated. Accepted values are constants defined in the class\n",
            " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
            " |          `AUTO` and the current `DistributionStrategy` chooses\n",
            " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
            " |          `trainable` must not be set to `True`.\n",
            " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
            " |          Accepted values are constants defined in the class\n",
            " |          `tf.VariableAggregation`.\n",
            " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
            " |          `collections`, `experimental_autocast` and `caching_device`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The variable created.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: When giving unsupported dtype and no initializer or when\n",
            " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
            " |  \n",
            " |  apply(self, inputs, *args, **kwargs)\n",
            " |      Deprecated, do NOT use!\n",
            " |      \n",
            " |      This is an alias of `self.__call__`.\n",
            " |      \n",
            " |      Args:\n",
            " |        inputs: Input tensor(s).\n",
            " |        *args: additional positional arguments to be passed to `self.call`.\n",
            " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor(s).\n",
            " |  \n",
            " |  compute_mask(self, inputs, mask=None)\n",
            " |      Computes an output mask tensor.\n",
            " |      \n",
            " |      Args:\n",
            " |          inputs: Tensor or list of tensors.\n",
            " |          mask: Tensor or list of tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |          None or a tensor (or list of tensors,\n",
            " |              one per output tensor of the layer).\n",
            " |  \n",
            " |  count_params(self)\n",
            " |      Count the total number of scalars composing the weights.\n",
            " |      \n",
            " |      Returns:\n",
            " |          An integer count.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: if the layer isn't yet built\n",
            " |            (in which case its weights aren't yet defined).\n",
            " |  \n",
            " |  get_input_at(self, node_index)\n",
            " |      Retrieves the input tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first input node of the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_input_mask_at(self, node_index)\n",
            " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A mask tensor\n",
            " |          (or list of tensors if the layer has multiple inputs).\n",
            " |  \n",
            " |  get_input_shape_at(self, node_index)\n",
            " |      Retrieves the input shape(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A shape tuple\n",
            " |          (or list of shape tuples if the layer has multiple inputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_losses_for(self, inputs)\n",
            " |      Deprecated, do NOT use!\n",
            " |      \n",
            " |      Retrieves losses relevant to a specific set of inputs.\n",
            " |      \n",
            " |      Args:\n",
            " |        inputs: Input tensor or list/tuple of input tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |        List of loss tensors of the layer that depend on `inputs`.\n",
            " |  \n",
            " |  get_output_at(self, node_index)\n",
            " |      Retrieves the output tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first output node of the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_output_mask_at(self, node_index)\n",
            " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A mask tensor\n",
            " |          (or list of tensors if the layer has multiple outputs).\n",
            " |  \n",
            " |  get_output_shape_at(self, node_index)\n",
            " |      Retrieves the output shape(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A shape tuple\n",
            " |          (or list of shape tuples if the layer has multiple outputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_updates_for(self, inputs)\n",
            " |      Deprecated, do NOT use!\n",
            " |      \n",
            " |      Retrieves updates relevant to a specific set of inputs.\n",
            " |      \n",
            " |      Args:\n",
            " |        inputs: Input tensor or list/tuple of input tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |        List of update ops of the layer that depend on `inputs`.\n",
            " |  \n",
            " |  get_weights(self)\n",
            " |      Returns the current weights of the layer, as NumPy arrays.\n",
            " |      \n",
            " |      The weights of a layer represent the state of the layer. This function\n",
            " |      returns both trainable and non-trainable weight values associated with this\n",
            " |      layer as a list of NumPy arrays, which can in turn be used to load state\n",
            " |      into similarly parameterized layers.\n",
            " |      \n",
            " |      For example, a `Dense` layer returns a list of two values: the kernel matrix\n",
            " |      and the bias vector. These can be used to set the weights of another\n",
            " |      `Dense` layer:\n",
            " |      \n",
            " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
            " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
            " |      >>> layer_a.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
            " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
            " |      >>> layer_b.get_weights()\n",
            " |      [array([[2.],\n",
            " |             [2.],\n",
            " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
            " |      >>> layer_b.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      \n",
            " |      Returns:\n",
            " |          Weights values as a list of NumPy arrays.\n",
            " |  \n",
            " |  set_weights(self, weights)\n",
            " |      Sets the weights of the layer, from NumPy arrays.\n",
            " |      \n",
            " |      The weights of a layer represent the state of the layer. This function\n",
            " |      sets the weight values from numpy arrays. The weight values should be\n",
            " |      passed in the order they are created by the layer. Note that the layer's\n",
            " |      weights must be instantiated before calling this function, by calling\n",
            " |      the layer.\n",
            " |      \n",
            " |      For example, a `Dense` layer returns a list of two values: the kernel matrix\n",
            " |      and the bias vector. These can be used to set the weights of another\n",
            " |      `Dense` layer:\n",
            " |      \n",
            " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
            " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
            " |      >>> layer_a.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
            " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
            " |      >>> layer_b.get_weights()\n",
            " |      [array([[2.],\n",
            " |             [2.],\n",
            " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
            " |      >>> layer_b.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      \n",
            " |      Args:\n",
            " |        weights: a list of NumPy arrays. The number\n",
            " |          of arrays and their shape must match\n",
            " |          number of the dimensions of the weights\n",
            " |          of the layer (i.e. it should match the\n",
            " |          output of `get_weights`).\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: If the provided weights list does not match the\n",
            " |          layer's specifications.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  from_config(config) from abc.ABCMeta\n",
            " |      Creates a layer from its config.\n",
            " |      \n",
            " |      This method is the reverse of `get_config`,\n",
            " |      capable of instantiating the same layer from the config\n",
            " |      dictionary. It does not handle layer connectivity\n",
            " |      (handled by Network), nor weights (handled by `set_weights`).\n",
            " |      \n",
            " |      Args:\n",
            " |          config: A Python dictionary, typically the\n",
            " |              output of get_config.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A layer instance.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  compute_dtype\n",
            " |      The dtype of the layer's computations.\n",
            " |      \n",
            " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
            " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
            " |      the weights.\n",
            " |      \n",
            " |      Layers automatically cast their inputs to the compute dtype, which causes\n",
            " |      computations and the output to be in the compute dtype as well. This is done\n",
            " |      by the base Layer class in `Layer.__call__`, so you do not have to insert\n",
            " |      these casts if implementing your own layer.\n",
            " |      \n",
            " |      Layers often perform certain internal computations in higher precision when\n",
            " |      `compute_dtype` is float16 or bfloat16 for numeric stability. The output\n",
            " |      will still typically be float16 or bfloat16 in such cases.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The layer's compute dtype.\n",
            " |  \n",
            " |  dtype\n",
            " |      The dtype of the layer weights.\n",
            " |      \n",
            " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
            " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
            " |      dtype of the layer's computations.\n",
            " |  \n",
            " |  dtype_policy\n",
            " |      The dtype policy associated with this layer.\n",
            " |      \n",
            " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
            " |  \n",
            " |  dynamic\n",
            " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
            " |  \n",
            " |  inbound_nodes\n",
            " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
            " |  \n",
            " |  input\n",
            " |      Retrieves the input tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one input,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input tensor or list of input tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |        AttributeError: If no inbound nodes are found.\n",
            " |  \n",
            " |  input_mask\n",
            " |      Retrieves the input mask tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one inbound node,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input mask tensor (potentially None) or list of input\n",
            " |          mask tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer is connected to\n",
            " |          more than one incoming layers.\n",
            " |  \n",
            " |  input_shape\n",
            " |      Retrieves the input shape(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one input,\n",
            " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
            " |      have the same shape.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input shape, as an integer shape tuple\n",
            " |          (or list of shape tuples, one tuple per input tensor).\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer has no defined input_shape.\n",
            " |          RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  losses\n",
            " |      List of losses added using the `add_loss()` API.\n",
            " |      \n",
            " |      Variable regularization tensors are created when this property is accessed,\n",
            " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
            " |      propagate gradients back to the corresponding variables.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
            " |      ...   def call(self, inputs):\n",
            " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
            " |      ...     return inputs\n",
            " |      >>> l = MyLayer()\n",
            " |      >>> l(np.ones((10, 1)))\n",
            " |      >>> l.losses\n",
            " |      [1.0]\n",
            " |      \n",
            " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
            " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      >>> model = tf.keras.Model(inputs, outputs)\n",
            " |      >>> # Activity regularization.\n",
            " |      >>> len(model.losses)\n",
            " |      0\n",
            " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
            " |      >>> len(model.losses)\n",
            " |      1\n",
            " |      \n",
            " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
            " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
            " |      >>> x = d(inputs)\n",
            " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      >>> model = tf.keras.Model(inputs, outputs)\n",
            " |      >>> # Weight regularization.\n",
            " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
            " |      >>> model.losses\n",
            " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of tensors.\n",
            " |  \n",
            " |  metrics\n",
            " |      List of metrics added using the `add_metric()` API.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      >>> input = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> d = tf.keras.layers.Dense(2)\n",
            " |      >>> output = d(input)\n",
            " |      >>> d.add_metric(tf.reduce_max(output), name='max')\n",
            " |      >>> d.add_metric(tf.reduce_min(output), name='min')\n",
            " |      >>> [m.name for m in d.metrics]\n",
            " |      ['max', 'min']\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of `Metric` objects.\n",
            " |  \n",
            " |  name\n",
            " |      Name of the layer (string), set in the constructor.\n",
            " |  \n",
            " |  non_trainable_variables\n",
            " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
            " |      \n",
            " |      Note: this method uses reflection to find variables on the current instance\n",
            " |      and submodules. For performance reasons you may wish to cache the result\n",
            " |      of calling this method if you don't expect the return value to change.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of variables for the current module (sorted by attribute\n",
            " |        name) followed by variables from all submodules recursively (breadth\n",
            " |        first).\n",
            " |  \n",
            " |  non_trainable_weights\n",
            " |      List of all non-trainable weights tracked by this layer.\n",
            " |      \n",
            " |      Non-trainable weights are *not* updated during training. They are expected\n",
            " |      to be updated manually in `call()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of non-trainable variables.\n",
            " |  \n",
            " |  outbound_nodes\n",
            " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
            " |  \n",
            " |  output\n",
            " |      Retrieves the output tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one output,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor or list of output tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |        AttributeError: if the layer is connected to more than one incoming\n",
            " |          layers.\n",
            " |        RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  output_mask\n",
            " |      Retrieves the output mask tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one inbound node,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Output mask tensor (potentially None) or list of output\n",
            " |          mask tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer is connected to\n",
            " |          more than one incoming layers.\n",
            " |  \n",
            " |  output_shape\n",
            " |      Retrieves the output shape(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has one output,\n",
            " |      or if all outputs have the same shape.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Output shape, as an integer shape tuple\n",
            " |          (or list of shape tuples, one tuple per output tensor).\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer has no defined output shape.\n",
            " |          RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  trainable_variables\n",
            " |      Sequence of trainable variables owned by this module and its submodules.\n",
            " |      \n",
            " |      Note: this method uses reflection to find variables on the current instance\n",
            " |      and submodules. For performance reasons you may wish to cache the result\n",
            " |      of calling this method if you don't expect the return value to change.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of variables for the current module (sorted by attribute\n",
            " |        name) followed by variables from all submodules recursively (breadth\n",
            " |        first).\n",
            " |  \n",
            " |  trainable_weights\n",
            " |      List of all trainable weights tracked by this layer.\n",
            " |      \n",
            " |      Trainable weights are updated via gradient descent during training.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of trainable variables.\n",
            " |  \n",
            " |  updates\n",
            " |  \n",
            " |  variable_dtype\n",
            " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
            " |  \n",
            " |  variables\n",
            " |      Returns the list of all layer variables/weights.\n",
            " |      \n",
            " |      Alias of `self.weights`.\n",
            " |      \n",
            " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
            " |      themselves Keras layers.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of variables.\n",
            " |  \n",
            " |  weights\n",
            " |      Returns the list of all layer variables/weights.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of variables.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  activity_regularizer\n",
            " |      Optional regularizer function for the output of this layer.\n",
            " |  \n",
            " |  input_spec\n",
            " |      `InputSpec` instance(s) describing the input format for this layer.\n",
            " |      \n",
            " |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
            " |      the layer to run input compatibility checks when it is called.\n",
            " |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
            " |      of rank 4. As such, you can set, in `__init__()`:\n",
            " |      \n",
            " |      ```python\n",
            " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
            " |      ```\n",
            " |      \n",
            " |      Now, if you try to call the layer on an input that isn't rank 4\n",
            " |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
            " |      error:\n",
            " |      \n",
            " |      ```\n",
            " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
            " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
            " |      ```\n",
            " |      \n",
            " |      Input checks that can be specified via `input_spec` include:\n",
            " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
            " |      - Shape\n",
            " |      - Rank (ndim)\n",
            " |      - Dtype\n",
            " |      \n",
            " |      For more information, see `tf.keras.layers.InputSpec`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
            " |  \n",
            " |  stateful\n",
            " |  \n",
            " |  supports_masking\n",
            " |      Whether this layer supports computing a mask using `compute_mask`.\n",
            " |  \n",
            " |  trainable\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
            " |  \n",
            " |  with_name_scope(method) from abc.ABCMeta\n",
            " |      Decorator to automatically enter the module name scope.\n",
            " |      \n",
            " |      >>> class MyModule(tf.Module):\n",
            " |      ...   @tf.Module.with_name_scope\n",
            " |      ...   def __call__(self, x):\n",
            " |      ...     if not hasattr(self, 'w'):\n",
            " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
            " |      ...     return tf.matmul(x, self.w)\n",
            " |      \n",
            " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
            " |      names included the module name:\n",
            " |      \n",
            " |      >>> mod = MyModule()\n",
            " |      >>> mod(tf.ones([1, 2]))\n",
            " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
            " |      >>> mod.w\n",
            " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
            " |      numpy=..., dtype=float32)>\n",
            " |      \n",
            " |      Args:\n",
            " |        method: The method to wrap.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The original method wrapped such that it enters the module's name scope.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
            " |  \n",
            " |  name_scope\n",
            " |      Returns a `tf.name_scope` instance for this class.\n",
            " |  \n",
            " |  submodules\n",
            " |      Sequence of all sub-modules.\n",
            " |      \n",
            " |      Submodules are modules which are properties of this module, or found as\n",
            " |      properties of modules which are properties of this module (and so on).\n",
            " |      \n",
            " |      >>> a = tf.Module()\n",
            " |      >>> b = tf.Module()\n",
            " |      >>> c = tf.Module()\n",
            " |      >>> a.b = b\n",
            " |      >>> b.c = c\n",
            " |      >>> list(a.submodules) == [b, c]\n",
            " |      True\n",
            " |      >>> list(b.submodules) == [c]\n",
            " |      True\n",
            " |      >>> list(c.submodules) == []\n",
            " |      True\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of all submodules.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods inherited from keras.utils.version_utils.LayerVersionSelector:\n",
            " |  \n",
            " |  __new__(cls, *args, **kwargs)\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(TextVectorization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "sMZ-loQtD9N6"
      },
      "outputs": [],
      "source": [
        "model1 = Sequential()\n",
        "\n",
        "# model1.add(Input(shape=(1,), dtype=tf.string))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "Ttlbx7G3D-c4"
      },
      "outputs": [],
      "source": [
        "tf_layer = TextVectorization(output_mode='int')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "TRrCHApaFpNv"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "in user code:\n\n    File \"C:\\Users\\rahul\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py\", line 117, in adapt_step  *\n        self._adapt_maybe_build(data)\n    File \"C:\\Users\\rahul\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py\", line 280, in _adapt_maybe_build  **\n        self.build(data_shape)\n    File \"C:\\Users\\rahul\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\layers\\preprocessing\\text_vectorization.py\", line 446, in build\n        raise RuntimeError(\n\n    RuntimeError: When using TextVectorization to tokenize strings, the innermost dimension of the input array must be 1, got shape (None, 2)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-98-42d252185927>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madapt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrainSet_pos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_numpy_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py\u001b[0m in \u001b[0;36madapt\u001b[1;34m(self, data, batch_size, steps)\u001b[0m\n\u001b[0;32m    242\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_adapt_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1127\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1128\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1129\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1130\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\rahul\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py\", line 117, in adapt_step  *\n        self._adapt_maybe_build(data)\n    File \"C:\\Users\\rahul\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\engine\\base_preprocessing_layer.py\", line 280, in _adapt_maybe_build  **\n        self.build(data_shape)\n    File \"C:\\Users\\rahul\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\layers\\preprocessing\\text_vectorization.py\", line 446, in build\n        raise RuntimeError(\n\n    RuntimeError: When using TextVectorization to tokenize strings, the innermost dimension of the input array must be 1, got shape (None, 2)\n"
          ]
        }
      ],
      "source": [
        "tf_layer.adapt([i for i in trainSet_pos.take(500).as_numpy_iterator()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "2uLl17BsF0wv"
      },
      "outputs": [],
      "source": [
        "model1.add(tf_layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Jm_F8LIiIHHQ"
      },
      "outputs": [],
      "source": [
        "sample_file = []\n",
        "with open(f'{trainSet_posFp}/7493_7.txt') as file:\n",
        "  sample_file=file.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4QsTMBTyHV3z",
        "outputId": "50b0e0ba-70b4-46f4-bda7-500135a7354a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2831"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_file.count('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pmMXjbWF-XT",
        "outputId": "26b9e00d-3857-4f62-98bf-e99b48698e65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "515"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1.predict([sample_file]).size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4C0MXnhN4h8"
      },
      "source": [
        "## Creating complete train dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "SR8HDtJlGyF6"
      },
      "outputs": [],
      "source": [
        "trainSet = trainSet_pos.concatenate(trainSet_neg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "FqZr07H5O72B"
      },
      "outputs": [],
      "source": [
        "y_pos = tf.repeat(1, repeats=12500)\n",
        "y_neg = tf.repeat(0, repeats=12500)\n",
        "y_train = tf.concat([y_pos, y_neg], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "Invalid `dataset_or_iterator`. `dataset_or_iterator` must be a `tf.data.Dataset` or tf.data.Iterator object, but got <class 'tensorflow.python.framework.ops.EagerTensor'>.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mget_structure\u001b[1;34m(dataset_or_iterator)\u001b[0m\n\u001b[0;32m   4105\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4106\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdataset_or_iterator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melement_spec\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4107\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    441\u001b[0m         np_config.enable_numpy_behavior()\"\"\".format(type(self).__name__, name))\n\u001b[1;32m--> 442\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'element_spec'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-51-842bda274d39>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainSet_complete\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(self, dataset, name)\u001b[0m\n\u001b[0;32m   1244\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1245\u001b[0m     \"\"\"\n\u001b[1;32m-> 1246\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mConcatenateDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mprefetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, dataset_to_concatenate, name)\u001b[0m\n\u001b[0;32m   4842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4843\u001b[0m     \u001b[0moutput_types\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_legacy_output_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4844\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0moutput_types\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mget_legacy_output_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset_to_concatenate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4845\u001b[0m       raise TypeError(f\"Incompatible types of input datasets: {output_types} \"\n\u001b[0;32m   4846\u001b[0m                       f\"vs. {get_legacy_output_types(dataset_to_concatenate)}.\")\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mget_legacy_output_types\u001b[1;34m(dataset_or_iterator)\u001b[0m\n\u001b[0;32m   4174\u001b[0m   return nest.map_structure(\n\u001b[0;32m   4175\u001b[0m       \u001b[1;32mlambda\u001b[0m \u001b[0mcomponent_spec\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mcomponent_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_to_legacy_output_types\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4176\u001b[1;33m       get_structure(dataset_or_iterator))\n\u001b[0m\u001b[0;32m   4177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mget_structure\u001b[1;34m(dataset_or_iterator)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdataset_or_iterator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0melement_spec\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4107\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4108\u001b[1;33m     raise TypeError(f\"Invalid `dataset_or_iterator`. `dataset_or_iterator` \"\n\u001b[0m\u001b[0;32m   4109\u001b[0m                     \u001b[1;34mf\"must be a `tf.data.Dataset` or tf.data.Iterator object, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4110\u001b[0m                     f\"but got {type(dataset_or_iterator)}.\")\n",
            "\u001b[1;31mTypeError\u001b[0m: Invalid `dataset_or_iterator`. `dataset_or_iterator` must be a `tf.data.Dataset` or tf.data.Iterator object, but got <class 'tensorflow.python.framework.ops.EagerTensor'>."
          ]
        }
      ],
      "source": [
        "trainSet_complete = tf.data.Dataset.concatenate(trainSet, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuAvSQFIO93o",
        "outputId": "40ac8b43-d7d3-4601-a868-3b7ea98585cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(25000,), dtype=int32, numpy=array([1, 1, 1, ..., 0, 0, 0])>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "iNvVm-roPpgb"
      },
      "outputs": [],
      "source": [
        "testSet = testSet_pos.concatenate(testSet_neg)\n",
        "y_test_pos = tf.repeat(1, repeats=5000)\n",
        "y_test_neg = tf.repeat(0, repeats=5000)\n",
        "y_test = tf.concat([y_test_pos, y_test_neg], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Fd2H1M3IP_Ts"
      },
      "outputs": [],
      "source": [
        "valSet = valSet_pos.concatenate(valSet_neg)\n",
        "y_val_pos = tf.repeat(1, repeats=7500)\n",
        "y_val_neg = tf.repeat(0, repeats=7500)\n",
        "y_val = tf.concat([y_val_pos, y_val_neg], axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on class Embedding in module keras.layers.embeddings:\n",
            "\n",
            "class Embedding(keras.engine.base_layer.Layer)\n",
            " |  Embedding(input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None, **kwargs)\n",
            " |  \n",
            " |  Turns positive integers (indexes) into dense vectors of fixed size.\n",
            " |  \n",
            " |  e.g. `[[4], [20]] -> [[0.25, 0.1], [0.6, -0.2]]`\n",
            " |  \n",
            " |  This layer can only be used as the first layer in a model.\n",
            " |  \n",
            " |  Example:\n",
            " |  \n",
            " |  >>> model = tf.keras.Sequential()\n",
            " |  >>> model.add(tf.keras.layers.Embedding(1000, 64, input_length=10))\n",
            " |  >>> # The model will take as input an integer matrix of size (batch,\n",
            " |  >>> # input_length), and the largest integer (i.e. word index) in the input\n",
            " |  >>> # should be no larger than 999 (vocabulary size).\n",
            " |  >>> # Now model.output_shape is (None, 10, 64), where `None` is the batch\n",
            " |  >>> # dimension.\n",
            " |  >>> input_array = np.random.randint(1000, size=(32, 10))\n",
            " |  >>> model.compile('rmsprop', 'mse')\n",
            " |  >>> output_array = model.predict(input_array)\n",
            " |  >>> print(output_array.shape)\n",
            " |  (32, 10, 64)\n",
            " |  \n",
            " |  Args:\n",
            " |    input_dim: Integer. Size of the vocabulary,\n",
            " |      i.e. maximum integer index + 1.\n",
            " |    output_dim: Integer. Dimension of the dense embedding.\n",
            " |    embeddings_initializer: Initializer for the `embeddings`\n",
            " |      matrix (see `keras.initializers`).\n",
            " |    embeddings_regularizer: Regularizer function applied to\n",
            " |      the `embeddings` matrix (see `keras.regularizers`).\n",
            " |    embeddings_constraint: Constraint function applied to\n",
            " |      the `embeddings` matrix (see `keras.constraints`).\n",
            " |    mask_zero: Boolean, whether or not the input value 0 is a special \"padding\"\n",
            " |      value that should be masked out.\n",
            " |      This is useful when using recurrent layers\n",
            " |      which may take variable length input.\n",
            " |      If this is `True`, then all subsequent layers\n",
            " |      in the model need to support masking or an exception will be raised.\n",
            " |      If mask_zero is set to True, as a consequence, index 0 cannot be\n",
            " |      used in the vocabulary (input_dim should equal size of\n",
            " |      vocabulary + 1).\n",
            " |    input_length: Length of input sequences, when it is constant.\n",
            " |      This argument is required if you are going to connect\n",
            " |      `Flatten` then `Dense` layers upstream\n",
            " |      (without it, the shape of the dense outputs cannot be computed).\n",
            " |  \n",
            " |  Input shape:\n",
            " |    2D tensor with shape: `(batch_size, input_length)`.\n",
            " |  \n",
            " |  Output shape:\n",
            " |    3D tensor with shape: `(batch_size, input_length, output_dim)`.\n",
            " |  \n",
            " |  **Note on variable placement:**\n",
            " |  By default, if a GPU is available, the embedding matrix will be placed on\n",
            " |  the GPU. This achieves the best performance, but it might cause issues:\n",
            " |  \n",
            " |  - You may be using an optimizer that does not support sparse GPU kernels.\n",
            " |  In this case you will see an error upon training your model.\n",
            " |  - Your embedding matrix may be too large to fit on your GPU. In this case\n",
            " |  you will see an Out Of Memory (OOM) error.\n",
            " |  \n",
            " |  In such cases, you should place the embedding matrix on the CPU memory.\n",
            " |  You can do so with a device scope, as such:\n",
            " |  \n",
            " |  ```python\n",
            " |  with tf.device('cpu:0'):\n",
            " |    embedding_layer = Embedding(...)\n",
            " |    embedding_layer.build()\n",
            " |  ```\n",
            " |  \n",
            " |  The pre-built `embedding_layer` instance can then be added to a `Sequential`\n",
            " |  model (e.g. `model.add(embedding_layer)`), called in a Functional model\n",
            " |  (e.g. `x = embedding_layer(x)`), or used in a subclassed model.\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      Embedding\n",
            " |      keras.engine.base_layer.Layer\n",
            " |      tensorflow.python.module.module.Module\n",
            " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
            " |      tensorflow.python.training.tracking.base.Trackable\n",
            " |      keras.utils.version_utils.LayerVersionSelector\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __init__(self, input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None, **kwargs)\n",
            " |  \n",
            " |  build = wrapper(instance, input_shape)\n",
            " |  \n",
            " |  call(self, inputs)\n",
            " |      This is where the layer's logic lives.\n",
            " |      \n",
            " |      Note here that `call()` method in `tf.keras` is little bit different\n",
            " |      from `keras` API. In `keras` API, you can pass support masking for\n",
            " |      layers as additional arguments. Whereas `tf.keras` has `compute_mask()`\n",
            " |      method to support masking.\n",
            " |      \n",
            " |      Args:\n",
            " |        inputs: Input tensor, or dict/list/tuple of input tensors.\n",
            " |          The first positional `inputs` argument is subject to special rules:\n",
            " |          - `inputs` must be explicitly passed. A layer cannot have zero\n",
            " |            arguments, and `inputs` cannot be provided via the default value\n",
            " |            of a keyword argument.\n",
            " |          - NumPy array or Python scalar values in `inputs` get cast as tensors.\n",
            " |          - Keras mask metadata is only collected from `inputs`.\n",
            " |          - Layers are built (`build(input_shape)` method)\n",
            " |            using shape info from `inputs` only.\n",
            " |          - `input_spec` compatibility is only checked against `inputs`.\n",
            " |          - Mixed precision input casting is only applied to `inputs`.\n",
            " |            If a layer has tensor arguments in `*args` or `**kwargs`, their\n",
            " |            casting behavior in mixed precision should be handled manually.\n",
            " |          - The SavedModel input specification is generated using `inputs` only.\n",
            " |          - Integration with various ecosystem packages like TFMOT, TFLite,\n",
            " |            TF.js, etc is only supported for `inputs` and not for tensors in\n",
            " |            positional and keyword arguments.\n",
            " |        *args: Additional positional arguments. May contain tensors, although\n",
            " |          this is not recommended, for the reasons above.\n",
            " |        **kwargs: Additional keyword arguments. May contain tensors, although\n",
            " |          this is not recommended, for the reasons above.\n",
            " |          The following optional keyword arguments are reserved:\n",
            " |          - `training`: Boolean scalar tensor of Python boolean indicating\n",
            " |            whether the `call` is meant for training or inference.\n",
            " |          - `mask`: Boolean input mask. If the layer's `call()` method takes a\n",
            " |            `mask` argument, its default value will be set to the mask generated\n",
            " |            for `inputs` by the previous layer (if `input` did come from a layer\n",
            " |            that generated a corresponding mask, i.e. if it came from a Keras\n",
            " |            layer with masking support).\n",
            " |      \n",
            " |      Returns:\n",
            " |        A tensor or list/tuple of tensors.\n",
            " |  \n",
            " |  compute_mask(self, inputs, mask=None)\n",
            " |      Computes an output mask tensor.\n",
            " |      \n",
            " |      Args:\n",
            " |          inputs: Tensor or list of tensors.\n",
            " |          mask: Tensor or list of tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |          None or a tensor (or list of tensors,\n",
            " |              one per output tensor of the layer).\n",
            " |  \n",
            " |  compute_output_shape = wrapper(instance, input_shape)\n",
            " |  \n",
            " |  get_config(self)\n",
            " |      Returns the config of the layer.\n",
            " |      \n",
            " |      A layer config is a Python dictionary (serializable)\n",
            " |      containing the configuration of a layer.\n",
            " |      The same layer can be reinstantiated later\n",
            " |      (without its trained weights) from this configuration.\n",
            " |      \n",
            " |      The config of a layer does not include connectivity\n",
            " |      information, nor the layer class name. These are handled\n",
            " |      by `Network` (one layer of abstraction above).\n",
            " |      \n",
            " |      Note that `get_config()` does not guarantee to return a fresh copy of dict\n",
            " |      every time it is called. The callers should make a copy of the returned dict\n",
            " |      if they want to modify it.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Python dictionary.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  __call__(self, *args, **kwargs)\n",
            " |      Wraps `call`, applying pre- and post-processing steps.\n",
            " |      \n",
            " |      Args:\n",
            " |        *args: Positional arguments to be passed to `self.call`.\n",
            " |        **kwargs: Keyword arguments to be passed to `self.call`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor(s).\n",
            " |      \n",
            " |      Note:\n",
            " |        - The following optional keyword arguments are reserved for specific uses:\n",
            " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
            " |            whether the `call` is meant for training or inference.\n",
            " |          * `mask`: Boolean input mask.\n",
            " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
            " |          layers do), its default value will be set to the mask generated\n",
            " |          for `inputs` by the previous layer (if `input` did come from\n",
            " |          a layer that generated a corresponding mask, i.e. if it came from\n",
            " |          a Keras layer with masking support.\n",
            " |        - If the layer is not built, the method will call `build`.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
            " |        RuntimeError: if `super().__init__()` was not called in the constructor.\n",
            " |  \n",
            " |  __delattr__(self, name)\n",
            " |      Implement delattr(self, name).\n",
            " |  \n",
            " |  __getstate__(self)\n",
            " |  \n",
            " |  __setattr__(self, name, value)\n",
            " |      Support self.foo = trackable syntax.\n",
            " |  \n",
            " |  __setstate__(self, state)\n",
            " |  \n",
            " |  add_loss(self, losses, **kwargs)\n",
            " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
            " |      \n",
            " |      Some losses (for instance, activity regularization losses) may be dependent\n",
            " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
            " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
            " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
            " |      of dependencies.\n",
            " |      \n",
            " |      This method can be used inside a subclassed layer or model's `call`\n",
            " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      class MyLayer(tf.keras.layers.Layer):\n",
            " |        def call(self, inputs):\n",
            " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
            " |          return inputs\n",
            " |      ```\n",
            " |      \n",
            " |      This method can also be called directly on a Functional Model during\n",
            " |      construction. In this case, any loss Tensors passed to this Model must\n",
            " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
            " |      losses become part of the model's topology and are tracked in `get_config`.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      # Activity regularization.\n",
            " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
            " |      ```\n",
            " |      \n",
            " |      If this is not the case for your loss (if, for example, your loss references\n",
            " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
            " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
            " |      topology since they can't be serialized.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      d = tf.keras.layers.Dense(10)\n",
            " |      x = d(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      # Weight regularization.\n",
            " |      model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
            " |          may also be zero-argument callables which create a loss tensor.\n",
            " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
            " |          Accepted values:\n",
            " |            inputs - Deprecated, will be automatically inferred.\n",
            " |  \n",
            " |  add_metric(self, value, name=None, **kwargs)\n",
            " |      Adds metric tensor to the layer.\n",
            " |      \n",
            " |      This method can be used inside the `call()` method of a subclassed layer\n",
            " |      or model.\n",
            " |      \n",
            " |      ```python\n",
            " |      class MyMetricLayer(tf.keras.layers.Layer):\n",
            " |        def __init__(self):\n",
            " |          super(MyMetricLayer, self).__init__(name='my_metric_layer')\n",
            " |          self.mean = tf.keras.metrics.Mean(name='metric_1')\n",
            " |      \n",
            " |        def call(self, inputs):\n",
            " |          self.add_metric(self.mean(inputs))\n",
            " |          self.add_metric(tf.reduce_sum(inputs), name='metric_2')\n",
            " |          return inputs\n",
            " |      ```\n",
            " |      \n",
            " |      This method can also be called directly on a Functional Model during\n",
            " |      construction. In this case, any tensor passed to this Model must\n",
            " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
            " |      metrics become part of the model's topology and are tracked when you\n",
            " |      save the model via `save()`.\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      model.add_metric(math_ops.reduce_sum(x), name='metric_1')\n",
            " |      ```\n",
            " |      \n",
            " |      Note: Calling `add_metric()` with the result of a metric object on a\n",
            " |      Functional Model, as shown in the example below, is not supported. This is\n",
            " |      because we cannot trace the metric result tensor back to the model's inputs.\n",
            " |      \n",
            " |      ```python\n",
            " |      inputs = tf.keras.Input(shape=(10,))\n",
            " |      x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      model = tf.keras.Model(inputs, outputs)\n",
            " |      model.add_metric(tf.keras.metrics.Mean()(x), name='metric_1')\n",
            " |      ```\n",
            " |      \n",
            " |      Args:\n",
            " |        value: Metric tensor.\n",
            " |        name: String metric name.\n",
            " |        **kwargs: Additional keyword arguments for backward compatibility.\n",
            " |          Accepted values:\n",
            " |          `aggregation` - When the `value` tensor provided is not the result of\n",
            " |          calling a `keras.Metric` instance, it will be aggregated by default\n",
            " |          using a `keras.Metric.Mean`.\n",
            " |  \n",
            " |  add_update(self, updates, inputs=None)\n",
            " |      Add update op(s), potentially dependent on layer inputs.\n",
            " |      \n",
            " |      Weight updates (for instance, the updates of the moving mean and variance\n",
            " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
            " |      when calling a layer. Hence, when reusing the same layer on\n",
            " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
            " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
            " |      of dependencies.\n",
            " |      \n",
            " |      This call is ignored when eager execution is enabled (in that case, variable\n",
            " |      updates are run on the fly and thus do not need to be tracked for later\n",
            " |      execution).\n",
            " |      \n",
            " |      Args:\n",
            " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
            " |          that returns an update op. A zero-arg callable should be passed in\n",
            " |          order to disable running the updates by setting `trainable=False`\n",
            " |          on this Layer, when executing in Eager mode.\n",
            " |        inputs: Deprecated, will be automatically inferred.\n",
            " |  \n",
            " |  add_variable(self, *args, **kwargs)\n",
            " |      Deprecated, do NOT use! Alias for `add_weight`.\n",
            " |  \n",
            " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregationV2.NONE: 0>, **kwargs)\n",
            " |      Adds a new variable to the layer.\n",
            " |      \n",
            " |      Args:\n",
            " |        name: Variable name.\n",
            " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
            " |        dtype: The type of the variable. Defaults to `self.dtype`.\n",
            " |        initializer: Initializer instance (callable).\n",
            " |        regularizer: Regularizer instance (callable).\n",
            " |        trainable: Boolean, whether the variable should be part of the layer's\n",
            " |          \"trainable_variables\" (e.g. variables, biases)\n",
            " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
            " |          Note that `trainable` cannot be `True` if `synchronization`\n",
            " |          is set to `ON_READ`.\n",
            " |        constraint: Constraint instance (callable).\n",
            " |        use_resource: Whether to use `ResourceVariable`.\n",
            " |        synchronization: Indicates when a distributed a variable will be\n",
            " |          aggregated. Accepted values are constants defined in the class\n",
            " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
            " |          `AUTO` and the current `DistributionStrategy` chooses\n",
            " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
            " |          `trainable` must not be set to `True`.\n",
            " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
            " |          Accepted values are constants defined in the class\n",
            " |          `tf.VariableAggregation`.\n",
            " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
            " |          `collections`, `experimental_autocast` and `caching_device`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The variable created.\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: When giving unsupported dtype and no initializer or when\n",
            " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
            " |  \n",
            " |  apply(self, inputs, *args, **kwargs)\n",
            " |      Deprecated, do NOT use!\n",
            " |      \n",
            " |      This is an alias of `self.__call__`.\n",
            " |      \n",
            " |      Args:\n",
            " |        inputs: Input tensor(s).\n",
            " |        *args: additional positional arguments to be passed to `self.call`.\n",
            " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor(s).\n",
            " |  \n",
            " |  compute_output_signature(self, input_signature)\n",
            " |      Compute the output tensor signature of the layer based on the inputs.\n",
            " |      \n",
            " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
            " |      and dtype information for a tensor. This method allows layers to provide\n",
            " |      output dtype information if it is different from the input dtype.\n",
            " |      For any layer that doesn't implement this function,\n",
            " |      the framework will fall back to use `compute_output_shape`, and will\n",
            " |      assume that the output dtype matches the input dtype.\n",
            " |      \n",
            " |      Args:\n",
            " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
            " |          objects, describing a candidate input for the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
            " |          how the layer would transform the provided input.\n",
            " |      \n",
            " |      Raises:\n",
            " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
            " |  \n",
            " |  count_params(self)\n",
            " |      Count the total number of scalars composing the weights.\n",
            " |      \n",
            " |      Returns:\n",
            " |          An integer count.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ValueError: if the layer isn't yet built\n",
            " |            (in which case its weights aren't yet defined).\n",
            " |  \n",
            " |  finalize_state(self)\n",
            " |      Finalizes the layers state after updating layer weights.\n",
            " |      \n",
            " |      This function can be subclassed in a layer and will be called after updating\n",
            " |      a layer weights. It can be overridden to finalize any additional layer state\n",
            " |      after a weight update.\n",
            " |  \n",
            " |  get_input_at(self, node_index)\n",
            " |      Retrieves the input tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first input node of the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_input_mask_at(self, node_index)\n",
            " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A mask tensor\n",
            " |          (or list of tensors if the layer has multiple inputs).\n",
            " |  \n",
            " |  get_input_shape_at(self, node_index)\n",
            " |      Retrieves the input shape(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A shape tuple\n",
            " |          (or list of shape tuples if the layer has multiple inputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_losses_for(self, inputs)\n",
            " |      Deprecated, do NOT use!\n",
            " |      \n",
            " |      Retrieves losses relevant to a specific set of inputs.\n",
            " |      \n",
            " |      Args:\n",
            " |        inputs: Input tensor or list/tuple of input tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |        List of loss tensors of the layer that depend on `inputs`.\n",
            " |  \n",
            " |  get_output_at(self, node_index)\n",
            " |      Retrieves the output tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first output node of the layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_output_mask_at(self, node_index)\n",
            " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A mask tensor\n",
            " |          (or list of tensors if the layer has multiple outputs).\n",
            " |  \n",
            " |  get_output_shape_at(self, node_index)\n",
            " |      Retrieves the output shape(s) of a layer at a given node.\n",
            " |      \n",
            " |      Args:\n",
            " |          node_index: Integer, index of the node\n",
            " |              from which to retrieve the attribute.\n",
            " |              E.g. `node_index=0` will correspond to the\n",
            " |              first time the layer was called.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A shape tuple\n",
            " |          (or list of shape tuples if the layer has multiple outputs).\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |  \n",
            " |  get_updates_for(self, inputs)\n",
            " |      Deprecated, do NOT use!\n",
            " |      \n",
            " |      Retrieves updates relevant to a specific set of inputs.\n",
            " |      \n",
            " |      Args:\n",
            " |        inputs: Input tensor or list/tuple of input tensors.\n",
            " |      \n",
            " |      Returns:\n",
            " |        List of update ops of the layer that depend on `inputs`.\n",
            " |  \n",
            " |  get_weights(self)\n",
            " |      Returns the current weights of the layer, as NumPy arrays.\n",
            " |      \n",
            " |      The weights of a layer represent the state of the layer. This function\n",
            " |      returns both trainable and non-trainable weight values associated with this\n",
            " |      layer as a list of NumPy arrays, which can in turn be used to load state\n",
            " |      into similarly parameterized layers.\n",
            " |      \n",
            " |      For example, a `Dense` layer returns a list of two values: the kernel matrix\n",
            " |      and the bias vector. These can be used to set the weights of another\n",
            " |      `Dense` layer:\n",
            " |      \n",
            " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
            " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
            " |      >>> layer_a.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
            " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
            " |      >>> layer_b.get_weights()\n",
            " |      [array([[2.],\n",
            " |             [2.],\n",
            " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
            " |      >>> layer_b.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      \n",
            " |      Returns:\n",
            " |          Weights values as a list of NumPy arrays.\n",
            " |  \n",
            " |  set_weights(self, weights)\n",
            " |      Sets the weights of the layer, from NumPy arrays.\n",
            " |      \n",
            " |      The weights of a layer represent the state of the layer. This function\n",
            " |      sets the weight values from numpy arrays. The weight values should be\n",
            " |      passed in the order they are created by the layer. Note that the layer's\n",
            " |      weights must be instantiated before calling this function, by calling\n",
            " |      the layer.\n",
            " |      \n",
            " |      For example, a `Dense` layer returns a list of two values: the kernel matrix\n",
            " |      and the bias vector. These can be used to set the weights of another\n",
            " |      `Dense` layer:\n",
            " |      \n",
            " |      >>> layer_a = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(1.))\n",
            " |      >>> a_out = layer_a(tf.convert_to_tensor([[1., 2., 3.]]))\n",
            " |      >>> layer_a.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> layer_b = tf.keras.layers.Dense(1,\n",
            " |      ...   kernel_initializer=tf.constant_initializer(2.))\n",
            " |      >>> b_out = layer_b(tf.convert_to_tensor([[10., 20., 30.]]))\n",
            " |      >>> layer_b.get_weights()\n",
            " |      [array([[2.],\n",
            " |             [2.],\n",
            " |             [2.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      >>> layer_b.set_weights(layer_a.get_weights())\n",
            " |      >>> layer_b.get_weights()\n",
            " |      [array([[1.],\n",
            " |             [1.],\n",
            " |             [1.]], dtype=float32), array([0.], dtype=float32)]\n",
            " |      \n",
            " |      Args:\n",
            " |        weights: a list of NumPy arrays. The number\n",
            " |          of arrays and their shape must match\n",
            " |          number of the dimensions of the weights\n",
            " |          of the layer (i.e. it should match the\n",
            " |          output of `get_weights`).\n",
            " |      \n",
            " |      Raises:\n",
            " |        ValueError: If the provided weights list does not match the\n",
            " |          layer's specifications.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  from_config(config) from builtins.type\n",
            " |      Creates a layer from its config.\n",
            " |      \n",
            " |      This method is the reverse of `get_config`,\n",
            " |      capable of instantiating the same layer from the config\n",
            " |      dictionary. It does not handle layer connectivity\n",
            " |      (handled by Network), nor weights (handled by `set_weights`).\n",
            " |      \n",
            " |      Args:\n",
            " |          config: A Python dictionary, typically the\n",
            " |              output of get_config.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A layer instance.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  compute_dtype\n",
            " |      The dtype of the layer's computations.\n",
            " |      \n",
            " |      This is equivalent to `Layer.dtype_policy.compute_dtype`. Unless\n",
            " |      mixed precision is used, this is the same as `Layer.dtype`, the dtype of\n",
            " |      the weights.\n",
            " |      \n",
            " |      Layers automatically cast their inputs to the compute dtype, which causes\n",
            " |      computations and the output to be in the compute dtype as well. This is done\n",
            " |      by the base Layer class in `Layer.__call__`, so you do not have to insert\n",
            " |      these casts if implementing your own layer.\n",
            " |      \n",
            " |      Layers often perform certain internal computations in higher precision when\n",
            " |      `compute_dtype` is float16 or bfloat16 for numeric stability. The output\n",
            " |      will still typically be float16 or bfloat16 in such cases.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The layer's compute dtype.\n",
            " |  \n",
            " |  dtype\n",
            " |      The dtype of the layer weights.\n",
            " |      \n",
            " |      This is equivalent to `Layer.dtype_policy.variable_dtype`. Unless\n",
            " |      mixed precision is used, this is the same as `Layer.compute_dtype`, the\n",
            " |      dtype of the layer's computations.\n",
            " |  \n",
            " |  dtype_policy\n",
            " |      The dtype policy associated with this layer.\n",
            " |      \n",
            " |      This is an instance of a `tf.keras.mixed_precision.Policy`.\n",
            " |  \n",
            " |  dynamic\n",
            " |      Whether the layer is dynamic (eager-only); set in the constructor.\n",
            " |  \n",
            " |  inbound_nodes\n",
            " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
            " |  \n",
            " |  input\n",
            " |      Retrieves the input tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one input,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input tensor or list of input tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |        RuntimeError: If called in Eager mode.\n",
            " |        AttributeError: If no inbound nodes are found.\n",
            " |  \n",
            " |  input_mask\n",
            " |      Retrieves the input mask tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one inbound node,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input mask tensor (potentially None) or list of input\n",
            " |          mask tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer is connected to\n",
            " |          more than one incoming layers.\n",
            " |  \n",
            " |  input_shape\n",
            " |      Retrieves the input shape(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one input,\n",
            " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
            " |      have the same shape.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Input shape, as an integer shape tuple\n",
            " |          (or list of shape tuples, one tuple per input tensor).\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer has no defined input_shape.\n",
            " |          RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  losses\n",
            " |      List of losses added using the `add_loss()` API.\n",
            " |      \n",
            " |      Variable regularization tensors are created when this property is accessed,\n",
            " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
            " |      propagate gradients back to the corresponding variables.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      >>> class MyLayer(tf.keras.layers.Layer):\n",
            " |      ...   def call(self, inputs):\n",
            " |      ...     self.add_loss(tf.abs(tf.reduce_mean(inputs)))\n",
            " |      ...     return inputs\n",
            " |      >>> l = MyLayer()\n",
            " |      >>> l(np.ones((10, 1)))\n",
            " |      >>> l.losses\n",
            " |      [1.0]\n",
            " |      \n",
            " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
            " |      >>> x = tf.keras.layers.Dense(10)(inputs)\n",
            " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      >>> model = tf.keras.Model(inputs, outputs)\n",
            " |      >>> # Activity regularization.\n",
            " |      >>> len(model.losses)\n",
            " |      0\n",
            " |      >>> model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
            " |      >>> len(model.losses)\n",
            " |      1\n",
            " |      \n",
            " |      >>> inputs = tf.keras.Input(shape=(10,))\n",
            " |      >>> d = tf.keras.layers.Dense(10, kernel_initializer='ones')\n",
            " |      >>> x = d(inputs)\n",
            " |      >>> outputs = tf.keras.layers.Dense(1)(x)\n",
            " |      >>> model = tf.keras.Model(inputs, outputs)\n",
            " |      >>> # Weight regularization.\n",
            " |      >>> model.add_loss(lambda: tf.reduce_mean(d.kernel))\n",
            " |      >>> model.losses\n",
            " |      [<tf.Tensor: shape=(), dtype=float32, numpy=1.0>]\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of tensors.\n",
            " |  \n",
            " |  metrics\n",
            " |      List of metrics added using the `add_metric()` API.\n",
            " |      \n",
            " |      Example:\n",
            " |      \n",
            " |      >>> input = tf.keras.layers.Input(shape=(3,))\n",
            " |      >>> d = tf.keras.layers.Dense(2)\n",
            " |      >>> output = d(input)\n",
            " |      >>> d.add_metric(tf.reduce_max(output), name='max')\n",
            " |      >>> d.add_metric(tf.reduce_min(output), name='min')\n",
            " |      >>> [m.name for m in d.metrics]\n",
            " |      ['max', 'min']\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of `Metric` objects.\n",
            " |  \n",
            " |  name\n",
            " |      Name of the layer (string), set in the constructor.\n",
            " |  \n",
            " |  non_trainable_variables\n",
            " |      Sequence of non-trainable variables owned by this module and its submodules.\n",
            " |      \n",
            " |      Note: this method uses reflection to find variables on the current instance\n",
            " |      and submodules. For performance reasons you may wish to cache the result\n",
            " |      of calling this method if you don't expect the return value to change.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of variables for the current module (sorted by attribute\n",
            " |        name) followed by variables from all submodules recursively (breadth\n",
            " |        first).\n",
            " |  \n",
            " |  non_trainable_weights\n",
            " |      List of all non-trainable weights tracked by this layer.\n",
            " |      \n",
            " |      Non-trainable weights are *not* updated during training. They are expected\n",
            " |      to be updated manually in `call()`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of non-trainable variables.\n",
            " |  \n",
            " |  outbound_nodes\n",
            " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
            " |  \n",
            " |  output\n",
            " |      Retrieves the output tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one output,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |        Output tensor or list of output tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |        AttributeError: if the layer is connected to more than one incoming\n",
            " |          layers.\n",
            " |        RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  output_mask\n",
            " |      Retrieves the output mask tensor(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has exactly one inbound node,\n",
            " |      i.e. if it is connected to one incoming layer.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Output mask tensor (potentially None) or list of output\n",
            " |          mask tensors.\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer is connected to\n",
            " |          more than one incoming layers.\n",
            " |  \n",
            " |  output_shape\n",
            " |      Retrieves the output shape(s) of a layer.\n",
            " |      \n",
            " |      Only applicable if the layer has one output,\n",
            " |      or if all outputs have the same shape.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Output shape, as an integer shape tuple\n",
            " |          (or list of shape tuples, one tuple per output tensor).\n",
            " |      \n",
            " |      Raises:\n",
            " |          AttributeError: if the layer has no defined output shape.\n",
            " |          RuntimeError: if called in Eager mode.\n",
            " |  \n",
            " |  trainable_variables\n",
            " |      Sequence of trainable variables owned by this module and its submodules.\n",
            " |      \n",
            " |      Note: this method uses reflection to find variables on the current instance\n",
            " |      and submodules. For performance reasons you may wish to cache the result\n",
            " |      of calling this method if you don't expect the return value to change.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of variables for the current module (sorted by attribute\n",
            " |        name) followed by variables from all submodules recursively (breadth\n",
            " |        first).\n",
            " |  \n",
            " |  trainable_weights\n",
            " |      List of all trainable weights tracked by this layer.\n",
            " |      \n",
            " |      Trainable weights are updated via gradient descent during training.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of trainable variables.\n",
            " |  \n",
            " |  updates\n",
            " |  \n",
            " |  variable_dtype\n",
            " |      Alias of `Layer.dtype`, the dtype of the weights.\n",
            " |  \n",
            " |  variables\n",
            " |      Returns the list of all layer variables/weights.\n",
            " |      \n",
            " |      Alias of `self.weights`.\n",
            " |      \n",
            " |      Note: This will not track the weights of nested `tf.Modules` that are not\n",
            " |      themselves Keras layers.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of variables.\n",
            " |  \n",
            " |  weights\n",
            " |      Returns the list of all layer variables/weights.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A list of variables.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from keras.engine.base_layer.Layer:\n",
            " |  \n",
            " |  activity_regularizer\n",
            " |      Optional regularizer function for the output of this layer.\n",
            " |  \n",
            " |  input_spec\n",
            " |      `InputSpec` instance(s) describing the input format for this layer.\n",
            " |      \n",
            " |      When you create a layer subclass, you can set `self.input_spec` to enable\n",
            " |      the layer to run input compatibility checks when it is called.\n",
            " |      Consider a `Conv2D` layer: it can only be called on a single input tensor\n",
            " |      of rank 4. As such, you can set, in `__init__()`:\n",
            " |      \n",
            " |      ```python\n",
            " |      self.input_spec = tf.keras.layers.InputSpec(ndim=4)\n",
            " |      ```\n",
            " |      \n",
            " |      Now, if you try to call the layer on an input that isn't rank 4\n",
            " |      (for instance, an input of shape `(2,)`, it will raise a nicely-formatted\n",
            " |      error:\n",
            " |      \n",
            " |      ```\n",
            " |      ValueError: Input 0 of layer conv2d is incompatible with the layer:\n",
            " |      expected ndim=4, found ndim=1. Full shape received: [2]\n",
            " |      ```\n",
            " |      \n",
            " |      Input checks that can be specified via `input_spec` include:\n",
            " |      - Structure (e.g. a single input, a list of 2 inputs, etc)\n",
            " |      - Shape\n",
            " |      - Rank (ndim)\n",
            " |      - Dtype\n",
            " |      \n",
            " |      For more information, see `tf.keras.layers.InputSpec`.\n",
            " |      \n",
            " |      Returns:\n",
            " |        A `tf.keras.layers.InputSpec` instance, or nested structure thereof.\n",
            " |  \n",
            " |  stateful\n",
            " |  \n",
            " |  supports_masking\n",
            " |      Whether this layer supports computing a mask using `compute_mask`.\n",
            " |  \n",
            " |  trainable\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
            " |  \n",
            " |  with_name_scope(method) from builtins.type\n",
            " |      Decorator to automatically enter the module name scope.\n",
            " |      \n",
            " |      >>> class MyModule(tf.Module):\n",
            " |      ...   @tf.Module.with_name_scope\n",
            " |      ...   def __call__(self, x):\n",
            " |      ...     if not hasattr(self, 'w'):\n",
            " |      ...       self.w = tf.Variable(tf.random.normal([x.shape[1], 3]))\n",
            " |      ...     return tf.matmul(x, self.w)\n",
            " |      \n",
            " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
            " |      names included the module name:\n",
            " |      \n",
            " |      >>> mod = MyModule()\n",
            " |      >>> mod(tf.ones([1, 2]))\n",
            " |      <tf.Tensor: shape=(1, 3), dtype=float32, numpy=..., dtype=float32)>\n",
            " |      >>> mod.w\n",
            " |      <tf.Variable 'my_module/Variable:0' shape=(2, 3) dtype=float32,\n",
            " |      numpy=..., dtype=float32)>\n",
            " |      \n",
            " |      Args:\n",
            " |        method: The method to wrap.\n",
            " |      \n",
            " |      Returns:\n",
            " |        The original method wrapped such that it enters the module's name scope.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from tensorflow.python.module.module.Module:\n",
            " |  \n",
            " |  name_scope\n",
            " |      Returns a `tf.name_scope` instance for this class.\n",
            " |  \n",
            " |  submodules\n",
            " |      Sequence of all sub-modules.\n",
            " |      \n",
            " |      Submodules are modules which are properties of this module, or found as\n",
            " |      properties of modules which are properties of this module (and so on).\n",
            " |      \n",
            " |      >>> a = tf.Module()\n",
            " |      >>> b = tf.Module()\n",
            " |      >>> c = tf.Module()\n",
            " |      >>> a.b = b\n",
            " |      >>> b.c = c\n",
            " |      >>> list(a.submodules) == [b, c]\n",
            " |      True\n",
            " |      >>> list(b.submodules) == [c]\n",
            " |      True\n",
            " |      >>> list(c.submodules) == []\n",
            " |      True\n",
            " |      \n",
            " |      Returns:\n",
            " |        A sequence of all submodules.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables (if defined)\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object (if defined)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Static methods inherited from keras.utils.version_utils.LayerVersionSelector:\n",
            " |  \n",
            " |  __new__(cls, *args, **kwargs)\n",
            " |      Create and return a new object.  See help(type) for accurate signature.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "help(Embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "ename": "UnicodeDecodeError",
          "evalue": "'utf-8' codec can't decode byte 0xc3 in position 4: unexpected end of data",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-47-547b0c570a95>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtf_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\layers\\preprocessing\\text_vectorization.py\u001b[0m in \u001b[0;36mget_vocabulary\u001b[1;34m(self, include_special_tokens)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[0mvocabulary\u001b[0m \u001b[0mwill\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minclude\u001b[0m \u001b[0many\u001b[0m \u001b[0mpadding\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mOOV\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m     \"\"\"\n\u001b[1;32m--> 382\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lookup_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_vocabulary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude_special_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mvocabulary_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\layers\\preprocessing\\index_lookup.py\u001b[0m in \u001b[0;36mget_vocabulary\u001b[1;34m(self, include_special_tokens)\u001b[0m\n\u001b[0;32m    321\u001b[0m       \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlookup_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m       \u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minvert\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 323\u001b[1;33m       \u001b[0mvocab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tensor_vocab_to_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    324\u001b[0m     lookup = collections.defaultdict(lambda: self.oov_token,\n\u001b[0;32m    325\u001b[0m                                      zip(indices, vocab))\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\layers\\preprocessing\\string_lookup.py\u001b[0m in \u001b[0;36m_tensor_vocab_to_numpy\u001b[1;34m(self, vocabulary)\u001b[0m\n\u001b[0;32m    348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_tensor_vocab_to_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[0mvocabulary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\layers\\preprocessing\\string_lookup.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    348\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_tensor_vocab_to_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[0mvocabulary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow\\python\\util\\compat.py\u001b[0m in \u001b[0;36mas_text\u001b[1;34m(bytes_or_text, encoding)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbytes_or_text\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytes_or_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mbytes_or_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Expected binary or unicode string, got %r'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbytes_or_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xc3 in position 4: unexpected end of data"
          ]
        }
      ],
      "source": [
        "tf_layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "mZtuhXLzQezE"
      },
      "outputs": [],
      "source": [
        "model1.add(Embedding(input_dim=1050, output_dim=64))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "model1.compile(optimizer='nadam', loss='binary_crossentropy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "`y` argument is not supported when using dataset as input.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m<ipython-input-50-9430c11fbe75>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalSet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m~\\anaconda3\\envs\\tensorflow_env\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_validate_args\u001b[1;34m(self, y, sample_weights, steps)\u001b[0m\n\u001b[0;32m    744\u001b[0m     \u001b[1;31m# Arguments that shouldn't be passed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_none_or_empty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 746\u001b[1;33m       raise ValueError(\"`y` argument is not supported when using \"\n\u001b[0m\u001b[0;32m    747\u001b[0m                        \"dataset as input.\")\n\u001b[0;32m    748\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_none_or_empty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mValueError\u001b[0m: `y` argument is not supported when using dataset as input."
          ]
        }
      ],
      "source": [
        "model1.fit(trainSet, y=y_train, epochs=5, validation_data=(valSet, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNx5/E2lEoiROLDiz7hkI4c",
      "include_colab_link": true,
      "name": "Untitled10.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
